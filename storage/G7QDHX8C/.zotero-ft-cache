
Skip to main content
Cornell University
We are hiring

We gratefully acknowledge support from
the Simons Foundation and member institutions.
arxiv logo > cs > arXiv:2106.15110

Help | Advanced Search
Search
Computer Science > Computation and Language
(cs)
[Submitted on 29 Jun 2021 ( v1 ), last revised 23 Apr 2022 (this version, v2)]
Title: Time-Aware Language Models as Temporal Knowledge Bases
Authors: Bhuwan Dhingra , Jeremy R. Cole , Julian Martin Eisenschlos , Daniel Gillick , Jacob Eisenstein , William W. Cohen
Download a PDF of the paper titled Time-Aware Language Models as Temporal Knowledge Bases, by Bhuwan Dhingra and 5 other authors
Download PDF

    Abstract: Many facts come with an expiration date, from the name of the President to the basketball team Lebron James plays for. But language models (LMs) are trained on snapshots of data collected at a specific moment in time, and this can limit their utility, especially in the closed-book setting where the pretraining corpus must contain the facts the model should memorize. We introduce a diagnostic dataset aimed at probing LMs for factual knowledge that changes over time and highlight problems with LMs at either end of the spectrum -- those trained on specific slices of temporal data, as well as those trained on a wide range of temporal data. To mitigate these problems, we propose a simple technique for jointly modeling text with its timestamp. This improves memorization of seen facts from the training time period, as well as calibration on predictions about unseen facts from future time periods. We also show that models trained with temporal context can be efficiently "refreshed" as new data arrives, without the need for retraining from scratch. 

Comments: 	Version accepted to TACL
Subjects: 	Computation and Language (cs.CL)
Cite as: 	arXiv:2106.15110 [cs.CL]
  	(or arXiv:2106.15110v2 [cs.CL] for this version)
  	https://doi.org/10.48550/arXiv.2106.15110
Focus to learn more
arXiv-issued DOI via DataCite
Journal reference: 	Transactions of the Association for Computational Linguistics 2022; 10 257-273
Related DOI : 	https://doi.org/10.1162/tacl_a_00459
Focus to learn more
DOI(s) linking to related resources
Submission history
From: Bhuwan Dhingra [ view email ]
[v1] Tue, 29 Jun 2021 06:18:57 UTC (5,563 KB)
[v2] Sat, 23 Apr 2022 07:04:46 UTC (5,786 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Time-Aware Language Models as Temporal Knowledge Bases, by Bhuwan Dhingra and 5 other authors
    PDF
    Other formats 

( license )
Current browse context:
cs.CL
< prev   |   next >
new | recent | 2106
Change to browse by:
cs
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

DBLP - CS Bibliography
listing | bibtex
Bhuwan Dhingra
Daniel Gillick
Jacob Eisenstein
William W. Cohen
a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

