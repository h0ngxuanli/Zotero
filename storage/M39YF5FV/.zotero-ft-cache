Universal Domain Adaptation
Kaichao You1, Mingsheng Long1( ), Zhangjie Cao1, Jianmin Wang1, and Michael I. Jordan2 1KLiss, MOE; BNRist; School of Software, Tsinghua University, China 1Research Center for Big Data, Tsinghua University, China 1Beijing Key Laboratory for Industrial Big Data System and Application 2University of California, Berkeley, USA
youkaichao@gmail.com, {mingsheng,jimwang}@tsinghua.edu.cn, jordan@cs.berkeley.edu

Abstract

Closed Set DA

Partial DA

Domain adaptation aims to transfer knowledge in the presence of the domain gap. Existing domain adaptation methods rely on rich prior knowledge about the relationship between the label sets of source and target domains, which greatly limits their application in the wild. This paper introduces Universal Domain Adaptation (UDA) that requires no prior knowledge on the label sets. For a given source label set and a target label set, they may contain a common label set and hold a private label set respectively, bringing up an additional category gap. UDA requires a model to either (1) classify the target sample correctly if it is associated with a label in the common label set, or (2) mark it as “unknown” otherwise. More importantly, a UDA model should work stably against a wide spectrum of commonness (the proportion of the common label set over the complete label set) so that it can handle real-world problems with unknown target label sets. To solve the universal domain adaptation problem, we propose Universal Adaptation Network (UAN). It quantiﬁes sample-level transferability to discover the common label set and the label sets private to each domain, thereby promoting the adaptation in the automatically discovered common label set and recognizing the “unknown” samples successfully. A thorough evaluation shows that UAN outperforms the state of the art closed set, partial and open set domain adaptation methods in the novel UDA setting.
1. Introduction
Deep learning has boosted the progress of computer vision and improved state of the art performance on diverse vision tasks such as image classiﬁcation [13], object detection [30] and semantic segmentation [12]. However, the remarkable efﬁcacy of deep learning algorithms highly relies on abundant labeled training data, which requires tedious labor work on collecting labeled data. Given a large-scale

Open Set DA (Busto et al. 2017) Open Set DA (Saito et al. 2018)

Universal DA
?

Source Domain Label Set

Target Domain Label Set

Figure 1. Universal Domain Adaptation (UDA) and existing domain adaptation settings with respect to label sets of source and target domains (blue shades indicate shared labels). Only UDA is able to deal with the setting that the label set of target domain is unknown.

unlabeled dataset, it is usually prohibitive to annotate enough training data such that we can train a deep learning model that generalizes well. An alternative is to leverage off-theshelf labeled data from a related domain (source domain) to improve the model for the domain of interest (target domain). The target domain may contain data collected by different sensors, from different perspectives or under different illumination conditions compared with the source domain, leading to large domain gap. Domain adaptation [33] aims to minimize the domain gap and successfully transfer the model trained on the source domain to the target domain.
Existing domain adaptation methods tackle the domain gap either by learning domain invariant feature representation, by generating features/samples for target domains or by transforming samples between domains through generative

2720

models. They suppose that label sets are identical across domains, as shown in Figure 1 (closed set domain adaptation). This simpliﬁed scenario focuses on the fundamental problem of domain adaptation and provides insightful ideas for future research. Recent works try to relax the assumption by proposing open set domain adaptation [28, 35] and partial domain adaptation [2, 45]. As shown in Figure 1, partial domain adaptation [2, 45] requests that the source label set contains the target label set while Busto et al. [28] introduces “unknown” classes in both domains, and assumes common classes between two domains are known in the training phase. Modiﬁed open set domain adaptation by Saito et al. [35] removes data of source unknown classes such that the source label set is a subset of the target label set. Luo et al. [24] allows partly shared label sets and requires some labeled data in the target domain, where the target label set is known. These works constitute valuable advances towards practical domain adaptation.
Practical scenarios are way more complicated and these assumptions are easily violated. For example, labeled animals from different datasets are easily accessible. But if we want to recognize animals in the wild, we are exposed to two challenges: (1) The background may deviate from those in the training data, leading to large domain gap; (2) Some native species do not exist in the training data, in the meantime, animal species in the deployed environment may not cover all the training species because training data is too diverse, leading to large category gap. In summary, the relationship of label sets between the source and target domains is unknown in the presence of a large domain gap. If the source label set is large enough to contain the target label set, partial domain adaptation methods are good choices; if the source label set is contained in the target label set or common classes are known, open set domain adaptation methods are good choices. In a general scenario, however, we cannot select the proper domain adaptation method because no prior knowledge about the target domain label set is given.
For this purpose, we propose a generalized setting, termed Universal Domain Adaptation (UDA). In UDA, given a labeled source domain, for any related target domain, regardless of how its label set differs from that of the source domain, we need to classify its samples correctly if it belongs to any class in the source label set, or mark it as“unknown” otherwise. The word “universal” indicates that UDA imposes no prior knowledge on the label sets.
UDA poses two major technical challenges for designing domain adaptation models in the wild. (1) Since we know nothing about the target label set, we cannot decide which part of the source domain should be matched to which part of the target domain. If we naively match the entire source domain with the entire target domain, mismatching of different label sets will deteriorate the model. (2) The model should be able to mark target samples as “unknown” if they

do not belong to any class in the source label set. Since there are no labeled training data for these classes, by no means the classiﬁer can tell their detailed category.
To address Universal Domain Adaptation, we propose Universal Adaptation Network (UAN), equipping with a novel criterion to quantify the transferability of each sample. The criterion integrates both the domain similarity and the prediction uncertainty of each sample into a sample-level weighting mechanism. With the transferability-enhanced UAN model, the samples coming from the common label set between the source and target domains are automatically detected and matched while the target samples coming from the target private label set can be successfully marked by a rejection pipeline as “unknown” class.
The main contributions of this paper are: (1) We introduce a more practical Universal Domain Adaptation (UDA) setting that imposes no prior knowledge on the label sets of source and target domains. This is important considering that we do not have access to target labels in unsupervised domain adaptation and sometimes it is even impossible to know the target label set, not to mention how it overlaps with the source label set. (2) We study the performance of existing domain adaptation methods under a variety of UDA settings including closed set, partial and open set domain adaptation. Methods tailored to speciﬁc settings do not work well in UDA. This highlights the need for a UDA-friendly model. (3) We propose Universal Adaptation Network (UAN), an end-to-end solution, which exploits both the domain similarity and the prediction uncertainty of each sample to develop a weighting mechanism for discovering label sets shared by both domains and promote common-class adaptation. Empirical results show that UAN works stably across different UDA settings and outperforms existing methods.
2. Related Work
We brieﬂy review recent domain adaptation methods in this section. According to the constraint on the label set relationship between domains, these methods fall into closed set domain adaptation, partial domain adaptation, or open set domain adaptation.
2.1. Closed Set Domain Adaptation
Closed set domain adaptation focuses on mitigating the impact of the domain gap between source and target domains. Solutions to closed set domain adaptation mainly fall into two categories: feature adaptation and generative model. Feature adaptation methods diminish the feature distribution discrepancy between source and target domains by minimizing well-deﬁned statistical distances on feature distributions. Early shallow adaptation methods [33, 7, 27, 5, 46, 42] usually provide insights in developing modern deep adaptation methods [38, 21, 6, 11, 39, 23, 37, 34, 22], while other

2721

deep adaptation methods further explore architecture designs [19, 43, 36, 26, 20, 41, 16, 47, 25, 4, 18]. Tzeng et al. [38] and Long et al. [21] ﬁrst proposed to minimize Maximum Mean Discrepancy (MMD) of deep features across domains. Long et al. [23] further exploits a residual transfer structure and introduces entropy minimization on target data. Zellinger et al. [44] enables distribution alignment by optimizing Central Moment Discrepancy (CMD). Haeusser et al. [11] constructs a bipartite graph to force feature distribution alignment within clusters. Bhushan et al. [1] enables domain adaptation by minimizing Earth Mover’s Distance (EMD) between distributions. Meanwhile, with signiﬁcant advances made in image synthesis by Generative Adversarial Nets [8], methods that match feature distributions by generative models are proposed. They learn a domain classiﬁer to discriminate features from source and target domains and force the feature extractor to confuse the domain classiﬁer in an adversarial learning paradigm [6, 39, 37].
Methods based on generative models synthesize labeled target samples as data augmentation and match domains in both pixel and feature levels [19, 36, 16, 20, 26, 17, 41]. With the impressive results of Cycle-Consistent Generative Adversarial Network [48] in image translation, CycleGANbased domain adaptation methods have been studied recently [15, 32]. These methods usually transform source images into target-like images and vice versa with CycleGAN, then train the classiﬁers for each domain respectively with source images and transformed images.
Attempts for closed set domain adaptation focus on solving fundamental problems in distribution matching and provide a solid basis for the extension of domain adaptation.
2.2. Partial Domain Adaptation
The presence of Big Data gives rise to partial domain adaptation (PDA) [2, 45, 3], which transfers a learner from a big source domain to a small target domain. The label set of the source domain is supposed to be large enough to contain the target label set. To solve partial domain adaptation, Cao et al. [2] utilizes multiple domain discriminators with classlevel and instance-level weighting mechanism to achieve per-class adversarial distribution matching. Zhang et al. [45] constructs an auxiliary domain discriminator to quantify the probability of a source sample being similar to the target domain. Cao et al. [3] further improves PDA by employing only one adversarial network and jointly applying class-level weighting on the source classiﬁer.
Efforts for partial domain adaptation push well-studied domain adaptation problem towards a more practical setting.
2.3. Open Set Domain Adaptation
Busto et al. [28] proposed open set domain adaptation (OSDA), as shown in Figure 1. The classes private to both domains are uniﬁed as an “unknown” class. They use an

Assign-and-Transform-Iteratively (ATI) algorithm to map target samples to source classes and then train SVMs for ﬁnal classiﬁcation. Saito et al. [35] modiﬁed the open set domain adaptation by requiring no data of the source private label set and extends the source classiﬁer by adding an explicit “unknown” class and trains it adversarially among classes.
These methods tackle the domain gap by discarding the “unknown” classes when common classes are known in advance. While conﬁned from more generalized settings, they shed light on designing practical domain adaptation models.

3. Universal Domain Adaptation

In this section, we formally introduce Universal Domain Adaptation (UDA) setting and address it by a novel Universal Adaptation Network (UAN).

3.1. Problem Setting

In Universal Domain Adaptation (UDA), a source domain Ds = {(xsi , yis)} consisting of ns labeled samples and a target domain Dt = {(xti)} of nt unlabeled samples are provided at training. Note that the source data are sampled

from distribution p while the target data from distribution q.

We use Cs to denote the label set of source domain and Ct the label set of target domain. C = Cs ∩ Ct is the common label set shared by both domains. Cs = Cs \ C and Ct = Ct \ C
represent the label sets private to the source domain and the

target domain respectively. pCs and pC are used to denote the distributions of source data with labels in the label set Cs and C respectively, and qCt , qC for target distributions with labels in the label set Ct, C respectively. Note that the target data
are fully unlabeled, and the target label sets (inaccessible at

training) are only used for deﬁning the UDA problem.

We deﬁne the commonness between two domains as the

Jaccard

distance

of

two

label

sets:

ξ

=

. |Cs ∩Ct |
|Cs ∪Ct |

Closed

set

domain adaptation is a special case of UDA when ξ = 1.

The smaller ξ is, the less sharing knowledge is and the more

difﬁcult the adaptation is. The task for UDA is to design a

model that does not know ξ but works well across a wide

spectrum of ξ. It must be able to distinguish between target

data coming from C and target data coming from Ct, as well as to learn a classiﬁcation model f to minimize the target

risk in the common label set, i.e. min E(x,y)∼qC [f (x) = y].

3.2. Technical Challenges

In UDA, a new challenge has emerged, the category gap
between two domains. The root of the category gap lies in
the difference of the label sets. If we naively pick any of
the existing closed set domain adaptation methods to solve UDA, source data in Cs may be matched with target data from Ct. Such blind alignment is problematic since their label sets have no overlap (Cs ∩ Ct = ∅) and forcefully matching them will cause many target private data to be

2722

Training phase xFz

EG

G ^y

w s,wt

D' d^'

ED

ED'
D d^

Testing phase

G ^y

xF z

wt

argmax ^y

No

wt <w0?

Yes
unknown

D' d^

conv layer

fc layer

loss

computation flow

weighting mechanism

Figure 2. The training and testing phases of the Universal Adaptation Network (UAN) designed for Universal Domain Adaptation (UDA).

predicted as a class in Cs whereas they should be marked as “unknown”. If we turn to tailored methods of partial or open set domain adaptation, we must face the fact that the relationship between Cs and Ct is unknown. In the absence of the conﬁguration about C, Cs and Ct, it is hard to make a choice among tailored domain adaptation methods. Thus, we need to automatically identify the source and target data from C, such that feature alignment can be done in the autodiscovered common label set.
Despite the category gap, the domain gap still exists in UDA setting, i.e. between the source and target data in the common label set. In other words, p = q and pC = qC. Domain adaptation should be applied to align distributions of the source and target data in the common label set C.
Another challenge for UDA is to detect “unknown” classes. In practice, conﬁdence thresholding, which marks samples with low classiﬁcation conﬁdence as “unknown”, is often used. Nonetheless, such a straightforward method may fail in universal domain adaptation since the predictions by neural networks are usually overconﬁdent [10] but less discriminative due to the underlying domain gap.
3.3. Universal Adaptation Network
We propose Universal Adaptation Network (UAN) to address the UDA problem. As shown in Figure 2, the architecture of UAN consists of a feature extractor F , an adversarial domain discriminator D, a non-adversarial domain discriminator D′ and a label classiﬁer G. Input x from either domain is fed into the feature extractor F . The extracted feature z = F (x) is forwarded into the label classiﬁer G to obtain the probability yˆ = G(z) of x over the source classes Cs. The non-adversarial domain discriminator D′ obtains the domain similarity dˆ′ = D′(z), quantifying the similarity of x to the source domain. The adversarial domain discriminator

D aims to adversarially match the feature distributions of the source and target data falling in the common label set C (Note that we need a mechanism to detect the common label
set). EG, ED′ and ED represent the error for label classiﬁer G, non-adversarial domain discriminator D′ and adversarial
domain discriminator D, which are formally deﬁned as

EG = E(x,y)∼pL (y, G(F (x)))

(1)

ED′ = − Ex∼p log D′ (F (x)) − Ex∼q log 1 − D′ (F (x))

(2)

ED = − Ex∼pws(x) log D (F (x)) − Ex∼qwt(x) log (1 − D (F (x)))

(3)

where L is the standard cross-entropy loss, ws(x) indicates
the probability of a source sample x belonging to the common label set C, and similarly, wt(x) indicates the probabil-
ity of a target sample x belonging to the common label set C. The details of ws(x) and wt(x) will be elaborated in the next subsection. With well-established weighting ws(x) and wt(x), the adversarial domain discriminator D is conﬁned
to distinguish the source and target data in the common label set C. Adversarially, the feature extractor F strives to confuse D, yielding domain-invariant features in the common label set C. The label classiﬁer G trained on such features
can be applied safely to the target domain.
The training of UAN can be written as a minimax game:

max min EG − λED

D F,G

(4)

min
D′

ED′

where λ is a hyper-parameter to trade off between transferability and discriminability. We utilize the well-established gradient reversal layer proposed by Ganin et al. [6] to reverse

2723

the gradient between F and D to optimize all the modules
in an end-to-end training framework.
The testing phase of UAN is shown in the right plot of
Figure 2. Given each input target sample x, its categorical prediction yˆ(x) over the source label set Cs, and the domain prediction dˆ′(x), we compute wt(x) using Eq. (8) (details in the next subsection). With a validated threshold w0, the class y(x) can be predicted by thresholding yˆ(x) w.r.t. w0:

y(x) =

unknown argmax (yˆ)

wt < w0 wt ≥ w0

(5)

which either rejects the target sample x as “unknown” class or classiﬁes it to one of the source classes.

3.4. Transferability Criterion

In this section, we further elaborate on how to compute weighting ws = ws(x) and wt = wt(x) by sample-level transferability criterion. With a proper sample-level transferability criterion, each point in both source and target domains can be weighted such that the distributions of source and target data in the common label set C can be maximally aligned. Also, data from target private label set Ct can be identiﬁed and marked as “unknown” with the help of the sample-level transferability criterion. Thus, a well-established samplelevel transferability criterion should satisfy Eq. (6):

Ex∼pC ws(x) > Ex∼pCs ws(x) Ex∼qC wt(x) > Ex∼qCt wt(x)

(6)

These inequalities should hold in a non-negligible margin.
Now we need to construct the sample-level transferability
criterion. We ﬁrst list what we have at hand about each input x: yˆ, dˆ, dˆ′. Since D is involved in adversarial training and thus fooled, its output dˆ is not discriminative enough. We thus analyze the properties of yˆ and dˆ′ as follows.
Domain Similarity. In Eq. (2), the objective of D′ is to
predict samples from source domain as 1 and samples from target domain as 0. Thus, dˆ′ can be seen as the quantiﬁcation
for the domain similarity of each sample. For a source sample, smaller dˆ′ means that it is more similar to the target domain; for a target sample, larger dˆ′ means that it is more
similar to the source domain. Therefore, we can hypothesize that Ex∼pCs dˆ′ > Ex∼pC dˆ′ > Ex∼qC dˆ′ > Ex∼qCt dˆ′.
Due to the nature of D′, inequality Ex∼pCs dˆ′, Ex∼pC dˆ′ > Ex∼qC dˆ′, Ex∼qCt dˆ′ naturally holds. Since pC and qC share the same label set, pC is closer to qC compared with qCt , and it is reasonable to hypothesize Ex∼pCs dˆ′ > Ex∼pC dˆ′. The same observation applies to Ex∼qC dˆ′ > Ex∼qCt dˆ′.
Prediction Uncertainty. The prediction yˆ contains the
discriminative information about the input, but it is only reli-
able in the source domain guaranteed by labeled data. To ex-
ploit unlabeled data, entropy minimization has been used as a

criterion in semi-supervised learning and domain adaptation
[9, 23] to enforce the decision boundary in the unlabeled data
to pass through low-density area. In principle, entropy quan-
tiﬁes the prediction uncertainty, and smaller entropy means more conﬁdent prediction. We hypothesize: Ex∼qCt H(yˆ) > Ex∼qC H(yˆ) > Ex∼pC H(yˆ) > Ex∼pCs H(yˆ).
Since the source domain is labeled and the target domain
is unlabeled, predictions are certain for source samples and uncertain for target samples, Ex∼qCt H(yˆ), Ex∼qC H(yˆ) > Ex∼pC H(yˆ), Ex∼pCs H(yˆ).
Similar samples from qC and pC can attract each other. Thus, the entropy of samples from pC becomes larger because they are inﬂuenced by the high entropy samples from qC. Still, as Cs has no intersection with Ct, samples from pCs are not inﬂuenced by the target data and keeps highest certainty. So we hypothesize that Ex∼pC H(yˆ) > Ex∼pCs H(yˆ). Similarly, Ct has no intersection with Cs (data from qCt does not belong to any class in Cs), and thus the hypothesis Ex∼qCt H(yˆ) > Ex∼qC H(yˆ) is reasonable.
With the above analysis, the sample-level transferability
criterion for source data points and target data points can be
respectively deﬁned as Eq. (7) and Eq. (8):

ws(x)

=

H (yˆ ) log |Cs|

−

dˆ′(x)

(7)

wt(x)

=

dˆ′(x)

−

H (yˆ ) log |Cs|

(8)

Note that the entropy is normalized by its maximum value (log |Cs|) so that it is restricted into [0, 1] and comparable to the domain similarity measure dˆ′. Also, the weights are normalized into interval [0, 1] during training.
The proposed universal adaptation network (UAN) lever-
ages the sample-level transferability criterion to disentangle source data in C, Cs and target data in C, Ct. As such, the category gap is reduced. The domain gap is reduced as well by aligning features between domains in shared label set C.

4. Experiments
To perform a thorough evaluation, we compare UAN with state of the art methods tailored to various domain adaptation settings under a variety of UDA settings on several datasets with different ξ, |Cs ∪ Ct|, Ct and Cs. Then, we explore the performance with respect to the change of ξ, |Cs ∪ Ct|, Ct and Cs. We further provide comprehensive analyses of the hyper-parameter sensitivity and the quality of samplelevel transferability criterion about the proposed UAN model. Code and data will be available at github.com/thuml.
4.1. Experimental Setup
In this subsection, we describe the datasets, the evaluation protocols and the implementation details.

2724

Table 1. Average class accuracy (%) of universal domain adaptation tasks on Ofﬁce-Home (ξ = 0.15) dataset (ResNet)

Method

Ofﬁce-Home

Ar → Cl Ar → Pr Ar → Rw Cl → Ar Cl → Pr Cl → Rw Pr → Ar Pr → Cl Pr → Rw Rw → Ar Rw → Cl Rw → Pr Avg

ResNet [13] DANN [6] RTN [23] IWAN [45] PADA [45] ATI [28] OSBP [35]

59.37 56.17 50.46 52.55 39.58 52.90 47.75

76.58 81.72 77.80 81.40 69.37 80.37 60.90

87.48 86.87 86.90 86.51 76.26 85.91 76.78

69.86 68.67 65.12 70.58 62.57 71.08 59.23

71.11 73.38 73.40 70.99 67.39 72.41 61.58

81.66 83.76 85.07 85.29 77.47 84.39 74.33

73.72 69.92 67.86 74.88 48.39 74.28 61.67

56.30 56.84 45.23 57.33 35.79 57.84 44.50

86.07 85.80 85.50 85.07 79.60 85.61 79.31

78.68 79.41 79.20 77.48 75.94 76.06 70.59

59.22 57.26 55.55 59.65 44.50 60.17 54.95

78.59 78.26 78.79 78.91 78.10 78.42 75.18

73.22 73.17 70.91 73.39 62.91 73.29 63.90

UAN w/o d 61.60 UAN w/o y 56.63
UAN 63.00

81.86 77.51 82.83

87.67 87.61 87.85

74.52 71.96 76.88

73.59 69.08 78.70

84.88 83.18 85.36

73.65 71.40 78.22

57.37 56.10 58.59

86.61 84.24 86.80

81.58 79.27 83.37

62.15 60.59 63.17

79.14 75.39 78.35 72.91 79.43 77.02

Table 2. Average class accuracy (%) on Ofﬁce-31 (ξ = 0.32), ImageNet-Caltech (ξ = 0.07) and VisDA2017 (ξ = 0.50) (ResNet)

Method

Ofﬁce-31

ImageNet-Caltech VisDA

A → W D → W W → D A → D D → A W → A Avg I → C C → I

ResNet [13] DANN [6] RTN [23] IWAN [45] PADA [45] ATI [28] OSBP [35]

75.94 80.65 85.70 85.25 85.37 79.38 66.13

89.60 80.94 87.80 90.09 79.26 92.60 73.57

90.91 88.07 88.91 90.00 90.91 90.08 85.62

80.45 82.67 82.69 84.27 81.68 84.40 72.92

78.83 74.82 74.64 84.22 55.32 78.85 47.35

81.42 83.54 83.26 86.25 82.61 81.57 60.48

82.86 81.78 84.18 86.68 79.19 84.48 67.68

70.28 71.37 71.94 72.19 65.47 71.59 62.08

65.14 66.54 66.15 66.48 58.73 67.36 55.48

52.80 52.94 53.92 58.72 44.98 54.81 30.26

UAN

85.62

94.77

97.99

86.50

85.45

85.12 89.24 75.28 70.17 60.83

4.1.1 Datasets
Ofﬁce-31 [33] is de facto for visual domain adaptation with 31 categories in 3 visually distinct domains (A, D, W). We use the 10 classes shared by Ofﬁce-31 and Caltech-256 [7] as the common label set C, then in alphabetical order, the next 10 classes are used as the Cs, and the reset 11 classes are used as the Ct. Here ξ = 0.32.
Ofﬁce-Home [40] is a larger dataset with 65 object categories in 4 different domains: Artistic images (Ar), Clip-Art images (Cl), Product images (Pr) and Real-World images (Rw). In alphabet order, we use the ﬁrst 10 classes as C, the next 5 classes as Cs and the rest as Ct. Here ξ = 0.15.
VisDA2017 [29] dataset focuses on a special domain adaptation setting (simulation to real). The source domain consists of images generated by game engines and target domain consists of real-world images. There are 12 classes in this dataset. We use the ﬁrst 6 classes as C, the next 3 classes as Cs and the rest as Ct. Here ξ = 0.50.
ImageNet-Caltech is built from ImageNet-1K [31] with 1000 classes and Caltech-256 with 256 classes. As in previous works [2, 3], we used the 84 common classes shared by both domains as the common label set C and use their private classes as the private label set respectively. This dataset naturally falls into the universal domain adaptation paradigm. We form two universal domain adaptation tasks: I → C and C → I. Here ξ = 0.07.

These dataset settings are set up to both comply with the existing conﬁgurations [2, 3, 35, 28] and cover as many commonness levels ξ as possible, since brute-force evaluation of all combinations of ξ, |Cs ∪ Ct|, Ct and Cs is unacceptable.
4.1.2 Evaluation Details
Compared Methods. We compare the proposed UAN with (1) Convolutional Neural Network: ResNet [13], (2) close-set domain adaptation methods: Domain-Adversarial Neural Networks (DANN) [6], Residual Transfer Networks (RTN) [23], (3) partial domain adaptation methods: Importance Weighted Adversarial Nets (IWAN) [45], Partial Adversarial Domain Adaptation (PADA) [3], (4) open set domain adaptation methods: Assign-and-Transform-Iteratively (ATI) [28], Open Set Back-Propagation (OSBP) [35]. These methods are state of the art in their respective settings (ATI-λ is compared and λ is derived as described in [28]). It shall be valuable to study the performance of these methods in the practical UDA setting.
Evaluation Protocols. We adopt the evaluation protocol in Visual Domain Adaptation (VisDA2018) Open-Set Classiﬁcation Challenge, where all the data in the target private label set is regarded as one uniﬁed “unknown” class and the average of per-class accuracy for all the |C| + 1 classes is the ﬁnal result. We extend existing methods by conﬁdence thresholding. At the testing stage, if the prediction conﬁ-

2725

90

90

70

80

80

Accuracy Accuracy
Accuracy

70 60 50
0

ResNet DANN IWAN OSBP UAN

5

10

15

20 21

Size of Target Private Label Set

70

ResNet

DANN

60

IWAN

OSBP

UAN

50 31

25

20

15

10

5

0

Size of Common Label Set

UAN

ResNet

DANN

IWAN

ATI-λ

60

−1.0

−0.8

−0.6

−0.4

−0.2

0.0

w0

(a) Accuracy w.r.t. |Ct|

(b) Accuracy w.r.t. |C|

(c) Sensitivity to w0

Figure 3. (a) Accuracy w.r.t. |Ct| in task A → D, ξ = 0.32. (b) Accuracy w.r.t. |C| in task A → D. (c) Performance w.r.t. threshold w0.

dence is under the conﬁdence threshold, the input image is classiﬁed as “unknown”.
Implementation Details. Implementation is in PyTorch and ResNet-50 [13] is used as the backbone network. Models are ﬁne-tuned from ResNet-50 pre-trained on ImageNet. We set temperature [14] as 10 when calculating yˆ in Eq. (7) because the prediction for source data is usually too certain and the entropy is low. When applied in Eq. (3), ws, wt are normalized in a mini-batch to be within interval [0, 1].
4.2. Classiﬁcation Results
The classiﬁcation results are shown in Tables 1 and 2, respectively. UAN outperforms all the compared methods in terms of the average per-class accuracy. In particular, we have some key observations.
In the practical UDA setting, especially in the difﬁcult Ofﬁce-Home dataset, most existing methods perform similarly to or even worse than ResNet, indicating that existing methods are prone to negative transfer in UDA settings, meaning that they perform worse than a model only trained on source data without any adaptation. For example, Figure 4(a) shows the per-class accuracy gain compared to ResNet on task Ar → Cl. We can ﬁnd that DANN, IWAN, and OSBP suffer from negative transfer in most classes and are only able to promote the adaptation for a few classes. Only UAN promotes positive transfer for all classes.
In these various settings, UAN outperforms all the mentioned methods. This is because UAN has a carefully designed sample-level transferability criterion. It ﬁlters out data coming from Ct and Cs on feature alignment and provides a better criterion for “unknown” class detection than the existing conﬁdence thresholding method.
Existing methods perform well when their assumptions hold but worse when violated. Take OSBP as an example, if manually removing source private classes (invalid operation since target labels are unknown), its accuracy is 89.1% on Ofﬁce-31; however, if keeping source private classes (violating its assumption), its accuracy drops to 67.68%. As the assumptions of previous open set DA methods are violated in UDA, it is no wonder that their accuracies drop sharply.

4.3. Analysis on Different UDA Settings
Varying Size of Ct and Cs. With ﬁxed |Cs ∪ Ct| and ξ, we explore the performance of methods mentioned above on universal domain adaptation with the various sizes of Ct (Cs also changes correspondingly) on task A → D in Ofﬁce31 dataset. As shown in Figure 3(a), UAN outperforms all the compared methods on most sizes of Ct. In particular, when |Ct| = 0, which is the partial domain adaptation setting with Ct ⊂ Cs, the performance of UAN is comparable to IWAN’s performance. And when |Ct| = 21, which is the open set domain adaptation setting with Cs ⊂ Ct, the performance of UAN is comparable to OSBP’s performance. IWAN and OSBP both take advantage of the prior knowledge about label sets and design modules to exploit the knowledge. However, UAN can still catch up with them in their expert settings, indicating UAN is effective and robust to diverse sizes of Ct and Cs. In the middle of 0 and 21, where Cs and Ct are partly shared, UAN outperforms other methods with large margin. UAN can produce impressive results without any prior knowledge about the target label set. The general trend in Figure 3(a) is that the performance goes higher when |Ct| becomes larger. This is natural since larger |Ct| means smaller |Cs| and less distraction to the label classiﬁer.
Varying Size of Common Label Set C. We explore another dimension of universal domain adaptation by varying the size of C. This is done in Ofﬁce-31 dataset on task A → D. Here |C| + |Ct| + |Cs| = 31. For simplicity, we let |Ct| = |Cs| + 1 and vary |C| from 0 to 31. Figure 3(b) shows the accuracy of these methods with different |C|’s. When |C| = 0, source domain and target domain have no overlap on label sets, i.e. Ct ∩ Cs = ∅. We observe that UAN substantially outperforms all the compared methods with large margin, because they all assume that there is some common label set between source and target domains and cannot ﬁlter out target samples well when all the target samples are in the private label set Ct. When |C| = 31, which is the closed set domain adaptation setting with Cs = Ct, we see that the performance of UAN is comparable with DANN’s performance, indicating that the sample-level transferability criterion of

2726

Uncertainty

DANN

Domain Similarity

IWAN

10 0 -10 -20 -30
10 0 -10 -20 -30
10 0 -10 -20 -30

OSBP

Transferability

UAN

10 0 -10 -20
-30 0 1 2 3 4 5 6 7 8 9 class

−1

0

1

−1

0

1

source

target

(a) Negative Transfer in UDA

(b) Hypotheses Quality (blue for common and black for private)

Figure 4. (a) The negative transfer inﬂuence in UDA (task Ar → Cl). (b) Justiﬁcation of validity of hypotheses in Section 3.4.

UAN preserves useful samples and does not inﬂuence performance on the closed set domain adaptation setting. Note that when |C| keeps decreasing, the performance of DANN and IWAN drops rapidly and only UAN works stably.
4.4. Analysis of Universal Adaptation Network
Ablation Study. We go deeper into the efﬁcacy of the proposed sample-level transferability criterion by performing an ablation study that evaluates variants of UAN. (1) UAN w/o d is the variant without integrating the domain similarity into the sample-level transferability criterion in Eq. (7) and Eq. (8); (2) UAN w/o y is the variant without integrating the uncertainty criterion into sample-level transferability criterion in Eq. (7) and Eq. (8). Results are shown in bottom rows of Table 1. UAN outperforms UAN w/o d and UAN w/o y, indicating both the domain similarity component and the uncertainty criterion component in the deﬁnition of ws(x), wt(x) are important and necessary. In addition, UAN w/o d performs better than UAN w/o y, meaning that integrating the uncertainty criterion into the sample-level transferability criterion is even more crucial.
Hypotheses Justiﬁcation. To justify the validity of the hypotheses in Section 3.4, we plot in Figure 4(b) the estimated probability density function for different components of weights ws(x) in Eq. (7) and wt(x) in Eq. (8). Results show that all the hypotheses are successfully justiﬁed, explaining why UAN can perform well in various UDA settings. Another observation is that the uncertainty criterion and the domain similarity themselves can be used to distinguish all the examples from common label set and private label sets. By combining these two components we can obtain more distinguishable transferability criterion.

Threshold Sensitivity. We explore the sensitivity of UAN with respect to threshold w0 in task I → C. As shown in Figure 3(c), though UAN’s accuracies vary by about 2% w.r.t. w0, it consistently outperforms the other methods by large margins in a wide range of w0. Note that the baselines are fully tuned and their best accuracies are compared here.
5. Conclusion
In this paper, we introduce a novel Universal Domain Adaptation (UDA) setting, where no prior knowledge are required on the label set relationship between domains. We propose Universal Adaptation Network (UAN) with a welldesigned sample-level transferability criterion to address UDA. A thorough evaluation shows that existing methods requiring prior knowledge on the relationship of label sets cannot work well in general UDA setting while the proposed UAN works stably and achieves state-of-the-art results.
In practice, if one wants to generalize a model to a new scenario, the proposed UAN can be a good candidate model. If UAN classiﬁes most examples as “unknown”, then domain adaptation in such a new scenario may well fail, and collecting labels will be indispensable. On the other hand, if UAN can generate labels for most examples, collecting labels for such a scenario are not necessary and domain adaptation will perform the work. That said, UAN can serve as a pilot study when we encounter a new domain adaptation scenario.
Acknowledgements
This work is supported by National Key R&D Program of China (No. 2017YFC1502003) and National Natural Science Foundation of China (61772299, 71690231, and 61672313).

2727

References
[1] B. Bhushan Damodaran, B. Kellenberger, R. Flamary, D. Tuia, and N. Courty. Deepjdot: Deep joint distribution optimal transport for unsupervised domain adaptation. In ECCV, September 2018.
[2] Z. Cao, M. Long, J. Wang, and M. I. Jordan. Partial transfer learning with selective adversarial networks. In CVPR, June 2018.
[3] Z. Cao, L. Ma, M. Long, and J. Wang. Partial adversarial domain adaptation. In ECCV, pages 135–150, 2018.
[4] Q. Chen, Y. Liu, Z. Wang, I. Wassell, and K. Chetty. Re-weighted adversarial adaptation network for unsupervised domain adaptation. In CVPR, pages 7976– 7985, 2018.
[5] L. Duan, I. W. Tsang, and D. Xu. Domain transfer multiple kernel learning. TPAMI, 34(3):465–479, 2012.
[6] Y. Ganin, E. Ustinova, H. Ajakan, P. Germain, H. Larochelle, F. Laviolette, M. Marchand, and V. S. Lempitsky. Domain-adversarial training of neural networks. JMLR, 17:59:1–59:35, 2016.
[7] B. Gong, Y. Shi, F. Sha, and K. Grauman. Geodesic ﬂow kernel for unsupervised domain adaptation. In CVPR, 2012.
[8] I. Goodfellow, J. Pouget-Abadie, M. Mirza, B. Xu, D. Warde-Farley, S. Ozair, A. Courville, and Y. Bengio. Generative adversarial nets. In NeurIPS, pages 2672– 2680, 2014.
[9] Y. Grandvalet and Y. Bengio. Semi-supervised learning by entropy minimization. In NeurIPS, pages 529–536, 2004.
[10] C. Guo, G. Pleiss, Y. Sun, and K. Q. Weinberger. On calibration of modern neural networks. In International Conference on Machine Learning, pages 1321–1330.
[11] P. Haeusser, T. Frerix, A. Mordvintsev, and D. Cremers. Associative domain adaptation. In ICCV, volume 2, page 6, 2017.
[12] K. He, G. Gkioxari, P. Dollár, and R. Girshick. Mask r-cnn. In ICCV, pages 2980–2988. IEEE, 2017.
[13] K. He, X. Zhang, S. Ren, and J. Sun. Deep residual learning for image recognition. In CVPR, 2016.
[14] G. Hinton, O. Vinyals, and J. Dean. Distilling the knowledge in a neural network.
[15] J. Hoffman, E. Tzeng, T. Park, J. Zhu, P. Isola, K. Saenko, A. A. Efros, and T. Darrell. Cycada: Cycleconsistent adversarial domain adaptation. In ICML, pages 1994–2003, 2018.
[16] L. Hu, M. Kan, S. Shan, and X. Chen. Duplex generative adversarial network for unsupervised domain adaptation. In CVPR, June 2018.

[17] S.-W. Huang, C.-T. Lin, S.-P. Chen, Y.-Y. Wu, P.-H. Hsu, and S.-H. Lai. Auggan: Cross domain adaptation with gan-based data augmentation. In ECCV, September 2018.
[18] G. Kang, L. Zheng, Y. Yan, and Y. Yang. Deep adversarial attention alignment for unsupervised domain adaptation: the beneﬁt of target expectation maximization. In ECCV, September 2018.
[19] B. Konstantinos, S. Nathan, D. David, E. Dumitru, and K. Dilip. Unsupervised pixel–level domain adaptation with generative adversarial networks. In CVPR, pages 95–104, 2017.
[20] Y.-C. Liu, Y.-Y. Yeh, T.-C. Fu, S.-D. Wang, W.-C. Chiu, and Y.-C. Frank Wang. Detach and adapt: Learning cross-domain disentangled deep representation. In CVPR, June 2018.
[21] M. Long, Y. Cao, J. Wang, and M. I. Jordan. Learning transferable features with deep adaptation networks. In ICML, 2015.
[22] M. Long, Z. Cao, J. Wang, and M. I. Jordan. Conditional domain adversarial network. In NeurIPS, 2018.
[23] M. Long, H. Zhu, J. Wang, and M. I. Jordan. Unsupervised domain adaptation with residual transfer networks. In NeurIPS, pages 136–144, 2016.
[24] Z. Luo, Y. Zou, J. Hoffman, and L. F. Fei-Fei. Label efﬁcient learning of transferable representations acrosss domains and tasks. In NeurIPS, pages 165–177, 2017.
[25] F. Maria Carlucci, L. Porzi, B. Caputo, E. Ricci, and S. Rota Bulo. Autodial: Automatic domain alignment layers. In ICCV, Oct 2017.
[26] Z. Murez, S. Kolouri, D. Kriegman, R. Ramamoorthi, and K. Kim. Image to image translation for domain adaptation. In CVPR, June 2018.
[27] S. J. Pan, I. W. Tsang, J. T. Kwok, and Q. Yang. Domain adaptation via transfer component analysis. TNNLS, 22(2):199–210, 2011.
[28] P. Panareda Busto and J. Gall. Open set domain adaptation. In ICCV, Oct 2017.
[29] X. Peng, B. Usman, N. Kaushik, D. Wang, J. Hoffman, K. Saenko, X. Roynard, J.-E. Deschaud, F. Goulette, and T. L. Hayes. VisDA: A synthetic-to-real benchmark for visual domain adaptation. In CVPR Workshops, pages 2021–2026.
[30] S. Ren, K. He, R. Girshick, and J. Sun. Faster r-cnn: Towards real-time object detection with region proposal networks. In NeurIPS, pages 91–99.
[31] O. Russakovsky, J. Deng, H. Su, J. Krause, S. Satheesh, S. Ma, Z. Huang, A. Karpathy, A. Khosla, M. Bernstein, A. C. Berg, and L. Fei-Fei. ImageNet Large Scale Visual Recognition Challenge. IJCV, 115(3):211–252, 2015.

2728

[32] P. Russo, F. M. Carlucci, T. Tommasi, and B. Caputo. From source to target and back: Symmetric bi-directional adaptive gan. In CVPR, June 2018.
[33] K. Saenko, B. Kulis, M. Fritz, and T. Darrell. Adapting visual category models to new domains. In ECCV, 2010.
[34] K. Saito, K. Watanabe, Y. Ushiku, and T. Harada. Maximum classiﬁer discrepancy for unsupervised domain adaptation. In CVPR, June 2018.
[35] K. Saito, S. Yamamoto, Y. Ushiku, and T. Harada. Open set domain adaptation by backpropagation. In ECCV, September 2018.
[36] S. Sankaranarayanan, Y. Balaji, C. D. Castillo, and R. Chellappa. Generate to adapt: Aligning domains using generative adversarial networks. In CVPR, June 2018.
[37] E. Tzeng, J. Hoffman, K. Saenko, and T. Darrell. Adversarial discriminative domain adaptation. In CVPR, 2017.
[38] E. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and T. Darrell. Deep domain confusion: Maximizing for domain invariance. arXiv preprint arXiv:1412.3474, 2014.
[39] E. Tzeng, J. Hoffman, N. Zhang, K. Saenko, and T. Darrell. Simultaneous deep transfer across domains and tasks. In ICCV, 2015.
[40] H. Venkateswara, J. Eusebio, S. Chakraborty, and S. Panchanathan. Deep hashing network for unsupervised domain adaptation. In CVPR, 2017.
[41] R. Volpi, P. Morerio, S. Savarese, and V. Murino. Adversarial feature augmentation for unsupervised domain adaptation. In CVPR, June 2018.
[42] X. Wang and J. Schneider. Flexible transfer learning under support and model shift. In NeurIPS, 2014.
[43] S. Xie, Z. Zheng, L. Chen, and C. Chen. Learning semantic representations for unsupervised domain adaptation. In ICML, pages 5423–5432, 2018.
[44] W. Zellinger, T. Grubinger, E. Lughofer, T. Natschläger, and S. Saminger-Platz. Central moment discrepancy (CMD) for domain-invariant representation learning. In ICLR.
[45] J. Zhang, Z. Ding, W. Li, and P. Ogunbona. Importance weighted adversarial nets for partial domain adaptation. In CVPR, June 2018.
[46] K. Zhang, B. Schölkopf, K. Muandet, and Z. Wang. Domain adaptation under target and conditional shift. In ICML, 2013.
[47] W. Zhang, W. Ouyang, W. Li, and D. Xu. Collaborative and adversarial network for unsupervised domain adaptation. In CVPR, June 2018.

[48] J.-Y. Zhu, T. Park, P. Isola, and A. A. Efros. Unpaired image-to-image translation using cycle-consistent adversarial networks. In ICCV, pages 2242–2251, 2017.

2729

