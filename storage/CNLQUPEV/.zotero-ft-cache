
Skip to main content
Cornell University
We gratefully acknowledge support from
the Simons Foundation and member institutions.
arxiv logo > stat > arXiv:1811.10154

Help | Advanced Search
Search
Statistics > Machine Learning
(stat)
[Submitted on 26 Nov 2018 ( v1 ), last revised 22 Sep 2019 (this version, v3)]
Title: Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead
Authors: Cynthia Rudin
Download a PDF of the paper titled Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead, by Cynthia Rudin
Download PDF

    Abstract: Black box machine learning models are currently being used for high stakes decision-making throughout society, causing problems throughout healthcare, criminal justice, and in other domains. People have hoped that creating methods for explaining these black box models will alleviate some of these problems, but trying to \textit{explain} black box models, rather than creating models that are \textit{interpretable} in the first place, is likely to perpetuate bad practices and can potentially cause catastrophic harm to society. There is a way forward -- it is to design models that are inherently interpretable. This manuscript clarifies the chasm between explaining black boxes and using inherently interpretable models, outlines several key reasons why explainable black boxes should be avoided in high-stakes decisions, identifies challenges to interpretable machine learning, and provides several example applications where interpretable models could potentially replace black box models in criminal justice, healthcare, and computer vision. 

Comments: 	Author's pre-publication version of a 2019 Nature Machine Intelligence article. Shorter Version was published in NIPS 2018 Workshop on Critiquing and Correcting Trends in Machine Learning. Expands also on NSF Statistics at a Crossroads Webinar
Subjects: 	Machine Learning (stat.ML) ; Machine Learning (cs.LG)
Cite as: 	arXiv:1811.10154 [stat.ML]
  	(or arXiv:1811.10154v3 [stat.ML] for this version)
  	https://doi.org/10.48550/arXiv.1811.10154
Focus to learn more
arXiv-issued DOI via DataCite
Journal reference: 	Nature Machine Intelligence, Vol 1, May 2019, 206-215
Submission history
From: Cynthia Rudin [ view email ]
[v1] Mon, 26 Nov 2018 03:00:25 UTC (2,019 KB)
[v2] Wed, 5 Dec 2018 04:09:42 UTC (2,024 KB)
[v3] Sun, 22 Sep 2019 03:05:09 UTC (1,087 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Stop Explaining Black Box Machine Learning Models for High Stakes Decisions and Use Interpretable Models Instead, by Cynthia Rudin
    PDF
    Other formats 

Current browse context:
stat.ML
< prev   |   next >
new | recent | 1811
Change to browse by:
cs
cs.LG
stat
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

2 blog links
( what is this? )
a export BibTeX citation Loading...
Bookmark
BibSonomy logo Mendeley logo Reddit logo ScienceWISE logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

