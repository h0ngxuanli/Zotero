
[CSDN首页]

    博客
    下载
    学习
    社区
    falsefalse
    GitCode
    InsCode 

搜索
会员中心
消息
历史
创作中心
发布
YOLOv5的Tricks | 【Trick12】YOLOv5使用的数据增强方法汇总
Clichong 已于 2022-08-07 17:59:20 修改 18126 收藏 274
分类专栏： # 目标检测YOLOv5技巧汇总 文章标签： 深度学习 人工智能 数据增强 yolov5 目标检测
版权
目标检测YOLOv5技巧汇总 专栏收录该内容
15 篇文章 117 订阅
订阅专栏

如有错误，恳请指出。

时隔两个多月重新看 yolov5 的代码显然开始力不从心，当时应该一鼓作气的整理完的。在专栏前面的内容一直介绍的是yolov5训练时候使用的一些技巧， 这里用这篇博客最后归纳一下yolov5在数据增强上所使用的技巧。

在yolov3-spp专栏的时候，我介绍过yolov3-spp大致所使用的一些 数据增强 的方法：

    数据增强——Mosaic（马赛克）

    数据增强——随机旋转、平移、缩放、错切、hsv增强

在之前详细的介绍过代码，而在yolov5这里，其实代码是类似的，甚至函数的名字都没有变化，看过源码的朋友就可能知道了，改变的地方其实不是很多，所以这里就不再详细介绍代码的细节了，只是总结一下使用的数据增强。

文章目录

    0. 自定义数据集的整体架构
    1. Mosaic数据增强
    2. Copy paste数据增强
    3. Random affine仿射变换
    4. MixUp数据增强
    5. HSV随机增强图像
    6. 随机水平翻转
    7. Cutout数据增强
    8. Albumentations数据增强工具包 

0. 自定义数据集的整体架构

项目中，使用 create_dataloader 函数构建 dataloader 与 dataset ，这个部分是整个算法的核心部分之一。实现数据增强的方法就是在构建 dataset 中设置的。

    create_dataloader函数 

 def create_dataloader ( path , imgsz , batch_size , stride , single_cls = False , hyp = None , augment = False , cache = False , pad = 0.0 , rect = False , rank = - 1 , workers = 8 , image_weights = False , quad = False , prefix = '' ) : # Make sure only the first process in DDP process the dataset first, and the following others can use the cache with torch_distributed_zero_first ( rank ) : dataset = LoadImagesAndLabels ( path , imgsz , batch_size , augment = augment , # augment images hyp = hyp , # augmentation hyperparameters rect = rect , # rectangular training cache_images = cache , single_cls = single_cls , stride = int ( stride ) , pad = pad , image_weights = image_weights , prefix = prefix ) batch_size = min ( batch_size , len ( dataset ) ) # 这里对num_worker进行更改 # nw = min([os.cpu_count(), batch_size if batch_size > 1 else 0, workers]) # number of workers nw = 0 # 可以适当提高这个参数0, 2, 4, 8, 16… sampler = torch . utils . data . distributed . DistributedSampler ( dataset ) if rank != - 1 else None loader = torch . utils . data . DataLoader if image_weights else InfiniteDataLoader # Use torch.utils.data.DataLoader() if dataset.properties will update during training else InfiniteDataLoader() dataloader = loader ( dataset , batch_size = batch_size , num_workers = nw , sampler = sampler , pin_memory = True , collate_fn = LoadImagesAndLabels . collate_fn4 if quad else LoadImagesAndLabels . collate_fn ) return dataloader , dataset
 

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31

 

可以看见， 在构建 dataloader 的时候，还对batch数据进行了设置，为其设置了批处理的 collate_fn 函数 。核心重点，就是 LoadImagesAndLabels 函数，自定义了数据集的处理过程。下面详细对其分析。

    LoadImagesAndLabels函数 

 class LoadImagesAndLabels ( Dataset ) : # YOLOv5 train_loader/val_loader, loads images and labels for training and validation cache_version = 0.5 # dataset labels *.cache version def __init__ ( self , path , img_size = 640 , batch_size = 16 , augment = False , hyp = None , rect = False , image_weights = False , cache_images = False , single_cls = False , stride = 32 , pad = 0.0 , prefix = '' ) : self . img_size = img_size self . augment = augment self . hyp = hyp self . image_weights = image_weights self . rect = False if image_weights else rect self . mosaic = self . augment and not self . rect # load 4 images at a time into a mosaic (only during training) self . mosaic_border = [ - img_size // 2 , - img_size // 2 ] self . stride = stride self . path = path self . albumentations = Albumentations ( ) if augment else None . . . . # 下面省略了许多步骤，不过无伤大雅 . . . . def __len__ ( self ) : return len ( self . img_files ) # def __iter__(self): # self.count = -1 # print('ran dataset iter') # #self.shuffled_vector = np.random.permutation(self.nF) if self.augment else np.arange(self.nF) # return self def __getitem__ ( self , index ) : index = self . indices [ index ] # linear, shuffled, or image_weights hyp = self . hyp mosaic = self . mosaic and random . random ( ) < hyp [ 'mosaic' ] if mosaic : # Load mosaic img , labels = load_mosaic ( self , index ) # use load_mosaic4 # img, labels = load_mosaic9(self, index) # use load_mosaic9 shapes = None # MixUp augmentation if random . random ( ) < hyp [ 'mixup' ] : img , labels = mixup ( img , labels , * load_mosaic ( self , random . randint ( 0 , self . n - 1 ) ) ) # img, labels = mixup(img, labels, *load_mosaic9(self, random.randint(0, self.n - 1))) else : # Load image img , ( h0 , w0 ) , ( h , w ) = load_image ( self , index ) # Letterbox shape = self . batch_shapes [ self . batch [ index ] ] if self . rect else self . img_size # final letterboxed shape img , ratio , pad = letterbox ( img , shape , auto = False , scaleup = self . augment ) shapes = ( h0 , w0 ) , ( ( h / h0 , w / w0 ) , pad ) # for COCO mAP rescaling labels = self . labels [ index ] . copy ( ) if labels . size : # normalized xywh to pixel xyxy format labels [ : , 1 : ] = xywhn2xyxy ( labels [ : , 1 : ] , ratio [ 0 ] * w , ratio [ 1 ] * h , padw = pad [ 0 ] , padh = pad [ 1 ] ) if self . augment : img , labels = random_perspective ( img , labels , degrees = hyp [ 'degrees' ] , translate = hyp [ 'translate' ] , scale = hyp [ 'scale' ] , shear = hyp [ 'shear' ] , perspective = hyp [ 'perspective' ] ) nl = len ( labels ) # number of labels if nl : labels [ : , 1 : 5 ] = xyxy2xywhn ( labels [ : , 1 : 5 ] , w = img . shape [ 1 ] , h = img . shape [ 0 ] , clip = True , eps = 1E-3 ) # create_dataloader to set augment if self . augment : # Albumentations img , labels = self . albumentations ( img , labels ) nl = len ( labels ) # update after albumentations # HSV color-space # augment_hsv(img, hgain=hyp['hsv_h'], sgain=hyp['hsv_s'], vgain=hyp['hsv_v']) # Flip up-down if random . random ( ) < hyp [ 'flipud' ] : img = np . flipud ( img ) if nl : labels [ : , 2 ] = 1 - labels [ : , 2 ] # Flip left-right if random . random ( ) < hyp [ 'fliplr' ] : img = np . fliplr ( img ) if nl : labels [ : , 1 ] = 1 - labels [ : , 1 ] # Cutouts # labels = cutout(img, labels, p=0.5) labels_out = torch . zeros ( ( nl , 6 ) ) if nl : labels_out [ : , 1 : ] = torch . from_numpy ( labels ) # Convert img = img . transpose ( ( 2 , 0 , 1 ) ) [ : : - 1 ] # HWC to CHW, BGR to RGB img = np . ascontiguousarray ( img ) return torch . from_numpy ( img ) , labels_out , self . img_files [ index ] , shapes @staticmethod def collate_fn ( batch ) : img , label , path , shapes = zip ( * batch ) # transposed for i , l in enumerate ( label ) : l [ : , 0 ] = i # add target image index for build_targets() return torch . stack ( img , 0 ) , torch . cat ( label , 0 ) , path , shapes @staticmethod def collate_fn4 ( batch ) : img , label , path , shapes = zip ( * batch ) # transposed n = len ( shapes ) // 4 img4 , label4 , path4 , shapes4 = [ ] , [ ] , path [ : n ] , shapes [ : n ] ho = torch . tensor ( [ [ 0. , 0 , 0 , 1 , 0 , 0 ] ] ) wo = torch . tensor ( [ [ 0. , 0 , 1 , 0 , 0 , 0 ] ] ) s = torch . tensor ( [ [ 1 , 1 , .5 , .5 , .5 , .5 ] ] ) # scale for i in range ( n ) : # zidane torch.zeros(16,3,720,1280) # BCHW i *= 4 if random . random ( ) < 0.5 : im = F . interpolate ( img [ i ] . unsqueeze ( 0 ) . float ( ) , scale_factor = 2. , mode = 'bilinear' , align_corners = False ) [ 0 ] . type ( img [ i ] . type ( ) ) l = label [ i ] else : im = torch . cat ( ( torch . cat ( ( img [ i ] , img [ i + 1 ] ) , 1 ) , torch . cat ( ( img [ i + 2 ] , img [ i + 3 ] ) , 1 ) ) , 2 ) l = torch . cat ( ( label [ i ] , label [ i + 1 ] + ho , label [ i + 2 ] + wo , label [ i + 3 ] + ho + wo ) , 0 ) * s img4 . append ( im ) label4 . append ( l ) for i , l in enumerate ( label4 ) : l [ : , 0 ] = i # add target image index for build_targets() return torch . stack ( img4 , 0 ) , torch . cat ( label4 , 0 ) , path4 , shapes4
 
 

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31
    32
    33
    34
    35
    36
    37
    38
    39
    40
    41
    42
    43
    44
    45
    46
    47
    48
    49
    50
    51
    52
    53
    54
    55
    56
    57
    58
    59
    60
    61
    62
    63
    64
    65
    66
    67
    68
    69
    70
    71
    72
    73
    74
    75
    76
    77
    78
    79
    80
    81
    82
    83
    84
    85
    86
    87
    88
    89
    90
    91
    92
    93
    94
    95
    96
    97
    98
    99
    100
    101
    102
    103
    104
    105
    106
    107
    108
    109
    110
    111
    112
    113
    114
    115
    116
    117
    118
    119
    120
    121
    122
    123
    124
    125
    126
    127
    128
    129
    130
    131
    132
    133
    134
    135
    136

 

大致的函数代码如上所示，但是其实有很多的繁琐步骤。 self.rect 是都进行矩形训练，但是一般来说是进行矩形推理来加快推理速度。 cache_image 是为了缓存图像，以空间换时间。这些内容我都省略掉，没有贴上来。

自定义数据集的重点是 __getitem__ 函数，各种数据增强的方式就是在这里进行的 。所以我对部分代码进行了省略，只贴出了重要的部分。
1. Mosaic数据增强

这个部分之前已经介绍过了，不过值得一提的是，这里 yolov5还额外提出了一个9图的mosaic操作 ，就是把之前的4个图像换成了9张图像，拼接在一起处理， 图像更大了而且label也更多，训练一张这样的拼接图像等同与训练了9张小图。

    操作示例 

在这里插入图片描述

    Mosaic（4张）实现代码 

 def load_mosaic ( self , index ) : # YOLOv5 4-mosaic loader. Loads 1 image + 3 random images into a 4-image mosaic labels4 , segments4 = [ ] , [ ] s = self . img_size yc , xc = [ int ( random . uniform ( - x , 2 * s + x ) ) for x in self . mosaic_border ] # mosaic center x, y indices = [ index ] + random . choices ( self . indices , k = 3 ) # 3 additional image indices random . shuffle ( indices ) for i , index in enumerate ( indices ) : # Load image img , _ , ( h , w ) = load_image ( self , index ) # place img in img4 if i == 0 : # top left img4 = np . full ( ( s * 2 , s * 2 , img . shape [ 2 ] ) , 114 , dtype = np . uint8 ) # base image with 4 tiles x1a , y1a , x2a , y2a = max ( xc - w , 0 ) , max ( yc - h , 0 ) , xc , yc # xmin, ymin, xmax, ymax (large image) x1b , y1b , x2b , y2b = w - ( x2a - x1a ) , h - ( y2a - y1a ) , w , h # xmin, ymin, xmax, ymax (small image) elif i == 1 : # top right x1a , y1a , x2a , y2a = xc , max ( yc - h , 0 ) , min ( xc + w , s * 2 ) , yc x1b , y1b , x2b , y2b = 0 , h - ( y2a - y1a ) , min ( w , x2a - x1a ) , h elif i == 2 : # bottom left x1a , y1a , x2a , y2a = max ( xc - w , 0 ) , yc , xc , min ( s * 2 , yc + h ) x1b , y1b , x2b , y2b = w - ( x2a - x1a ) , 0 , w , min ( y2a - y1a , h ) elif i == 3 : # bottom right x1a , y1a , x2a , y2a = xc , yc , min ( xc + w , s * 2 ) , min ( s * 2 , yc + h ) x1b , y1b , x2b , y2b = 0 , 0 , min ( w , x2a - x1a ) , min ( y2a - y1a , h ) img4 [ y1a : y2a , x1a : x2a ] = img [ y1b : y2b , x1b : x2b ] # img4[ymin:ymax, xmin:xmax] padw = x1a - x1b padh = y1a - y1b # Labels labels , segments = self . labels [ index ] . copy ( ) , self . segments [ index ] . copy ( ) if labels . size : labels [ : , 1 : ] = xywhn2xyxy ( labels [ : , 1 : ] , w , h , padw , padh ) # normalized xywh to pixel xyxy format segments = [ xyn2xy ( x , w , h , padw , padh ) for x in segments ] labels4 . append ( labels ) segments4 . extend ( segments ) # Concat/clip labels labels4 = np . concatenate ( labels4 , 0 ) for x in ( labels4 [ : , 1 : ] , * segments4 ) : np . clip ( x , 0 , 2 * s , out = x ) # clip when using random_perspective() # img4, labels4 = replicate(img4, labels4) # replicate # Augment img4 , labels4 , segments4 = copy_paste ( img4 , labels4 , segments4 , p = self . hyp [ 'copy_paste' ] ) img4 , labels4 = random_perspective ( img4 , labels4 , segments4 , degrees = self . hyp [ 'degrees' ] , translate = self . hyp [ 'translate' ] , scale = self . hyp [ 'scale' ] , shear = self . hyp [ 'shear' ] , perspective = self . hyp [ 'perspective' ] , border = self . mosaic_border ) # border to remove return img4 , labels4
 
 

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31
    32
    33
    34
    35
    36
    37
    38
    39
    40
    41
    42
    43
    44
    45
    46
    47
    48
    49
    50
    51
    52
    53
    54
    55

 

    Mosaic（9张）实现代码 

 def load_mosaic9 ( self , index ) : # YOLOv5 9-mosaic loader. Loads 1 image + 8 random images into a 9-image mosaic labels9 , segments9 = [ ] , [ ] s = self . img_size indices = [ index ] + random . choices ( self . indices , k = 8 ) # 8 additional image indices random . shuffle ( indices ) for i , index in enumerate ( indices ) : # Load image img , _ , ( h , w ) = load_image ( self , index ) # place img in img9 if i == 0 : # center img9 = np . full ( ( s * 3 , s * 3 , img . shape [ 2 ] ) , 114 , dtype = np . uint8 ) # base image with 4 tiles h0 , w0 = h , w c = s , s , s + w , s + h # xmin, ymin, xmax, ymax (base) coordinates elif i == 1 : # top c = s , s - h , s + w , s elif i == 2 : # top right c = s + wp , s - h , s + wp + w , s elif i == 3 : # right c = s + w0 , s , s + w0 + w , s + h elif i == 4 : # bottom right c = s + w0 , s + hp , s + w0 + w , s + hp + h elif i == 5 : # bottom c = s + w0 - w , s + h0 , s + w0 , s + h0 + h elif i == 6 : # bottom left c = s + w0 - wp - w , s + h0 , s + w0 - wp , s + h0 + h elif i == 7 : # left c = s - w , s + h0 - h , s , s + h0 elif i == 8 : # top left c = s - w , s + h0 - hp - h , s , s + h0 - hp padx , pady = c [ : 2 ] x1 , y1 , x2 , y2 = [ max ( x , 0 ) for x in c ] # allocate coords # Labels labels , segments = self . labels [ index ] . copy ( ) , self . segments [ index ] . copy ( ) if labels . size : labels [ : , 1 : ] = xywhn2xyxy ( labels [ : , 1 : ] , w , h , padx , pady ) # normalized xywh to pixel xyxy format segments = [ xyn2xy ( x , w , h , padx , pady ) for x in segments ] labels9 . append ( labels ) segments9 . extend ( segments ) # Image img9 [ y1 : y2 , x1 : x2 ] = img [ y1 - pady : , x1 - padx : ] # img9[ymin:ymax, xmin:xmax] hp , wp = h , w # height, width previous # Offset yc , xc = [ int ( random . uniform ( 0 , s ) ) for _ in self . mosaic_border ] # mosaic center x, y img9 = img9 [ yc : yc + 2 * s , xc : xc + 2 * s ] # Concat/clip labels labels9 = np . concatenate ( labels9 , 0 ) labels9 [ : , [ 1 , 3 ] ] -= xc labels9 [ : , [ 2 , 4 ] ] -= yc c = np . array ( [ xc , yc ] ) # centers segments9 = [ x - c for x in segments9 ] for x in ( labels9 [ : , 1 : ] , * segments9 ) : np . clip ( x , 0 , 2 * s , out = x ) # clip when using random_perspective() # img9, labels9 = replicate(img9, labels9) # replicate # Augment img9 , labels9 = random_perspective ( img9 , labels9 , segments9 , degrees = self . hyp [ 'degrees' ] , translate = self . hyp [ 'translate' ] , scale = self . hyp [ 'scale' ] , shear = self . hyp [ 'shear' ] , perspective = self . hyp [ 'perspective' ] , border = self . mosaic_border ) # border to remove return img9 , labels9
 
 

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31
    32
    33
    34
    35
    36
    37
    38
    39
    40
    41
    42
    43
    44
    45
    46
    47
    48
    49
    50
    51
    52
    53
    54
    55
    56
    57
    58
    59
    60
    61
    62
    63
    64
    65
    66
    67
    68
    69
    70
    71
    72

 

使用这两个方法的方式很简单，只需要改变两个地方就可以了，如下所示：

 mosaic = self . mosaic and random . random ( ) < hyp [ 'mosaic' ] if mosaic : # Load mosaic img , labels = load_mosaic ( self , index ) # use load_mosaic4 # img, labels = load_mosaic9(self, index) # use load_mosaic9 shapes = None # MixUp augmentation if random . random ( ) < hyp [ 'mixup' ] : img , labels = mixup ( img , labels , * load_mosaic ( self , random . randint ( 0 , self . n - 1 ) ) ) # img, labels = mixup(img, labels, *load_mosaic9(self, random.randint(0, self.n - 1)))
 

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11

 

需要注意，这里的Mosaic函数并不只有Mosaic操作，还包含了仿射变换 random_perspective 与 copy_paste 操作，下面会介绍到。
2. Copy paste数据增强

中文名叫复制粘贴大法，将部分目标随机的粘贴到图片中，前提是数据要有segments数据才行，即每个目标的实例分割信息。下面是Copy paste原论文中的示意图。

    操作示例 

在这里插入图片描述

    实现代码 

 def copy_paste ( im , labels , segments , p = 0.5 ) : # Implement Copy-Paste augmentation https://arxiv.org/abs/2012.07177, labels as nx5 np.array(cls, xyxy) n = len ( segments ) if p and n : h , w , c = im . shape # height, width, channels im_new = np . zeros ( im . shape , np . uint8 ) for j in random . sample ( range ( n ) , k = round ( p * n ) ) : l , s = labels [ j ] , segments [ j ] box = w - l [ 3 ] , l [ 2 ] , w - l [ 1 ] , l [ 4 ] ioa = bbox_ioa ( box , labels [ : , 1 : 5 ] ) # intersection over area if ( ioa < 0.30 ) . all ( ) : # allow 30% obscuration of existing labels labels = np . concatenate ( ( labels , [ [ l [ 0 ] , * box ] ] ) , 0 ) segments . append ( np . concatenate ( ( w - s [ : , 0 : 1 ] , s [ : , 1 : 2 ] ) , 1 ) ) cv2 . drawContours ( im_new , [ segments [ j ] . astype ( np . int32 ) ] , - 1 , ( 255 , 255 , 255 ) , cv2 . FILLED ) result = cv2 . bitwise_and ( src1 = im , src2 = im_new ) result = cv2 . flip ( result , 1 ) # augment segments (flip left-right) i = result > 0 # pixels to replace # i[:, :] = result.max(2).reshape(h, w, 1) # act over ch im [ i ] = result [ i ] # cv2.imwrite('debug.jpg', im) # debug return im , labels , segments
 
 

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22

 

在加载马赛克数据增强的时候，是自动使用这个方法的：

 # Augment img4 , labels4 , segments4 = copy_paste ( img4 , labels4 , segments4 , p = self . hyp [ 'copy_paste' ] )
 

    1
    2

 

如果选择不用，可以直接选择注释掉即可。一般来说，在训练自定义数据集的时候，肯定没有相关的掩码，所以其实也没有用到。
3. Random affine仿射变换

yolov5的仿射变换包含随机旋转、平移、缩放、错切操作，和yolov3-spp一样，代码都没有改变。据配置文件里的超参数发现只使用了Scale和Translation即缩放和平移。

    操作示例 

在这里插入图片描述

    实现代码 

 def random_perspective ( im , targets = ( ) , segments = ( ) , degrees = 10 , translate = .1 , scale = .1 , shear = 10 , perspective = 0.0 , border = ( 0 , 0 ) ) : # torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(.1, .1), scale=(.9, 1.1), shear=(-10, 10)) # targets = [cls, xyxy] height = im . shape [ 0 ] + border [ 0 ] * 2 # shape(h,w,c) width = im . shape [ 1 ] + border [ 1 ] * 2 # Center C = np . eye ( 3 ) C [ 0 , 2 ] = - im . shape [ 1 ] / 2 # x translation (pixels) C [ 1 , 2 ] = - im . shape [ 0 ] / 2 # y translation (pixels) # Perspective P = np . eye ( 3 ) P [ 2 , 0 ] = random . uniform ( - perspective , perspective ) # x perspective (about y) P [ 2 , 1 ] = random . uniform ( - perspective , perspective ) # y perspective (about x) # Rotation and Scale R = np . eye ( 3 ) a = random . uniform ( - degrees , degrees ) # a += random.choice([-180, -90, 0, 90]) # add 90deg rotations to small rotations s = random . uniform ( 1 - scale , 1 + scale ) # s = 2 ** random.uniform(-scale, scale) R [ : 2 ] = cv2 . getRotationMatrix2D ( angle = a , center = ( 0 , 0 ) , scale = s ) # Shear S = np . eye ( 3 ) S [ 0 , 1 ] = math . tan ( random . uniform ( - shear , shear ) * math . pi / 180 ) # x shear (deg) S [ 1 , 0 ] = math . tan ( random . uniform ( - shear , shear ) * math . pi / 180 ) # y shear (deg) # Translation T = np . eye ( 3 ) T [ 0 , 2 ] = random . uniform ( 0.5 - translate , 0.5 + translate ) * width # x translation (pixels) T [ 1 , 2 ] = random . uniform ( 0.5 - translate , 0.5 + translate ) * height # y translation (pixels) # Combined rotation matrix M = T @ S @ R @ P @ C # order of operations (right to left) is IMPORTANT if ( border [ 0 ] != 0 ) or ( border [ 1 ] != 0 ) or ( M != np . eye ( 3 ) ) . any ( ) : # image changed if perspective : im = cv2 . warpPerspective ( im , M , dsize = ( width , height ) , borderValue = ( 114 , 114 , 114 ) ) else : # affine im = cv2 . warpAffine ( im , M [ : 2 ] , dsize = ( width , height ) , borderValue = ( 114 , 114 , 114 ) ) # Visualize # import matplotlib.pyplot as plt # ax = plt.subplots(1, 2, figsize=(12, 6))[1].ravel() # ax[0].imshow(im[:, :, ::-1]) # base # ax[1].imshow(im2[:, :, ::-1]) # warped # Transform label coordinates n = len ( targets ) if n : use_segments = any ( x . any ( ) for x in segments ) new = np . zeros ( ( n , 4 ) ) if use_segments : # warp segments segments = resample_segments ( segments ) # upsample for i , segment in enumerate ( segments ) : xy = np . ones ( ( len ( segment ) , 3 ) ) xy [ : , : 2 ] = segment xy = xy @ M . T # transform xy = xy [ : , : 2 ] / xy [ : , 2 : 3 ] if perspective else xy [ : , : 2 ] # perspective rescale or affine # clip new [ i ] = segment2box ( xy , width , height ) else : # warp boxes xy = np . ones ( ( n * 4 , 3 ) ) xy [ : , : 2 ] = targets [ : , [ 1 , 2 , 3 , 4 , 1 , 4 , 3 , 2 ] ] . reshape ( n * 4 , 2 ) # x1y1, x2y2, x1y2, x2y1 xy = xy @ M . T # transform xy = ( xy [ : , : 2 ] / xy [ : , 2 : 3 ] if perspective else xy [ : , : 2 ] ) . reshape ( n , 8 ) # perspective rescale or affine # create new boxes x = xy [ : , [ 0 , 2 , 4 , 6 ] ] y = xy [ : , [ 1 , 3 , 5 , 7 ] ] new = np . concatenate ( ( x . min ( 1 ) , y . min ( 1 ) , x . max ( 1 ) , y . max ( 1 ) ) ) . reshape ( 4 , n ) . T # clip new [ : , [ 0 , 2 ] ] = new [ : , [ 0 , 2 ] ] . clip ( 0 , width ) new [ : , [ 1 , 3 ] ] = new [ : , [ 1 , 3 ] ] . clip ( 0 , height ) # filter candidates i = box_candidates ( box1 = targets [ : , 1 : 5 ] . T * s , box2 = new . T , area_thr = 0.01 if use_segments else 0.10 ) targets = targets [ i ] targets [ : , 1 : 5 ] = new [ i ] return im , targets
 
 

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31
    32
    33
    34
    35
    36
    37
    38
    39
    40
    41
    42
    43
    44
    45
    46
    47
    48
    49
    50
    51
    52
    53
    54
    55
    56
    57
    58
    59
    60
    61
    62
    63
    64
    65
    66
    67
    68
    69
    70
    71
    72
    73
    74
    75
    76
    77
    78
    79
    80
    81
    82
    83
    84
    85
    86
    87

 

在加载马赛克数据增强的时候，同样是自动默认同时使用这个方法的。如果不想使用，直接注释即可。

 # Augment img4 , labels4 , segments4 = copy_paste ( img4 , labels4 , segments4 , p = self . hyp [ 'copy_paste' ] ) img4 , labels4 = random_perspective ( img4 , labels4 , segments4 , degrees = self . hyp [ 'degrees' ] , translate = self . hyp [ 'translate' ] , scale = self . hyp [ 'scale' ] , shear = self . hyp [ 'shear' ] , perspective = self . hyp [ 'perspective' ] , border = self . mosaic_border ) # border to remove
 

    1
    2
    3
    4
    5
    6
    7
    8
    9

 

而且，如果选择不适应马赛克数据增强，而是选择其他的数据增强方式，仿射变换同样会被使用到。

 if mosaic : # Load mosaic img , labels = load_mosaic ( self , index ) # use load_mosaic4 . . . else : # Load image img , ( h0 , w0 ) , ( h , w ) = load_image ( self , index ) . . . if self . augment : img , labels = random_perspective ( img , labels , degrees = hyp [ 'degrees' ] , translate = hyp [ 'translate' ] , scale = hyp [ 'scale' ] , shear = hyp [ 'shear' ] , perspective = hyp [ 'perspective' ] )
 
 

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17

 

其原理，可以参考之前的文章： 数据增强 | 旋转、平移、缩放、错切、HSV增强
4. MixUp数据增强

这个比较熟悉了，就是调整透明度两张图像叠加在一起。代码中只有较大的模型才使用到了MixUp，而且每次只有10%的概率会使用到。

    操作示例 

在这里插入图片描述

    实现代码 

 def mixup ( im , labels , im2 , labels2 ) : # Applies MixUp augmentation https://arxiv.org/pdf/1710.09412.pdf r = np . random . beta ( 32.0 , 32.0 ) # mixup ratio, alpha=beta=32.0 im = ( im * r + im2 * ( 1 - r ) ) . astype ( np . uint8 ) labels = np . concatenate ( ( labels , labels2 ) , 0 ) return im , labels
 

    1
    2
    3
    4
    5
    6

 

可以看见，实现只需要几行代码，比较简单的。这个方法在多数的计算机视觉模型中都有使用到。

在调用马赛克处理的时候，MixUp有一定的几率会被使用到

 # MixUp augmentation if random . random ( ) < hyp [ 'mixup' ] : img , labels = mixup ( img , labels , * load_mosaic ( self , random . randint ( 0 , self . n - 1 ) ) ) # img, labels = mixup(img, labels, *load_mosaic9(self, random.randint(0, self.n - 1)))
 

    1
    2
    3
    4

 

5. HSV随机增强图像

随机增强图像HSV在 数据增强 | 旋转、平移、缩放、错切、HSV增强 这篇文章中也有介绍到。不过在yolov5中，这里默认是注释掉不使用的。

    操作示例 

在这里插入图片描述

    实现代码 

 def augment_hsv ( im , hgain = 0.5 , sgain = 0.5 , vgain = 0.5 ) : # HSV color-space augmentation if hgain or sgain or vgain : r = np . random . uniform ( - 1 , 1 , 3 ) * [ hgain , sgain , vgain ] + 1 # random gains hue , sat , val = cv2 . split ( cv2 . cvtColor ( im , cv2 . COLOR_BGR2HSV ) ) dtype = im . dtype # uint8 x = np . arange ( 0 , 256 , dtype = r . dtype ) lut_hue = ( ( x * r [ 0 ] ) % 180 ) . astype ( dtype ) lut_sat = np . clip ( x * r [ 1 ] , 0 , 255 ) . astype ( dtype ) lut_val = np . clip ( x * r [ 2 ] , 0 , 255 ) . astype ( dtype ) im_hsv = cv2 . merge ( ( cv2 . LUT ( hue , lut_hue ) , cv2 . LUT ( sat , lut_sat ) , cv2 . LUT ( val , lut_val ) ) ) cv2 . cvtColor ( im_hsv , cv2 . COLOR_HSV2BGR , dst = im ) # no return needed
 

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14

 

在选择进行数据增强的配置中，默认注释不使用，如下所示：

 # create_dataloader to set augment if self . augment : # Albumentations img , labels = self . albumentations ( img , labels ) nl = len ( labels ) # update after albumentations # HSV color-space # augment_hsv(img, hgain=hyp['hsv_h'], sgain=hyp['hsv_s'], vgain=hyp['hsv_v'])
 

    1
    2
    3
    4
    5
    6
    7
    8

 

6. 随机水平翻转

这个就是如字面意思，随机上下左右的水平翻转

    操作示例 

在这里插入图片描述

    实现代码 

 # Flip up-down if random . random ( ) < hyp [ 'flipud' ] : img = np . flipud ( img ) if nl : labels [ : , 2 ] = 1 - labels [ : , 2 ] # Flip left-right if random . random ( ) < hyp [ 'fliplr' ] : img = np . fliplr ( img ) if nl : labels [ : , 1 ] = 1 - labels [ : , 1 ]
 

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11

 

7. Cutout数据增强

Cutout是一种新的正则化方法。训练时随机把图片的一部分减掉，这样能提高模型的鲁棒性。它的来源是计算机视觉任务中经常遇到的物体遮挡问题。通过cutout生成一些类似被遮挡的物体，不仅可以让模型在遇到遮挡问题时表现更好，还能让模型在做决定时更多地考虑环境。

Cutout数据增强在之前也见过很多次了。在yolov5的代码中默认也是不启用的。

    操作实例 

在这里插入图片描述

    实现代码 

 def cutout ( im , labels , p = 0.5 ) : # Applies image cutout augmentation https://arxiv.org/abs/1708.04552 if random . random ( ) < p : h , w = im . shape [ : 2 ] scales = [ 0.5 ] * 1 + [ 0.25 ] * 2 + [ 0.125 ] * 4 + [ 0.0625 ] * 8 + [ 0.03125 ] * 16 # image size fraction for s in scales : mask_h = random . randint ( 1 , int ( h * s ) ) # create random masks mask_w = random . randint ( 1 , int ( w * s ) ) # box xmin = max ( 0 , random . randint ( 0 , w ) - mask_w // 2 ) ymin = max ( 0 , random . randint ( 0 , h ) - mask_h // 2 ) xmax = min ( w , xmin + mask_w ) ymax = min ( h , ymin + mask_h ) # apply random color mask im [ ymin : ymax , xmin : xmax ] = [ random . randint ( 64 , 191 ) for _ in range ( 3 ) ] # return unobscured labels if len ( labels ) and s > 0.03 : box = np . array ( [ xmin , ymin , xmax , ymax ] , dtype = np . float32 ) ioa = bbox_ioa ( box , labels [ : , 1 : 5 ] ) # intersection over area labels = labels [ ioa < 0.60 ] # remove >60% obscured labels return labels
 
 

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25

 

源码中默认是不启动的

 # Cutouts # labels = cutout(img, labels, p=0.5)
 

    1
    2

 

8. Albumentations数据增强工具包

Albumentations 数据增强工具包在之前已经介绍过，见： Yolo系列 | Yolov4v5的模型结构与正负样本匹配

    github地址：https://github.com/albumentations-team/albumentations
    docs使用文档：https://albumentations.ai/docs

其涵盖了绝大部分的数据增强方式，如下：

在这里插入图片描述

    yolov5代码 

 class Albumentations : # YOLOv5 Albumentations class (optional, only used if package is installed) def __init__ ( self ) : self . transform = None try : import albumentations as A check_version ( A . __version__ , '1.0.3' ) # version requirement self . transform = A . Compose ( [ A . Blur ( p = 0.01 ) , A . MedianBlur ( p = 0.01 ) , A . ToGray ( p = 0.01 ) , A . CLAHE ( p = 0.01 ) , A . RandomBrightnessContrast ( p = 0.0 ) , A . RandomGamma ( p = 0.0 ) , A . ImageCompression ( quality_lower = 75 , p = 0.0 ) ] , bbox_params = A . BboxParams ( format = 'yolo' , label_fields = [ 'class_labels' ] ) ) logging . info ( colorstr ( 'albumentations: ' ) + ', ' . join ( f' { x } ' for x in self . transform . transforms if x . p ) ) except ImportError : # package not installed, skip pass except Exception as e : logging . info ( colorstr ( 'albumentations: ' ) + f' { e } ' ) def __call__ ( self , im , labels , p = 1.0 ) : if self . transform and random . random ( ) < p : new = self . transform ( image = im , bboxes = labels [ : , 1 : ] , class_labels = labels [ : , 0 ] ) # transformed im , labels = new [ 'image' ] , np . array ( [ [ c , * b ] for c , b in zip ( new [ 'class_labels' ] , new [ 'bboxes' ] ) ] ) return im , labels
 
 

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28

 

    自己调用代码 

 import albumentations as A class Albumentations : # YOLOv5 Albumentations class (optional, only used if package is installed) def __init__ ( self ) : self . transform = A . Compose ( [ A . Blur ( p = 0.15 ) , # 随机模糊 A . GaussianBlur ( p = 0.15 ) , # 高斯滤波器模糊 A . MedianBlur ( p = 0.15 ) , # 中值滤波器模糊输入图像 A . GaussNoise ( p = 0.15 ) , # 高斯噪声应用于输入图像 A . InvertImg ( 0.15 ) , # 通过从255中减去像素值来反转输入图像 A . ToGray ( p = 0.15 ) , # 将输入的 RGB 图像转换为灰度 A . CLAHE ( p = 0.15 ) , # 自适应直方图均衡 A . ChannelShuffle ( p = 0.15 ) , # 随机重新排列输入 RGB 图像的通道 A . ColorJitter ( p = 0.25 ) , # 随机改变图像的亮度、对比度和饱和度 A . FancyPCA ( p = 0.25 ) , # 使用FancyPCA增强RGB图像 A . Sharpen ( p = 0.15 ) , # 锐化输入图像并将结果与​​原始图像叠加 A . HueSaturationValue ( p = 0.15 ) , # 随机改变输入图像的色调、饱和度和值 A . RandomBrightnessContrast ( p = 0.15 ) , # 随机改变输入图像的亮度和对比度 # 与random_perspective函数重复 # A.Rotate(limit=20, p=0.35), # 随机旋转 # A.HorizontalFlip(p=0.35), # 水平翻转 # A.VerticalFlip(p=0.35), # 垂直翻转 # A.Perspective(p=0.35), # 透视变换 A . ImageCompression ( quality_lower = 75 , p = 0.01 ) ] , # 减少图像的 Jpeg、WebP 压缩 # yolo格式的边界框坐标的格式: [x_center, y_center, width, height] bbox_params = A . BboxParams ( format = 'yolo' , label_fields = [ 'class_labels' ] ) ) logging . info ( colorstr ( 'albumentations: ' ) + ', ' . join ( f' { x } ' for x in self . transform . transforms if x . p ) ) def __call__ ( self , im , labels , p = 1.0 ) : if self . transform and random . random ( ) < p : new = self . transform ( image = im , bboxes = labels [ : , 1 : ] , class_labels = labels [ : , 0 ] ) # transformed im , labels = new [ 'image' ] , np . array ( [ [ c , * b ] for c , b in zip ( new [ 'class_labels' ] , new [ 'bboxes' ] ) ] ) return im , labels
 
 

    1
    2
    3
    4
    5
    6
    7
    8
    9
    10
    11
    12
    13
    14
    15
    16
    17
    18
    19
    20
    21
    22
    23
    24
    25
    26
    27
    28
    29
    30
    31
    32
    33
    34
    35
    36
    37
    38
    39
    40

 

可以看见，使用方法类似于pytorch的transform。使用的方法是类似的。

不过， 在Albumentations提供的数据增强方式比pytorch官方的更多，使用也比较方便 。

参考资料：

1. YOLOv5网络详解

2. YOLOv5 (6.0/6.1) brief summary

3. Yolo系列 | Yolov4v5的模型结构与正负样本匹配

4. 数据增强 | 旋转、平移、缩放、错切、HSV增强

5. 【Trick7】数据增强——Mosaic（马赛克）

6. 【Trick8】数据增强——随机旋转、平移、缩放、错切、hsv增强
文章知识点与官方知识档案匹配，可进一步学习相关知识
Python入门技能树 人工智能 深度学习 322055 人正在系统学习中
Clichong
关注 关注

    30
    274
    打赏
    17

专栏目录
【 YOLOV5 -6.x讲解】 数据增强 方式介绍+代码实现
小李的研究生学习日记
07-11 1万+
数据增强 的作用：分割需要在像素级别进行标签标注，一些专业领域的图像标注，依赖于专业人士的知识素养，在数据集规模很小的情况，如何提高模型的表现力迁移学习：使得具有大量标注数据的源域帮助提升模型的训练效果 数据增强 学习到空间的不变形，像素级别的不变形特征都有限，利用平移，缩放，旋转，改变色调值等 方法 ，让模型见过各种类型的数据，提高模型在测试数据上的判别力同个batch里做rectangle宽高等比变换， 加快训练 ，对于多余的黑边做到最小，实现降低计算量。............
YOLOv5 数据增强 测试
03-29
对 YOLOv5 -6.1源码中的 数据增强 部分进行代码复现与测试
17  条评论
qq_48333434 热评
请问博主表情包 有yolov7的嘛
写评论
... yolov5 网络增加亮度 数据增强 方法 _ yolov5 数据增强 _大黑山修道的博客...
7-26
在 yolov5 中添加图像增强 在github上下载 yolov5 源码包; 然后再utils目录下的datasets.py文件 在def load_image(self, i):的函数中添加 数据增强 的函数: 如: defgamma_trans(img,gamma):''' 首先归一化到0-1范围,然后gamma作为指数值...
训练数据不够怎么造？yolo5 最有用的trick 之 数据增强 详解
OpenDataLab的博客
11-10 3129
yolo5应用的trick繁多，此本文将针对yolo5的 数据增强 方面进行详细解读
YOLOv5 数据增强 线下 数据增强 # 裁剪 平移 改变亮度 加噪声 旋转角 镜像
weixin_46135327的博客
06-09 123
xml_helper文件。
YOLOv5 数据增强 方法
weixin_35756373的博客
01-08 1992
YOLOv5 的 数据增强 方法 包括以下几种： 随机剪裁：随机从输入图像中剪裁出一块区域并将其作为新的输入。 随机翻转：随机将输入图像左右或上下翻转。 随机颜色变化：随机调整输入图像的对比度、亮度和饱和度。 随机加噪：在输入图像上随机添加噪声。 随机模糊： 使用 高斯模糊或中值滤波器对输入图像进行随机模糊。 通过这些 方法 ，可以在训练期间扩充数据集，从而使模型更加稳健。 ...
yolov5 启用 数据增强 、tensorboard可视化及cutout增强
小俊俊的博客
03-12 1万+
yolov5 启用 数据增强 与tensorboard可视化 一， yolov5 启用 数据增强 1.data目录下，有两个hyp的文件：data/hyp.scratch.yaml和data/hyp.finetune.yaml具体内容如下： # Hyperparameters for VOC fine-tuning # python train.py --batch 64 --cfg '' --weights yolov5 m.pt --data voc.yaml --img 512 --epochs 50 # See
YOLOv5 数据增强 data augmentation (七)
sebeefe的博客
03-02 3710
1. 数据增强 介绍 当我们训练集中的图片比较少时，容易造成网络的过拟合。为了避免这种情况一般我们要经过图像处理的 方法 ，人为地去增加些图片数据，这样就会增加我们可用图片的数目，减少过拟合的可能性。 可以通过像素级的剪裁(Crop)、旋转(Rotation)、反转(Flip)、色调(Hue)、饱和度(Saturation)、曝光量(Exposure)、宽高比(Aspect)来做 数据增强 。 另外还可以在图片级 数据增强 ，比如MixUp、CurMix、Mosaic、Blur 2.图片级像素增强 Mixup
YOLOV5 超参数设置与 数据增强 解析
qq_41627642的博客
06-23 2万+
无
Yolov5 (v6.1) 数据增强 方式解析
Blue Book Is All You Need
05-15 2万+
4-Mosaic 数据增强 /9-Mosaic 数据增强
Yolov5 数据增强 - Mosaic
qq_35326529的博客
12-15 3035
Mosaic
YOLO数据集实现 数据增强 的 方法 （裁剪、平移 、旋转、改变亮度、加噪声等）
最新发布
路人贾的博客
07-16 461
数据集样本太少怎么办？数据集优质图像不够怎么办？如何做到更好的数据预处理？一文带你学会 数据增强 ，还可实现带标签的扩充。
Yolov3_ tricks
03-08
YOLOV3的pytorch版本中嵌入了许多技巧 在Darknet上添加我的新模块很麻烦，然后我在Pytorch上实现了带有许多技巧的完整版yolov3 详尽的中文注释！ 表现 地图 车 人 自行车 官方基准 74.3％ 85.6％ 79.4％ 58.0％ ...
html-tips- tricks :我最喜欢HTML5技巧和窍门
03-18
html-tips- tricks HTML5并不是新事物。自初始版本（2014年10月）以来，我们一直在 使用 它的多个功能。作为#100DaysOfCode计划的一部分，我花了一些时间再次访问功能列表。看到我发现了什么？我还没有真正 使用 过它！在...
Python Tricks 使用 pywinrm 远程控制 Windows 主机的 方法
09-16
主要介绍了Python Tricks 使用 pywinrm 远程控制 Windows 主机的 方法 ，本文给大家介绍的非常详细，对大家的学习或工作具有一定的参考借鉴价值,需要的朋友可以参考下
yoloV4.pdf
04-29
yoloV4速度效率双提升。将 AP 和 FPS 分别提高了10%和12%。该论文是非常好的 目标检测 学习资料。详细讲解了各种 tricks 的效果。
手把手带你调参 YOLOv5 (v5.0-v7.0)（推理）
热门推荐
Blue Book Is All You Need
04-24 8万+
解析 YOLOv5 项目中detect.py文件27个参数含义
【 YOLOv5 -6.x】 数据增强 代码解析
weixin_43799388的博客
03-29 1万+
文章目录前言像素级 数据增强 HSV色域变换旋转Rotation缩放Scale翻转Flip平移Translate剪切Shear透视Perspective三种常用的图片级 数据增强 MixupCutoutCutmixMosaic 数据增强 完整代码及数据Reference 前言 本文 使用 的 YOLOv5 版本为v6.1，对 YOLOv5 -6.x网络结构还不熟悉的同学，可以移步至：【 YOLOv5 -6.x】网络模型&源码解析 想要尝试改进 YOLOv5 -6.1的同学，可以参考以下几篇博客： 【魔改 YOLOv5 -6.x（上）】
yolov5 数据强化 方法 并不是越多越好
weixin_39122088的博客
12-07 8843
最近刚刚更新的 yolov5 3.1版本，里边封装了好多好多的数据强化 方法 ，但是在实际训练中，并不是强化 方法 越多越好，下边主要是基于其中的三种 方法 做一下介绍： 1.mosaic Mosaic简单的说就是把四张训练图片缩放拼成一张图，这样我们原本较大的目标在缩小大概一倍之后也会变成较小的目标，这样训练可以增强我们模型的检测小模型的能力。 但是如果我们的数据集本身就有很多的小目标，那么这个 方法 反而会导致本来较小的目标变得更小，导致模型的泛化能力变差。例如下边这张图是我自己正在做的一个 目标检测 项目训练集label分
YOLOv5 输入端（一）—— Mosaic 数据增强 |CSDN创作打卡
tt丫的博客
02-10 1万+
入门小菜鸟，希望像做笔记记录自己学的东西，也希望能帮助到同样入门的人，更希望大佬们帮忙纠错啦~侵权立删。 目录 一、原理分析 二、代码分析 1、主体部分——load_mosaic 2、load_image函数 3、random_perspective()函数（详见代码解析） 一、原理分析 YOLOv5 采用和YOLOv4一样的Mosaic 数据增强 。 主要原理：它将一张选定的图片和随机的3张图片进行随机裁剪，再拼接到一张图上作为训练数据。 这样可以丰富图片的背景，而且四张图片拼接在一起变相提
yolov4和 yolov5 哪个好
06-06
Yolov4和 Yolov5 都是 目标检测 算法中比较出色的模型，它们都具有较高的检测精度和较快的检测速度。但是，它们在一些方面略有不同，例如： 1. Yolov4 使用 了更多的 tricks ，如CSPDarknet53网络结构、SPP结构、PAN结构等，使得其在精度上略胜一筹； 2. Yolov5 采用了更轻量化的网络结构，如采用了更小的Conv和更少的通道数，使得其在速度上更快； 3. Yolov5 在训练时 使用 的 数据增强 方式更多样化，如CutMix、Mosaic等，使得其在鲁棒性上更优秀。 综上所述，选择哪一个模型取决于具体的应用场景和需求。如果需要更高的检测精度，可以选择Yolov4；如果需要更快的检测速度，可以选择 Yolov5 。
“相关推荐”对你有帮助么？

    非常没帮助
    没帮助
    一般
    有帮助
    非常有帮助

    关于我们
    招贤纳士
    商务合作
    寻求报道
    400-660-0108
    kefu@csdn.net
    在线客服
    工作时间 8:30-22:00

    公安备案号11010502030143
    京ICP备19004658号
    京网文〔2020〕1039-165号
    经营性网站备案信息
    北京互联网违法和不良信息举报中心
    家长监护
    网络110报警服务
    中国互联网举报中心
    Chrome商店下载
    账号管理规范
    版权与免责声明
    版权申诉
    出版物许可证
    营业执照
    ©1999-2023北京创新乐知网络技术有限公司

Clichong CSDN认证博客专家 CSDN认证企业博客
码龄4年 暂无认证

347
    原创

1万+
    周排名

3253
    总排名

99万+
    访问

    等级

6641
    积分

1185
    粉丝

1410
    获赞

538
    评论

1万+
    收藏

持之以恒
签到新秀
五一创作勋章
笔耕不辍
阅读者勋章
知无不言
分享学徒
分享小兵
求知
博客之星–参与
持续创作
勤写标兵
1024勋章
创作能手
私信
关注
热门文章

    HC-SR04超声波测距模块的原理介绍与代码实现 78917
    L298N电机驱动模块的接线使用与代码实现 60960
    pwm电机调速的原理介绍与代码实现 46706
    轻量级网络——MobileNetV2 37681
    轻量级网络——ShuffleNetV2 22725

分类专栏

    点云检测OpenPCDet实战专栏 付费 22篇
    深度学习 40篇
    机器学习 18篇
    推荐系统 4篇
    MMOpenLab 9篇
    点云检测专栏
    三维点云论文 23篇
    三维点云实践 12篇
    目标检测专栏
    目标检测论文 32篇
    目标检测实践 11篇
    目标检测YOLOv3技巧汇总 13篇
    目标检测YOLOv5技巧汇总 15篇
    计算机视觉
    视频理解 1篇
    语义分割 2篇
    无监督学习 2篇
    GANs 3篇
    OpenCV 3篇
    MATLAB 2篇
    深度学习理论进阶 6篇
    网络结构
    CNN 11篇
    MLP 7篇
    Transformer 8篇
    嵌入式学习
    Linux 15篇
    STM8 15篇
    Markdown 3篇
    STM32 1篇
    软件安装及使用 9篇
    计算机基础
    LeetCode 8篇
    Python 15篇
    数据结构和算法 17篇
    计算机网络 7篇
    操作系统 12篇
    Debug 7篇
    Outside of Study 2篇

最新评论

    生成对抗网络——CGAN

    cm0420y: 博主，我想问一下手写数据集不是多分类问题嘛，为什么损失函数用的是bce而不是cross binary loss
    Open3d系列 | 3. Open3d实现点云上采样、点云聚类、点云分割以及点云重建

    qq_40278087: 下采样中deepcopy是什么，运行程序的时候报错啊，博主。
    YOLOv5的Tricks | 【Trick12】YOLOv5使用的数据增强方法汇总

    qq_48333434: 请问博主表情包 有yolov7的嘛
    HC-05蓝牙模块遇到的问题与解决方法及实现和手机通信

    m0_50632788: 求手机的串口调试助手
    YOLOv5的Tricks | 【Trick15】使用COCO API评估模型在自己数据集的结果

    weixin_42233304: 博主你这个yolo转coco的代码有问题呀

您愿意向朋友推荐“博客详情页”吗？

    强烈不推荐
    不推荐
    一般般
    推荐
    强烈推荐

最新文章

    OpenPCDet系列 | 8.2 nuScenes数据集的eval流程
    OpenPCDet系列 | 8.1 nuScenes数据集的处理流程与gt_sample的database构建
    MATLAB图像处理实现高光抑制

2023年 34篇
2022年 132篇
2021年 107篇
2020年 74篇
目录

    文章目录
    0. 自定义数据集的整体架构
    1. Mosaic数据增强
    2. Copy paste数据增强
    3. Random affine仿射变换
    4. MixUp数据增强
    5. HSV随机增强图像
    6. 随机水平翻转
    7. Cutout数据增强
    8. Albumentations数据增强工具包 

只看目录 隐藏侧栏 新手引导 客服 举报 返回顶部
