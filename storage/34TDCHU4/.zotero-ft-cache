
Skip to main content
Cornell University
We are hiring

We gratefully acknowledge support from
the Simons Foundation and member institutions.
arxiv logo > cs > arXiv:2204.06092

Help | Advanced Search
Search
Computer Science > Computation and Language
(cs)
[Submitted on 12 Apr 2022 ( v1 ), last revised 22 Jan 2023 (this version, v2)]
Title: ASQA: Factoid Questions Meet Long-Form Answers
Authors: Ivan Stelmakh , Yi Luan , Bhuwan Dhingra , Ming-Wei Chang
Download a PDF of the paper titled ASQA: Factoid Questions Meet Long-Form Answers, by Ivan Stelmakh and 3 other authors
Download PDF

    Abstract: An abundance of datasets and availability of reliable evaluation metrics have resulted in strong progress in factoid question answering (QA). This progress, however, does not easily transfer to the task of long-form QA, where the goal is to answer questions that require in-depth explanations. The hurdles include (i) a lack of high-quality data, and (ii) the absence of a well-defined notion of the answer's quality. In this work, we address these problems by (i) releasing a novel dataset and a task that we call ASQA (Answer Summaries for Questions which are Ambiguous); and (ii) proposing a reliable metric for measuring performance on ASQA. Our task focuses on factoid questions that are ambiguous, that is, have different correct answers depending on interpretation. Answers to ambiguous questions should synthesize factual information from multiple sources into a long-form summary that resolves the ambiguity. In contrast to existing long-form QA tasks (such as ELI5), ASQA admits a clear notion of correctness: a user faced with a good summary should be able to answer different interpretations of the original ambiguous question. We use this notion of correctness to define an automated metric of performance for ASQA. Our analysis demonstrates an agreement between this metric and human judgments, and reveals a considerable gap between human performance and strong baselines. 

Comments: 	A minor bug in computing the ROUGE score was fixed. The fix **did not** result in any changes in observations and conclusions
Subjects: 	Computation and Language (cs.CL)
Cite as: 	arXiv:2204.06092 [cs.CL]
  	(or arXiv:2204.06092v2 [cs.CL] for this version)
  	https://doi.org/10.48550/arXiv.2204.06092
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Ivan Stelmakh [ view email ]
[v1] Tue, 12 Apr 2022 21:58:44 UTC (757 KB)
[v2] Sun, 22 Jan 2023 14:25:40 UTC (757 KB)
Full-text links:
Download:

    Download a PDF of the paper titled ASQA: Factoid Questions Meet Long-Form Answers, by Ivan Stelmakh and 3 other authors
    PDF
    Other formats 

( license )
Current browse context:
cs.CL
< prev   |   next >
new | recent | 2204
Change to browse by:
cs
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

