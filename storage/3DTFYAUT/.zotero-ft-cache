Confidence May Cheat: Self-Training on Graph Neural Networks under Distribution Shift

Hongrui Liuâˆ—
liuhongrui@bupt.edu.cn Beijing University of Posts and
Telecommunications

Binbin Hu
bin.hbb@antfin.com Ant Group

Xiao Wang
xiaowang@bupt.edu.cn Beijing University of Posts and
Telecommunications Peng Cheng Laboratory

arXiv:2201.11349v1 [cs.LG] 27 Jan 2022

Chuan Shiâ€ 
shichuan@bupt.edu.cn Beijing University of Posts and
Telecommunications Peng Cheng Laboratory

Zhiqiang Zhang
lingyao.zzq@antfin.com Ant Group

Jun Zhou
jun.zhoujun@antfin.com Ant Group

ABSTRACT
Graph Convolutional Networks (GCNs) have recently attracted vast interest and achieved state-of-the-art performance on graphs, but its success could typically hinge on careful training with amounts of expensive and time-consuming labeled data. To alleviate labeled data scarcity, self-training methods have been widely adopted on graphs by labeling high-confidence unlabeled nodes and then adding them to the training step. In this line, we empirically make a thorough study for current self-training methods on graphs. Surprisingly, we find that high-confidence unlabeled nodes are not always useful, and even introduce the distribution shift issue between the original labeled dataset and the augmented dataset by self-training, severely hindering the capability of self-training on graphs. To this end, in this paper, we propose a novel Distribution Recovered Graph Self-Training framework (DR-GST), which could recover the distribution of the original labeled dataset. Specifically, we first prove the equality of loss function in self-training framework under the distribution shift case and the population distribution if each pseudo-labeled node is weighted by a proper coefficient. Considering the intractability of the coefficient, we then propose to replace the coefficient with the information gain after observing the same changing trend between them, where information gain is respectively estimated via both dropout variational inference and dropedge variational inference in DR-GST. However, such a weighted loss function will enlarge the impact of incorrect pseudo labels. As a result, we apply the loss correction method to improve the quality of pseudo labels. Both our theoretical analysis and extensive experiments on five benchmark datasets demonstrate the effectiveness of the proposed DR-GST, as well as each well-designed component in DR-GST.
âˆ—
Work done during internship at Ant Group.
â€ 
Corresponding author
WWW â€™22, April 25â€“29, 2022, Virtual Event, Lyon, France Â© 2022 Association for Computing Machinery. This is the authorâ€™s version of the work. It is posted here for your personal use. Not for redistribution. The definitive Version of Record was published in Proceedings of the ACM Web Conference 2022 (WWW â€™22), April 25â€“29, 2022, Virtual Event, Lyon, France, https://doi.org/10.1145/3485447.3512172.

CCS CONCEPTS
â€¢ Computing methodologies â†’ Neural networks; â€¢ Theory of computation â†’ Social networks; Semi-supervised learning.

KEYWORDS
Graph Neural Networks, Self-Training, Information Gain
ACM Reference Format: Hongrui Liu, Binbin Hu, Xiao Wang, Chuan Shi, Zhiqiang Zhang, and Jun Zhou. 2022. Confidence May Cheat: Self-Training on Graph Neural Networks under Distribution Shift. In Proceedings of the ACM Web Conference 2022 (WWW â€™22), April 25â€“29, 2022, Virtual Event, Lyon, France. ACM, New York, NY, USA, 11 pages. https://doi.org/10.1145/3485447.3512172

1 INTRODUCTION
Graphs are ubiquitous across many real-world applications, ranging from citation and social network analysis to protein interface and chemical bond prediction. With the surge of demands, Graph Convolution Network (GCN) and its variants [17, 18, 30, 32, 35] (abbreviated as GCNs) have recently attracted vast interest and achieved state-of-the-art performance in various tasks on graphs, most notably semi-supervised node classification. Nevertheless, its success could typically hinge on careful training with large amounts of labeled data, which is expensive and time-consuming to be obtained [28]. Empirically, the performance of GCNs will rapidly decline with the decrease of labeled data [38].
As one of the promising approaches, self-training [16, 19] aims at addressing labeled data scarcity by making full use of abundant unlabeled data in addition to task-specific labeled data. Given an arbitrary model trained on the original labeled data as the teacher model, the key idea of self-training is to pseudo-label high-confidence unlabeled samples to augment the above labeled data, and a student model is trained with augmented data to replace the teacher model. Such an iteration learning is repeated until convergence 1. Analogously, self-training has great potential to facilitate advancing GCNs to exploiting unlabeled data [20, 28, 38]. Whereas, these studies only focus on the high-confidence nodes on account of the prefabricated assumption that the higher the confidence, the more

1
The

teacher-student

term

is

commonly

adopted

in

current

self-training

studies

[8,

14,

22], and we just reuse it here for a clearer explanation.

WWW â€™22, April 25â€“29, 2022, Virtual Event, Lyon, France
accurate the prediction. Naturally, we are curious about such a fundamental question, â€œAre all the unlabeled nodes pseudo-labeled with high confidence truly useful?â€
As a motivating example, we conduct an analysis experiment on a benchmark dataset Cora [26] to explore how much additional information these high-confidence nodes can bring to the model (denoted as information gain). More details can be seen in Section 3. Surprisingly, our experimental results show a clear negative correlation between the confidence and the information gain, implying that nodes pseudo-labeled by existing graph self-training methods with high confidence may be low-information-gain and useless. To further understand the underlying reason, we illustrate the distribution of unlabeled nodes and find these high-confidence (or low-information-gain) nodes are far from the decision boundary, which implies that they potentially guide the model to perform worthless optimization for a more crisp decision boundary. Existing graph self-training methods which focus on high-confidence nodes are â€œcheatedâ€ by confidence in this way.
In light of the above observations, we further investigate into what will happen when self-training is cheated by confidence. We discover that during the optimization procedure dominated by easy nodes (i.e., nodes with low information gain), the Distribution Shift phenomenon between the original and augmented dataset gradually appears. This is because more and more easy nodes selected by high confidence are added to the original labeled dataset, leading to the distribution gradually shifting to the augmented dataset and overmuch attention paid on such easy nodes as a result. Not surprisingly, this issue will severely threaten the capacity of selftraining on graphs, since the distribution of the augmented dataset is different from the population distribution, resulting in a terrible generalization during evaluation. Alleviating distribution shift from self-training on graphs is in urgent demand, which is unexplored in existing studies.
In this paper, we propose an information gain weighted selftraining framework DR-GST which could recover the distribution of original labeled dataset. Specifically, we first prove that the loss function of the self-training framework under the distribution shift case is equal to that under the population distribution if we could weight each pseudo-labeled node with a proper coefficient. But the coefficient is generally intractable in practice. Then we discover the same changing trend between the coefficient and information gain, and propose to replace the coefficient with information gain, where the information gain can be estimated via both dropout variational inference and dropedge variational inference. Consequently, we can recover the shifted distribution with the newly proposed information gain weighted loss function. Such a loss function forces the model to pay more attention to hard nodes, i.e., nodes with high information gain, but will enlarge the impact of incorrect pseudo labels. Therefore, we apply loss correction [10, 23, 27] to self-training to correct the prediction of the student model, so that the impact of incorrect pseudo labels from the teacher model can be alleviated in this way. Finally, we conduct a theoretical analysis of self-training on graphs, and the conclusion shows both distribution shift and incorrect pseudo labels will severely hinder its capability, which is consistent with our designs.
In summary, the main contributions are highlighted as follows:

Hongrui Liu, Binbin Hu, Xiao Wang, Chuan Shi, Zhiqiang Zhang, and Jun Zhou
â€¢ We make a thorough study on graph self-training, and find two phenomena below: 1) pseudo-labeled high-confidence nodes may
cheat. 2) distribution shift between the original labeled dataset
and the augmented dataset. Both of them severely hinder the
capability of self-training on graphs. â€¢ We propose a novel graph self-training framework DR-GST that
not only addresses the distribution shift issue from the view
of information gain, but also is equipped with the creative loss
correction strategy for improving qualities of pseudo labels. â€¢ We theoretically analyze the rationality of the whole DR-GST
framework and extensive experimental results on five benchmark
datasets demonstrates that DR-GST consistently and significantly
outperforms various state-of-arts.
2 PRELIMINARY
Let ğ’¢ = (ğ’±, â„°, X) be a graph with the adjacent matrix A âˆˆ R|ğ’± |Ã—|ğ’± |, where ğ’± and â„° are respectively the set of nodes and edges, and X = [x1, x2, Â· Â· Â· , x|ğ’± |] âˆˆ R|ğ’± |Ã—ğ·ğ‘£ is the ğ·ğ‘£-dimensional feature matrix for nodes. In the common semi-supervised node classifica-
tion setting, we only have access to a small amounts of labeled nodes ğ’±ğ¿ with their labels ğ’´ğ¿ along with a larger amounts of unlabeled nodes ğ’±ğ‘ˆ , where |ğ’±ğ¿ | â‰ª |ğ’±ğ‘ˆ |.
Self-training Generally, self-training methods on graphs firstly train a vanilla GCN as the base teacher model ğ‘“ğœƒ (X, A) with groundtruth labels ğ’´ğ¿, where ğœƒ is the model parameter set. We could obtain the probability vector for each node ğ‘£ğ‘– âˆˆ ğ’± as: p (ğ‘¦ğ‘– |xğ‘–, A; ğœƒ ) = ğ‘“ğœƒ (xğ‘–, A). For convenience, we abbreviate it to pğ‘– and denote the j-th element of pğ‘– by ğ‘ğ‘–,ğ‘— . Next, the teacher model pseudo-labels a subset ğ’®ğ‘ˆ âŠ‚ ğ’±ğ‘ˆ of unlabeled nodes with its prediction ğ‘¦Â¯ğ‘¢ = arg maxğ‘— ğ‘ğ‘¢,ğ‘— for each node ğ‘£ğ‘¢ âˆˆ ğ’®ğ‘ˆ . The selection of ğ’®ğ‘ˆ is based on the confidence score ğ‘Ÿğ‘– = maxğ‘— ğ‘ğ‘–,ğ‘— , i.e., only nodes with ğ‘Ÿğ‘– higher than a threshold or top-k high-confidence nodes are added to the labeled dataset. Then the augmented dataset ğ’±ğ¿ âˆª ğ’®ğ‘ˆ is used to train a student model ğ‘“ğœƒÂ¯ with the following objective function.

min â„’
ğœƒÂ¯âˆˆÎ˜

(A,

X,

ğ’´ğ¿ )

=

min
ğœƒÂ¯âˆˆÎ˜

Eğ‘£ğ‘–

âˆˆğ’±ğ¿ ,ğ‘¦ğ‘–

âˆˆğ’´ğ¿ ğ‘™

(ğ‘¦ğ‘– ,

pğ‘– )

+ ğœ†Eğ‘£ğ‘¢ âˆˆğ’®ğ‘ˆ ,ğ’®ğ‘ˆ âŠ‚ğ’±ğ‘ˆ Eğ‘¦Â¯ğ‘¢ âˆ¼p(ğ‘¦ğ‘¢ |xğ‘¢,ğ´;ğœƒ )ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ ) ,

(1)

where ğ‘™ (ğ‘¦ğ‘–, pğ‘– ) = âˆ’ log ğ‘ğ‘–,ğ‘¦ğ‘– is the multi-class cross entropy loss and we fix ğœ† = 1 in this paper. Finally we replace the teacher

model with the student model and iterate the above procedure until

convergence.

Information Gain As can be seen in Eq. 1, self-training on

graphs will exploit the unlabeled data to train the whole model.

Here, we aim to measure how an unlabeled node contributes to

the model optimization in a principled way, i.e., information gain.

Information gain usually measures the reduction in information

given a random variable, where information is generally calculated

by the Shannonâ€™s entropy [6]. We utilize the information gain

here to seek the node ğ‘£ğ‘¢ which owns the most information about

parameters ğœƒ of model posterior and could reduce the number of

possible parameter hypotheses maximally fast. We refer to this type

of information gain as information gain about model parameters

[22]. Formally, given a node ğ‘£ğ‘¢ , the information gain about model

Confidence May Cheat: Self-Training on Graph Neural Networks under Distribution Shift

WWW â€™22, April 25â€“29, 2022, Virtual Event, Lyon, France

(a)

(b)

Figure 1: (a): Relationship between confidence and information gain on Cora. (b): Visualization of embeddings on Cora

(a) ğ‘ƒğ‘ğ‘œğ‘

(b) ğ‘ƒğ‘ ğ‘¡

(c) ratio of ğ‘ƒğ‘ğ‘œğ‘ and ğ‘ƒğ‘ ğ‘¡

Figure 2: Visualization of labeled nodes under the ideal condition. (ğ‘ƒğ‘ğ‘œğ‘ : distribution before self-training, ğ‘ƒğ‘ ğ‘¡ : distribution after self-training)

parameters is defined as Bğ‘¢ , which could be calculated as follows: Bğ‘¢ (ğ‘¦ğ‘¢, ğœƒ |xğ‘¢, A, ğ’¢) = H[Eğ‘ƒ (ğœƒ |ğ’¢) [ğ‘¦ğ‘¢ |xğ‘¢, A; ğœƒ ]] (2) âˆ’Eğ‘ƒ (ğœƒ |ğ’¢) [H[ğ‘¦ğ‘¢ |xğ‘¢, A; ğœƒ ]],
where H(Â·) denotes the Shannonâ€™s entropy and ğ‘ƒ (ğœƒ |ğ’¢) is the distribution of model posterior. The first term measures the information of the model parameters under posterior, while the second term captures the information of model parameters given an additional node ğ‘£ğ‘¢ . Obviously, by calculating the difference between the two terms above, Bğ‘¢ can measure how much information ğ‘£ğ‘¢ can bring to learn the model parameters ğœƒ .
3 EMPIRICAL ANALYSIS
In this section, we conduct a series of empirical analysis to examine whether current graph self-training approaches adopt a principled way to leverage unlabeled data for semi-supervised node classification.
Empirical Analysis of Confidence To better understand the capacity of high-confidence nodes in current self-training approaches, we aim to closely examine that how much additional information these nodes can bring to the model based on information gain. We first visualize the relationship between confidence and information gain in Fig. 1(a), where the x-axis is the confidence while the y-axis is the information gain, and the blue and orange dots respectively represent nodes with correct and incorrect predictions. From Fig. 1(a) we can observe a negative correlation, implying that existing graph self-training methods only focus on easy nodes (nodes with low information gain) and confidence may be cheating as a result. Essentially, such a â€œcheating" phenomenon lies in the worthless optimization for a more crisp decision boundary. Specifically, as shown in Fig. 1(b), on the Cora dataset, we visualize the node embeddings on the last layer of the standard GCN before softmax using t-SNE [29] algorithm, where a darker dot represents a node with lower information gain. From the plots, we find that most of easy nodes (i.e., low information gain) are far from the decision boundary. Whereas, these nodes are always emphasized by current self-training methods on graphs [20, 28, 38] by force of high confidence. That is, these methods are â€œcheatedâ€ by confidence in this way.
Empirical Analysis of Distribution Shift Furthermore, we investigate what will happen when self-training has been cheated by confidence. As an illustrative example, we randomly generate

500 nodes (blue) following two-dimensional Gaussion distribution ğ’© (0, 0, 0.3, 0.3, 0) to represent labeled nodes in one class, and another 4000 nodes (grey) following the distribution of concentric circles [1] to represent labeled nodes belonging to other classes, as shown in Fig. 2(a). Furthermore, following the common self-training setting, a large amount of unlabeled nodes still exists in the dataset, but for clarity, we omit them in the figure. In line with the core idea of current self-training methods, for the â€œblueâ€ class, unlabeled nodes around the center are pseudo-labeled for self-training since these nodes have high confidence (a.k.a., far from the decision boundary). During iteration, as shown in Fig 2(b), the data distribution will become more and more sharpen since nodes far from the decision boundary are paid disproportionate attention and thus the unsatisfying Distribution Shift phenomenon between the original and augmented dataset indeed appears.

4 THE DR-GST FRAMEWORK
In this section, we elaborate the proposed DR-GST, a novel selftraining framework aiming at recovering the shifted distribution.

4.1 Information Gain Weighted Loss Function Towards Distribution Shift

We start with the formulation of the self-training task by analyzing the corresponding loss functions. Specifically, assuming that the original labeled dataset follows the population distribution ğ‘ƒğ‘ğ‘œğ‘ , given a classifier ğ‘“ğœƒ parameterized by ğœƒ , the best parameter set ğœƒ could be obtained via minimizing the following loss function:

â„’ğ‘ğ‘œğ‘ = E(ğ‘£ğ‘–,ğ‘¦ğ‘– )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´)ğ‘™ (ğ‘¦ğ‘–, pğ‘– ).

(3)

Similarly, under the distribution shift case caused by self-training, the loss function can be represented as

â„’ğ‘ ğ‘¡

=

|ğ’±ğ¿ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

|

E ( ğ‘£ğ‘– ,ğ‘¦ğ‘–

) âˆ¼ğ‘ƒğ‘ğ‘œ ğ‘

(ğ’±,ğ’´ ) ğ‘™

(ğ‘¦ğ‘–

,

pğ‘–

)

(4)

+

|ğ’®ğ‘ˆ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

| E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ ğ‘¡

(ğ’±,ğ’´)ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ ),

where ğ‘ƒğ‘ ğ‘¡ represents the shifted distribution of the augmented dataset.
Generally, the distribution shift could lead to a terrible generalization during evaluation, and thus severely threaten the capacity of graph self-training. Therefore, It is ideal to optimize ğ‘“ğœƒ with the loss function â„’ğ‘ğ‘œğ‘ under the population distribution rather than

WWW â€™22, April 25â€“29, 2022, Virtual Event, Lyon, France

â„’ğ‘ ğ‘¡ under the distribution shift case. However, only â„’ğ‘ ğ‘¡ is available in practice. To close the gap, we show the following theorem.

Theorem 4.1. Given â„’ğ‘ğ‘œğ‘ and â„’ğ‘ ğ‘¡ defined in Eq. 3 and Eq. 4,

assuming that ğ‘¦Â¯ğ‘¢ = ğ‘¦ğ‘¢ for each pseudo-labeled node ğ‘£ğ‘¢ âˆˆ ğ’®ğ‘ˆ , then

â„’ğ‘ ğ‘¡ = â„’ğ‘ğ‘œğ‘ holds true if â„’ğ‘ ğ‘¡ can be written with an additional weight

coefficient ğ›¾ğ‘¢

=

ğ‘ƒğ‘ğ‘œğ‘ (ğ‘£ğ‘¢,ğ‘¦ğ‘¢ ) ğ‘ƒğ‘ ğ‘¡ (ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )

as follows:

â„’ğ‘ ğ‘¡

=

|ğ’®ğ‘ˆ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

|

E

(ğ‘£ğ‘¢

,ğ‘¦ğ‘¢

)

âˆ¼ğ‘ƒğ‘ ğ‘¡

(

ğ’±,ğ’´

)

ğ›¾ğ‘¢

ğ‘™

(ğ‘¦Â¯ğ‘¢

,

pğ‘¢

)

(5)

+

|ğ’±ğ¿ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

| E(ğ‘£ğ‘–,ğ‘¦ğ‘– )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´)ğ‘™ (ğ‘¦ğ‘–, pğ‘– ),

Proof. Please refer to A.1.1.

â–¡

Based on Theorem 4.1, we can find that our desired â„’ğ‘ğ‘œğ‘ can be written as the available â„’ğ‘ ğ‘¡ only if a coefficient ğ›¾ğ‘¢ is added to â„’ğ‘ ğ‘¡ .

In other words, the distribution shift issue could be addressed by
optimizing ğ‘“ğœƒ with available â„’ğ‘ ğ‘¡ weighted by ğ›¾ğ‘¢ (in Eq. 5). However, it should be noted that the population distribution ğ‘ƒğ‘ğ‘œğ‘ in â„’ğ‘ ğ‘¡ is

generally intractable, which means that ğ›¾ğ‘¢ cannot be accurately

calculated.

To this end, we propose to build the bridge between ğ›¾ğ‘¢ and the

information gain, which is motivated as follows. Recalling the data

distributions shown in Fig. 2(a) and Fig. 2(b), we could formally

represent the former as ğ‘ƒğ‘ğ‘œğ‘ and the latter as ğ‘ƒğ‘ ğ‘¡ . We visualize the

desired weight coefficient ğ›¾ğ‘¢

=

ğ‘ƒğ‘ğ‘œğ‘ (ğ‘£ğ‘¢,ğ‘¦ğ‘¢ ) ğ‘ƒğ‘ ğ‘¡ (ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )

for each pseudo-labeled

node ğ‘£ğ‘¢ in Fig. 2(c) for better understanding its changing trend,

where the darker area means the larger ğ›¾ğ‘¢ . Obviously, we observe

that ğ›¾ğ‘¢ becomes smaller when getting closer to the center area (a.k.a., far away from the decision boundary), which is consistent

with the change trend of the information gain. This finding inspires

us to adopt the information gain to approximate ğ›¾ğ‘¢ .

4.2 Information Gain Estimation on Graphs

Next, we elaborate the estimation of the information gain for each node ğ‘£ğ‘¢ in graph. As mentioned in Eq. 2, the distribution of model posterior ğ‘ƒ (ğœƒ |ğ’¢) is desired for calculating information gain, but it is intractable in practice, and always computationally expensive for traditional bayesian neural networks [2, 11, 15]. Instead, we could shift attention towards dropout [9] and dropedge [25], a type of regularization technique for preventing over-fitting and over-smoothing in GCNs, which could be both interpreted as an approximation of ğ‘ƒ (ğœƒ |ğ’¢) [13]. Consequently, we propose to estimate the information gain assisted with dropout and dropedge (a.k.a., dropout and dropedge variational inference), which takes into account both features and the network topology in our unified framework DR-GST. For distinction, we refer to DR-GST with dropout variational inference as DR-GSTğ‘‘ğ‘œ and that with dropedge variational inference as DR-GSTğ‘‘ğ‘’ .

4.2.1 Dropout Variational Inference. Specifically, given a ğ¿-layer GCN model ğ‘“ğœƒ , its ğ‘™-th layer output H(ğ‘™) âˆˆ R|ğ’± |Ã—ğ·ğ‘™ can be obtained

by

H(ğ‘™) = ğœ (ğ”‘(A)H(ğ‘™âˆ’1) W(ğ‘™âˆ’1) ),

(6)

where ğ”‘(Â·) represents the normalizing operator, W(ğ‘™âˆ’1) âˆˆ Rğ·ğ‘™âˆ’1Ã—ğ·ğ‘™ is the (l-1)-th layer weight matrix, ğœ (Â·) is the activation function and

Hongrui Liu, Binbin Hu, Xiao Wang, Chuan Shi, Zhiqiang Zhang, and Jun Zhou

H(1) = X âˆˆ R|ğ’± |Ã—ğ·ğ‘£ , ğœƒ = {W(ğ‘™) }ğ‘™ğ¿=1. Dropout randomly masks features of nodes in the graph through drawing from an indepen-
dent Bernoulli random variable. Formally, the ğ‘™-th layer output of
ğ‘“ğœƒ with dropout can be written as:

H(ğ‘™) = ğœ (ğ”‘(A) (H(ğ‘™âˆ’1) âŠ™ Z(ğ‘™âˆ’1) )W(ğ‘™âˆ’1) ),

(7)

where each element of Z(ğ‘™) âˆˆ {0, 1}ğ·ğ‘™âˆ’1Ã—ğ·ğ‘™âˆ’1 is a sample of Bernoulli random variable, representing whether or not the corresponding feature in H(ğ‘™âˆ’1) is set to zero.
Such Bernoulli random sampling on features can also be treated as a sample from ğ‘ƒ (ğœƒ |ğ’¢) [9], thus we can perform ğ‘‡ -times MonteCarlo sampling (referred to Monte-Carlo dropout, MC-dropout) during inference to estimate ğ‘ƒ (ğœƒ |ğ’¢). At each time ğ‘¡, a probability vector pËœğ‘¢ğ‘¡ = pËœğ‘¡ (ğ‘¦ğ‘¢ |xğ‘¢, A; ğœƒËœğ‘¡ ) can be obtained by performing forward pass under such a sample weight ğœƒËœğ‘¡ , i.e., pËœğ‘¢ğ‘¡ = ğ‘“ğœƒËœğ‘¡ (xğ‘¢, A).
However, from the perspective of the computational overhead
and practical performance, we only conduct dropout on the last
layer during MC-dropout. In other words, the probability vector pËœğ‘¢ğ‘¡ âˆˆ PËœğ‘¡ = ğ‘“ğœƒËœğ‘¡ (X, A) at each time ğ‘¡ can be obtained by:
PËœğ‘¡ = ğœ (ğ”‘(A) (Z(ğ‘¡) âŠ™ğœ (ğ”‘(A) Â· Â· Â· ğœ (ğ”‘(A)XW(1) ) Â· Â· Â· )W(ğ‘™âˆ’1) ))W(ğ‘™) ) (8)

4.2.2 Dropedge Variational Inference. The dropedge variational inference takes a similar way with dropout variation inference, but imposes the randomness on the network topology instead.
Specifically, the ğ‘™-th layer output of ğ‘“ğœƒ with dropedge can be written as:

H(ğ‘™) = ğœ (ğ”‘(A âŠ™ Z(ğ‘™âˆ’1) )H(ğ‘™âˆ’1) W(ğ‘™âˆ’1) ),

(9)

where each element of Z(ğ‘™) âˆˆ {0, 1} |ğ’± |Ã—|ğ’± | is also a sample of Bernoulli random variable, representing whether or not the corresponding edge in A is removed.
Similarly, we only conduct dropedge on the last layer and per-
form ğ‘‡ -times Monte-Carlo sampling (referred to as Monte-Carlo dropedge) base on dropedge, where at each time t, the probability vector pËœğ‘¢ğ‘¡ âˆˆ PËœğ‘¡ = ğ‘“ğœƒËœğ‘¡ (X, A) at each time ğ‘¡ is obtained by

PËœğ‘¡ = ğœ (ğ”‘(AâŠ™Z(ğ‘¡) )ğœ (ğ”‘(A) Â· Â· Â· ğœ (ğ”‘(A)XW(1) ) Â· Â· Â· )W(ğ‘™âˆ’1) )W(ğ‘™) ). (10)

4.2.3 Information Gain Estimation. With such probability vector
pËœğ‘¢ğ‘¡ obtained by Eq. 8 or Eq. 10, we can calculate the prediction distribution pğ‘¢ğ’¢ by averaging all the pËœğ‘¢ğ‘¡ :

pğ‘¢ğ’¢

=

p(ğ‘¦ğ‘¢ |xğ‘¢, A, ğ’¢)

=

1

ğ‘‡
âˆ‘ï¸ pËœğ‘¢ğ‘¡ , ğœƒËœğ‘¡

âˆ¼

ğ‘ƒ (ğœƒ |ğ’¢),

(11)

ğ‘‡

ğ‘¡ =1

and thus the information gain Bğ‘¢ can be calculated by:

Bğ‘¢ (ğ‘¦ğ‘¢, ğœƒ |xğ‘¢, A, ğ’¢)

=

ğ·
âˆ’ âˆ‘ï¸ ğ‘ğ’¢
ğ‘¢,ğ‘‘

log ğ‘ğ’¢
ğ‘¢,ğ‘‘

+

1 ğ‘‡

ğ·ğ‘‡
âˆ‘ï¸ âˆ‘ï¸ ğ‘Ëœğ‘¡
ğ‘¢,ğ‘‘

log ğ‘Ëœğ‘¡ .
ğ‘¢,ğ‘‘

ğ‘‘ =1

ğ‘‘=1 ğ‘¡ =1

(12)

Finally, we weight the loss function with above information gain

after normalization:

Confidence May Cheat: Self-Training on Graph Neural Networks under Distribution Shift

WWW â€™22, April 25â€“29, 2022, Virtual Event, Lyon, France

â„’ğ‘ ğ‘¡

=

|ğ’®ğ‘ˆ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

|

E ( ğ‘£ğ‘¢ ,ğ‘¦ğ‘¢

) âˆ¼ğ‘ƒğ‘ ğ‘¡

(ğ’±,ğ’´

)

BÂ¯ğ‘¢ğ‘™

(ğ‘¦Â¯ğ‘¢

,

pğ‘¢

)

+

|ğ’±ğ¿ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

| E(ğ‘£ğ‘–,ğ‘¦ğ‘– )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´)ğ‘™ (ğ‘¦ğ‘–, pğ‘– )

(13)

where

BÂ¯ğ‘¢

=

ğ›½

Â·

Bğ‘¢
1 |ğ’®ğ‘ˆ |

. ğ‘– Bğ‘–

Here, we can tune the balance coefficient ğ›½ to recover the population

distribution (i.e., â„’ğ‘ ğ‘¡ â‰ˆ â„’ğ‘ğ‘œğ‘ ) as much as possible.

4.3 Improving Qualities of Pseudo Labels via Loss Correction
Till now, we have addressed the distribution shift issue with an information gain weighted loss function, where more attentions are paid to nodes with high information gain rather than high confidence. Unfortunately, such a training pipeline still implies hidden risks. Specifically, considering that pseudo labels of hard nodes are more likely to be incorrect as shown in Fig. 1(a) and our DR-GST focuses more on hard nodes, the impact of incorrect pseudo-labeled nodes will be enlarged and even mislead the learning of GCNs. Previous works generally filter out these low-quality nodes with collaborative scoring [20, 28] or prefabricated assumption [38] in a relatively coarse-grained manner, where abundant nodes with high information gain are discarded in advance. Instead, motivated by studies on learning with noisy labels [10, 23, 27], we propose to incorporate loss correction strategy into graph self-training. In brief, DR-GST corrects the predictions of the student model in each iteration, so as to eliminate the negative impact of misleading pseudo labels from the teacher model.
Specifically, given a student model ğ‘“ğœƒÂ¯ trained by pseudo labels, the loss correction assumes there is a model ğ‘“ğœƒâˆ— trained by groundtruth labels and a transition matrix T such that ğ‘“ğœƒÂ¯ can be represented by ğ‘“ğœƒÂ¯ = Tğ‘“ğœƒâˆ— , as shown in Fig. 3, where each element in T âˆˆ Rğ‘Ã—ğ‘ is a transition probability from the ground-truth label to the pseudo label, i.e., ğ‘‡ğ‘˜ ğ‘— = ğ‘ƒ (ğ‘ŒÂ¯ = ğ‘— |ğ‘Œ = ğ‘˜) and ğ‘ is the number of classes. With such a transition matrix, every model trained by pseudo labels is equal to that trained by ground-truth labels. We have proved the equivalence relation above using the following proposition.
Proposition 4.2. Given a model ğ‘“ğœƒÂ¯ trained by pseudo labels and a model ğ‘“ğœƒâˆ— trained by ground-truth labels, assuming that there exists a transition matrix T such that the equation ğ‘“ğœƒÂ¯(xğ‘¢, A) = Tğ‘“ğœƒâˆ— (xğ‘¢, A) holds for each node ğ‘£ğ‘¢ , then ğœƒÂ¯ = ğœƒ âˆ— if T is a permutation matrix under cross entropy (CE) loss or T is an arbitrary non-zero matrix under mean square error (MSE) loss.

Proof. Please refer to Appendix A.1.2.

â–¡

Based on Proposition 4.2, ideally, we can train the student model regardless of the quality of labels, and recover ğ‘“ğœƒâˆ— with T. Specifically, as shown in Fig. 3, for each node ğ‘£ğ‘– âˆˆ {ğ’±ğ¿ âˆª ğ’®ğ‘ˆ } with its feature vector xğ‘– , we first feed it into student model and multiply the output with T to get ğ‘“ğœƒÂ¯(xğ‘–, A). Then we use ğ‘“ğœƒÂ¯(xğ‘–, A) to optimize the student model according to Eq. 13. Finally, at inference, we
can treat the student model as ğ‘“ğœƒâˆ— . Please note that the transition matrix T is pre-computed and not updated during optimization of
the student model.

Figure 3: An illustration of loss correction.

Next, we make an illustration for the computation of the transition matrix T. Noting that for each node ğ‘£ğ‘– âˆˆ ğ’±ğ¿ with the groundtruth label ğ‘¦ğ‘– = ğ‘˜, the probability ğ‘ƒ (ğ‘Œ = ğ‘˜ |ğ‘‹ = xğ‘– ) should be 1 since we definitely know its label to be ğ‘˜. Therefore, given the output probability ğ‘ğ‘˜ ğ‘— = ğ‘“ğœƒÂ¯(xğ‘–, A)ğ‘— of class ğ‘—, we have

ğ‘
ğ‘ğ‘˜ ğ‘— = ğ‘ƒ (ğ‘ŒÂ¯ = ğ‘— |ğ‘‹ = xğ‘– ) = âˆ‘ï¸ ğ‘ƒ (ğ‘ŒÂ¯ = ğ‘— |ğ‘Œ = ğ‘š, ğ‘‹ = xğ‘– )ğ‘ƒ (ğ‘Œ = ğ‘š|ğ‘‹ = xğ‘– )
ğ‘š=1
= ğ‘ƒ (ğ‘ŒÂ¯ = ğ‘— |ğ‘Œ = ğ‘˜, ğ‘‹ = xğ‘– ) Â· 1 + 0 + Â· Â· Â· + 0 = ğ‘‡ğ‘˜ ğ‘— (xğ‘– ) = ğ‘‡ğ‘˜ ğ‘— .
(14)
In others words, the output probability vector ğ‘“ğœƒÂ¯(xğ‘–, A) of each node ğ‘£ğ‘– with its ground-truth label ğ‘˜ is the ğ‘˜-th row of T, where ğœƒÂ¯ means such a model is trained with the augmented dataset ğ’±ğ¿ ğ’®ğ‘ˆ .
Technically, we first train a student model ğ‘“ğœƒÂ¯ without loss correction using the augmented dataset ğ’±ğ¿ âˆª ğ’®ğ‘ˆ , then update T according to ğ‘ğ‘˜ ğ‘— = ğ‘“ğœƒÂ¯(xğ‘–, A)ğ‘— , and finally re-train a student model from scratch with loss correction to obtain ğ‘“ğœƒâˆ— .
Considering that there are multiple nodes belonging to class ğ‘˜
in ğ’±ğ¿, we propose the following optimization problem to learn T
instead:

(ğ¿)

ğ‘

ğ‘
ğ‘˜

âˆ‘ï¸ arg min
T ğ‘˜ =1

âˆ‘ï¸
ğ‘— =1

| |Tğ‘˜,:

âˆ’

ğ‘“ğœƒÂ¯(xğ‘–, A)||2

+

| | TTT

âˆ’

I||2,

(15)

where

(ğ¿)
ğ‘
ğ‘˜

is

the

number

of

nodes

belonging

to

class

ğ‘˜

in

ğ’±ğ¿

and I is an identity matrix. Since the improved CE loss is utilized

as the loss function in this paper as mentioned in Eq. 1 and Eq. 13, we append the regularization term ||TTT âˆ’ I||2 for guiding T to approximate to a permutation matrix, which is derived from Proposition 4.2 under the CE loss. Moreover, we initialize T with the identify matrix I at the very beginning.

4.4 Overview of DR-GST
Till now, we have elaborated our proposed DR-GST framework,
which solves both the distribution shift and the low-quality pseudo
labels with the help of information gain and loss correction. We
summarize it in Algorithm 1 and further analyze its time complexity
in Appendix A.2. Given a graph ğ’¢ = (ğ’±, â„°, X) with its original labeled dataset ğ’±ğ¿,
unlabeled dataset ğ’±ğ‘ˆ , adjacent matrix A as well as its label set ğ’´ğ¿, we first train a teacher model ğ‘“ğœƒ on ğ’±ğ¿ to obtain the prediction ğ‘¦Â¯ğ‘¢ and the confidence ğ‘Ÿğ‘¢ for each unlabeled node ğ‘£ğ‘¢ âˆˆ ğ’±ğ‘ˆ at line 1. then iterate steps from line 3 to 9 util convergence, where we call each iteration a stage following [28]. Specifically, at line 3 we select part of unlabeled nodes whose confidence ğ‘Ÿğ‘¢ is bigger than a given threshold ğœ to obtain ğ’®ğ‘ˆ . Next at line 4 we pseudolabel each node ğ‘£ğ‘¢ âˆˆ ğ’®ğ‘ˆ with ğ‘¦Â¯ğ‘¢ to augment ğ’±ğ¿. Then at line 5 we calculate the information gain Bğ‘¢ according to dropout or dropedge

WWW â€™22, April 25â€“29, 2022, Virtual Event, Lyon, France

Hongrui Liu, Binbin Hu, Xiao Wang, Chuan Shi, Zhiqiang Zhang, and Jun Zhou

variational inference in Section 4.2 and normalize it according to
Eq. 13. With such information gain, we train a student model ğ‘“ğœƒÂ¯ at line 6 using the augmented dataset, where pseudo labels may
be incorrect. Therefore, at line 7 we update the transition matrix T with the output probability vector of ğ‘“ğœƒÂ¯ of each node ğ‘£ğ‘– âˆˆ ğ’±ğ¿ according to Eq. 15, and retrain the student model from scratch at line 8 with ğ‘“ğœƒÂ¯ = Tğ‘“ğœƒâˆ— to get ğ‘“ğœƒâˆ— . Finally, we replace the teacher model ğ‘“ğœƒ with ğ‘“ğœƒâˆ— and repeat above steps utill convergence.
Algorithm 1 The DR-GST Framework
Input: Graph ğ’¢ = (ğ’±, â„°, X), original labeled dataset ğ’±ğ¿, unlabeled dataset ğ’±ğ‘ˆ , adjacent matrix A, label set ğ’´ğ¿, transition matrix T=I
Output: Probability vector pğ‘– for each node ğ‘£ğ‘– 1: Train a teacher model ğ‘“ğœƒ on ğ’±ğ¿ to obtain the prediction ğ‘¦Â¯ğ‘¢ and
the confidence ğ‘Ÿğ‘¢ for each unlabeled node ğ‘£ğ‘¢ âˆˆ ğ’±ğ‘ˆ ; 2: for each stage ğ‘˜ do 3: Select part of unlabeled nodes according to ğ‘Ÿğ‘¢ to get ğ’®ğ‘ˆ ; 4: Pseudo-labeling each node ğ‘£ğ‘¢ âˆˆ ğ’®ğ‘ˆ with ğ‘¦Â¯ğ‘¢ ; 5: Calculate the information gain Bğ‘¢ according to Eq. 12; 6: Train a student model ğ‘“ğœƒÂ¯ without T according to Eq. 13; 7: Update T using ğ‘“ğœƒÂ¯(xğ‘–, A) of ğ‘£ğ‘– âˆˆ ğ’±ğ¿ according to Eq. 15; 8: Retrain a student model from scratch according to Eq. 13
with ğ‘“ğœƒÂ¯ = Tğ‘“ğœƒâˆ— to get ğ‘“ğœƒâˆ— ; 9: Replace the teacher model ğ‘“ğœƒ with the student model ğ‘“ğœƒâˆ— ; 10: end for 11: return pğ‘– = ğ‘“ğœƒâˆ— (xğ‘–, A) in the final stage.

4.5 Theoretical Analysis

In this section, we theoretically analyze the influence factors on self-training from the perspective of gradient descent, and our theorem below demonstrates the rationality of the whole DR-GST framework.

Theorem 4.3. Assuming that ||âˆ‡ğœƒğ‘™ (ğ‘¦ğ‘–, pğ‘– )|| â©½ Î¨ for each node ğ‘£ğ‘– , where Î¨ is a constant, given âˆ‡ğœƒ â„’ğ‘ğ‘œğ‘ and âˆ‡ğœƒ â„’ğ‘ ğ‘¡ , the gradient of â„’ğ‘ğ‘œğ‘ and â„’ğ‘ ğ‘¡ w.r.t. model parameters ğœƒ , the following bound between âˆ‡ğœƒ â„’ğ‘ğ‘œğ‘ and âˆ‡ğœƒ â„’ğ‘ ğ‘¡ holds:

||âˆ‡ğœƒ â„’ğ‘ğ‘œğ‘

âˆ’ âˆ‡ğœƒ â„’ğ‘ ğ‘¡ ||

â©½

|ğ’®ğ‘ˆ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

|

Î¨

(

2

|

|ğ‘ƒ

(ğ‘£ğ‘¢

,ğ‘¦ğ‘¢

)

âˆ¼ğ‘ƒğ‘ğ‘œ

ğ‘

(ğ’±,ğ’´

)

(ğ‘¦Â¯ğ‘¢

â‰  ğ‘¦ğ‘¢ )||

+ ||ğ‘ƒğ‘ ğ‘¡ (ğ’±, ğ’´) âˆ’ ğ‘ƒğ‘ğ‘œğ‘ (ğ’±, ğ’´)||).

(16)

Proof. Please refer to Appendix A.1.3.

â–¡

From the Theorem 4.3 we can conclude that the performance of self-training is negatively related to the difference ||ğ‘ƒğ‘ ğ‘¡ (ğ’±, ğ’´) âˆ’ ğ‘ƒğ‘ğ‘œğ‘ (ğ’±, ğ’´)|| between the two distributions as well as the error rate ||ğ‘ƒ (ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´) (ğ‘¦Â¯ğ‘¢ â‰  ğ‘¦ğ‘¢ )|| of pseudo labels. Meanwhile, we find our proposed DR-GST is a natural framework equipped with
two designs to correspondingly address the issues in self-training: information gain weighted loss function for distribution recovery and loss correction strategy for improving qualities of pseudo labels. This analysis further demonstrates the rationality of DR-GST framework
from the theoretical perspective.

5 EXPERIMENT
In this section, we evaluate the effectiveness of DR-GST framework on semi-supervised node classification task with five widely used benchmark datasets from citation networks [3, 26] (i.e., Cora, Citeseer, Pubmed and CoraFull) and social networks [21] (i.e., Flickr). More detailed descriptions about datasets are in Appendix A.3.1.
5.1 Experimental Setup
5.1.1 Baselines. We compare our proposed DR-GST framework with two categories of baselines, including three representative GCNs (i.e., GCN [17], GAT [30], PPNP [18]) and three graph selftraining frameworks (i.e., STs [20], M3S [28], ABN [38]). Noting that STs includes four variants (i.e., Self-Training, Co-Training, Union and Intersection) in the original paper and the best performance is reported in our experiments. The implementation of DR-GST and all the baselines can be seen in Appendix A.3.2. More detailed experimental environment can be seen in Appendix A.3.3.
5.1.2 Evaluation Protocol. To more comprehensively evaluate our model, for all the datasets, we arrange only a few (including 3, 5, 10, 20) labeled nodes per class (ğ¿/ğ¶) for the training set following [20]. Specifically, in the setting ğ¿/ğ¶ = 20, we follow the standard split [26] for Cora, Citeseer and Pubmed, and manually select 20 labeled nodes per class for CoraFull and Flickr considering the lack of standard split. In the setting ğ¿/ğ¶ < 20, we make 10 random splits for each ğ¿/ğ¶, where each random split represents that we randomly select part of nodes from the training set of ğ¿/ğ¶ = 20. For all the methods and all the cases, we run 10 times and report the mean accuracy.
5.2 Overall Comparison on Node Classification
The performance of different methods on node classification are summarized in Table 1. We have the following observations.
â€¢ Our proposed DR-GST framework outperforms all the baselines by a considerable margin across most cases of all the datasets. The results demonstrate the effectiveness of DR-GST by adopting a more principled mechanism to make use of unlabeled nodes in graph for boosting classification performance.
â€¢ With the decrease of labeled nodes, we observe that the performance of GCNs (i.e., GCN, GAT and APPNP) drops quickly. For clarity, we further illustrate the changing trend of accuracy w.r.t. ğ¿/ğ¶ in Fig. 4. Obviously, we can discover the larger performance margin between DR-GST and GCNs with fewer labeled nodes per class, which further implies the superior capacity of DR-GST for addressing labeled data scarcity on graph learning.
â€¢ Considering the two variants of DR-GST, we find that DR-GSTğ‘‘ğ‘œ performs better on Pubmed, CoraFull and Flickr while DR-GSTğ‘‘ğ‘’ on Cora and Citeseer. An intuitive explanation for such distinct performance is the different emphasis on network topology and feature information w.r.t. different graphs for node classification task. Correspondingly, in DR-GST framework, MC-dropedge performs information gain estimation with network topology while MC-dropout is based on feature information. This finding also sheds light on possible future work to combine both topology and feature to further enhance performance under our framework.

Confidence May Cheat: Self-Training on Graph Neural Networks under Distribution Shift

WWW â€™22, April 25â€“29, 2022, Virtual Event, Lyon, France

Table 1: Node classification results(%). (L/C: the number of labels per class; bold: best)

Dataset

Cora

Citeseer

Pubmed

CoraFull

Flickr

L/C 3 5 10 20 3 5 10 20 3 5 10 20 3 5 10 20 3 5 10 20
GCN 64.52 69.55 78.03 81.56 51.39 61.34 68.39 71.64 66.04 71.25 75.88 79.31 41.83 49.12 55.67 60.69 37.69 40.64 48.04 51.74
GAT 67.19 69.45 76.38 82.24 55.19 59.40 67.61 72.00 67.85 68.41 72.42 78.38 36.44 46.70 52.45 57.97 20.02 24.90 33.27 37.06 APPNP 65.06 75.53 81.33 83.14 51.22 60.48 68.50 71.64 65.77 73.01 76.35 79.51 40.29 44.49 50.89 60.77 24.76 35.54 47.87 61.55
STs 70.68 75.60 80.35 82.89 56.29 65.59 74.17 74.36 69.82 73.77 77.68 81.02 43.44 51.16 58.40 61.70 35.21 43.25 48.23 52.99 M3S 64.24 71.02 78.93 82.78 50.07 63.28 74.54 74.72 68.76 69.21 70.72 81.34 42.77 49.75 57.43 61.40 35.33 39.02 47.62 51.87 ABN 66.39 73.07 78.73 81.79 54.30 64.27 69.90 72.81 59.17 71.40 75.26 79.09 43.38 48.39 55.88 60.62 35.13 41.62 47.01 52.10 DR-GSTğ‘‘ğ‘œ 70.85 77.92 80.88 83.34 59.39 69.08 75.00 75.78 70.74 74.63 78.44 81.08 45.44 53.29 60.01 62.75 37.84 43.47 49.48 53.66 DR-GSTğ‘‘ğ‘’ 73.43 77.59 81.67 84.03 60.60 69.91 74.65 75.26 70.55 73.71 77.42 80.65 45.42 52.50 59.16 63.11 38.21 43.28 49.44 53.05

â€¢ Among the two categories of baselines, self-training frameworks (i.e., STs, M3S and ABN) can generally improve GCNs (i.e., GCN, GAT and APPNP), which indicates the usefulness of unlabeled data. Nevertheless, DR-GST still yields better performance for the following two promising designs: 1) We pay more attention on nodes with high information gain rather than high confidence, so that the unsatisfying distribution shift issue is avoided. 2) We adopt a loss correction strategy, where qualities of pseudo labels are improved for subsequent self-training.
5.3 In-depth Analysis of DR-GST
In this section, we make a series of analysis to better understand each component in DR-GST, as well as key parameter selections.
5.3.1 Ablation Study. As mentioned above, the performance of selftraining theoretically hinges on the distribution gap and qualities of pseudo labels, which could be naturally captured by our DR-GST framework with two corresponding designs: the information-gain based weighted loss function and loss correction module. To comprehensively understand their contributions towards self-training on graphs, we prepare following three variants of DR-GST: â€¢ DR-GST-lc: DR-GST only with the loss correction module, i.e.,
BÂ¯ = 1 for all the unlabeled nodes. â€¢ DR-GST-ig: DR-GST only with the information gain weighted
loss function. â€¢ DR-GST-w/o: DR-GST without the above two designs.
The results on DR-GSTğ‘‘ğ‘œ and DR-GSTğ‘‘ğ‘’ are respectively reported in Fig. 5 and Fig. 6 From the results we can find that the overall performance order is as follows: DR-GST > DR-GST-ig > DR-GST-lc > DR-GST-w/o. There are three conclusions here. Firstly, the best performance achieved by the complete DR-GST framework indicates the effectiveness of considering two components together. Secondly, the information gain weighted loss function and loss correction are both value modules for self-training on graphs. Thus, ignoring them altogether (i.e.,DR-GST-w/o) is not ideal. Thirdly, the information-gain weighted loss function plays a more vital role in our self-training framework since DR-GST-lc generally does not perform as well as DR-GST-ig. In short, above findings further verify the rationality of DR-GST from the empirical perspective.
5.3.2 Parameter Study. Here, we investigate into the sensitivity of two hyper-parameters (i.e., threshold ğœ and balance coefficient ğ›½) on Cora and CoraFull datasets. Similar observations are also

Figure 4: The changing trends of accuracy w.r.t. ğ¿/ğ¶
Figure 5: Ablation study of DR-GSTğ‘‘ğ‘œ . made on other datastes. In particular, we respectively report the performance of DR-GSTğ‘‘ğ‘œ and DR-GSTğ‘‘ğ‘’ , and vary the ğ¿/ğ¶ in {3, 5, 10}. For clear notation in figures, we use â€œdo-3â€ to denote DR-GSTğ‘‘ğ‘œ with ğ¿/ğ¶ = 3, and the rest can be done in the same manner.
Analysis of threshold ğœ in self-training We test the impact of threshold ğœ in self-training, and vary it from 0.40 to 0.70 for Cora and 0.60 to 0.90 for CoraFull. The results are summarized in Fig

WWW â€™22, April 25â€“29, 2022, Virtual Event, Lyon, France

Hongrui Liu, Binbin Hu, Xiao Wang, Chuan Shi, Zhiqiang Zhang, and Jun Zhou

(a) ğ‘ ğ‘¡ğ‘ğ‘”ğ‘’ = 1

(b) ğ‘ ğ‘¡ğ‘ğ‘”ğ‘’ = 2

(c) ğ‘ ğ‘¡ğ‘ğ‘”ğ‘’ = 3

Figure 6: Ablation study of DR-GSTğ‘‘ğ‘’ .

(d) ğ‘ ğ‘¡ğ‘ğ‘”ğ‘’ = 1

(e) ğ‘ ğ‘¡ğ‘ğ‘”ğ‘’ = 2

(f) ğ‘ ğ‘¡ğ‘ğ‘”ğ‘’ = 3

Figure 9: Visualization of learned embeddings for unlabeled nodes ((a)âˆ¼(c)) and test nodes ((d)âˆ¼(f)) on Cora at different stages during self-training.

Figure 7: Impact of threshold ğœ.
Figure 8: Impact of balance coefficient ğ›½.
.7. Generally speaking, the best performance is achieved when we set a smaller ğœ, which is consistent with our analysis above that high-confidence unlabeled nodes contribute less.
Analysis of balance coefficient ğ›½ We then test the impact of the balance coefficient ğ›½ in Eq. 13, and vary it from 1/3 to 1. The results are shown in Fig. 8. Obviously, with the increase of ğ›½, or, in other words, with more attention paid to hard nodes, the performance shows a downward trend, further demonstrating the effectiveness of our design. 5.3.3 Visualization. For a more intuitive of the proposed information gain based DR-GST, we conduct the task of visualization on Cora dataset. Specifically, as shown in Fig. 9, we visualize the output embedding of the student model at different stages in DR-GST for Cora dataset. From Fig. 9(a) to Fig. 9(c) we show the visualization of unlabeled nodes, where a lighter dot represents a node endowed with a higher weight by information gain when calculating the loss

function in Eq. 13. Obviously, we can discover that at an earlier stage, DR-GST pays more attention to nodes close to the decision boundary which is also indistinct at this moment. With the training progress going on, the light nodes gradually vanish, implying that most of information these nodes contain has been learned, leading to a more crisp decision boundary. From Fig. 9(d) to Fig. 9(f) we show the visualization of test nodes, where different colors represent different classes. Apparently, the separability of different classes for test nodes is gradually improved, further demonstrating the effectiveness of DR-GST for optimizing the decision boundary.
6 RELATED WORK
In line with the main focus of our work, we review the most related work in graph neural networks and self-training.
Graph Neural Networks Recent years have seen a surge of efforts on Graph Neural Networks (GNNs) and achieved state-ofthe-art performance in various tasks on graphs [33, 36]. Generally, current GNNs can be divided into two categories. The first category is spectral-based GNNs, which defines graph convolution operation in the spectral domain [4, 7]. The well-known GCN [17] simplifies graph convolutions by using the 1-order approximation. Since then, plenty of studies have sprung up. SGC [32] further simplifies GCN by removing the nonlinearities between GCN layers. [20] shows that GCNs smooth node features between neighbours. On the comparison, the other category is spatial-based GNNs, mainly devoted to aggregating and transforming the local information from the perspective of spatial domain. GAT [30] assigns the learnt weight to each edge during aggregation. [12] proposes a permutation-invariant aggregator for message passing. Moreover, there are many other graph neural models, we please refer the readers to recent surveys [34, 37] for a more comprehensive review.
Self-training Despite the success, GNNs typically require large amounts of labeled data, which is expensive and time-consuming. Self-training [16] is one of the earliest strategies addressing labeled data scarcity by making better use of abundant unlabeled data, and has shown remarkable performance on various tasks [14, 19, 22].

Confidence May Cheat: Self-Training on Graph Neural Networks under Distribution Shift

WWW â€™22, April 25â€“29, 2022, Virtual Event, Lyon, France

Recently, [20] proposes a graph-based self-training framework, demonstrating the effectiveness of self-training on graphs. Further, [28] utilizes the DeepCluster [5] to filter out low-quality pseudo labels during self-training. CaGCN-st [31] argues that self-training under-performs due to generally overlooked low-confidence but high-accuracy predictions, and proposes a confidence-calibrated self-training framework. [38] proposes to select high-quality unlabeled nodes via an adaptive pseudo labeling technique. [24] utilizes a margin prediction confidence to select unlabeled nodes, aiming at identifying the most confident labels. In summary, almost all of graph self-training methods focus on improving the quality of pseudo labels by virtue of confidence, but none of them have ever considered the capability and limitation of such selection criterion.
7 CONCLUSION
In this paper, we empirically make a thorough study for capability and limitation of current self-training methods on graphs, and surprisingly find they may be cheated by confidence and even suffer from the distribution shift issue, leading to unpromising performance. To this end, we propose a novel self-training framework DR-GST which not only addresses the distribution shift issue from the view of information gain, but also is equipped with the creative loss correction strategy for improving qualities of pseudo labels. Theoretical analysis and extensive experiments well demonstrate the effectiveness of the proposed DR-GST. Moreover, our study also gives an insight that confidence alone is not enough for selftraining and thus motivates us an interesting direction for future work, i.e., exploiting more criteria for the selection of unlabeled nodes during self-training.
8 ACKNOWLEDGMENTS
This work is supported in part by the National Natural Science Foundation of China (No. U20B2045, 62192784, 62172052, 61772082, 62002029, U1936104), the Fundamental Research Funds for the Central Universities 2021RC28 and CCF-Ant Group Research Fund.
REFERENCES
[1] Antonin Berthon, Bo Han, Gang Niu, Tongliang Liu, and Masashi Sugiyama. 2021. Confidence scores make instance-dependent label-noise learning possible. In ICML. 825â€“836.
[2] Charles Blundell, Julien Cornebise, Koray Kavukcuoglu, and Daan Wierstra. 2015. Weight uncertainty in neural network. In ICML. 1613â€“1622.
[3] Aleksandar Bojchevski and Stephan GÃ¼nnemann. 2018. Deep Gaussian Embedding of Graphs: Unsupervised Inductive Learning via Ranking. In ICLR.
[4] Joan Bruna, Wojciech Zaremba, Arthur Szlam, and Yann LeCun. 2014. Spectral Networks and Locally Connected Networks on Graphs. In ICLR.
[5] Mathilde Caron, Piotr Bojanowski, Armand Joulin, and Matthijs Douze. 2018. Deep clustering for unsupervised learning of visual features. In ECCV. 132â€“149.
[6] Thomas M Cover. 1999. Elements of information theory. John Wiley & Sons. [7] MichaÃ«l Defferrard, Xavier Bresson, and Pierre Vandergheynst. 2016. Convolu-
tional Neural Networks on Graphs with Fast Localized Spectral Filtering. In NIPS. 3837â€“3845. [8] Jiali Duan, Yen-Liang Lin, Son Dinh Tran, Larry S. Davis, and C.-C. Jay Kuo. 2020. SLADE: A Self-Training Framework for Distance Metric Learning. In CVPR. 9644â€“9653. [9] Yarin Gal and Zoubin Ghahramani. 2016. Dropout as a bayesian approximation: Representing model uncertainty in deep learning. In ICML. 1050â€“1059. [10] Jacob Goldberger and Ehud Ben-Reuven. 2017. Training deep neural-networks using a noise adaptation layer. In ICLR. [11] Alex Graves. 2011. Practical variational inference for neural networks. In NIPS. 2348â€“2356. [12] William L Hamilton, Rex Ying, and Jure Leskovec. 2017. Inductive representation learning on large graphs. In NIPS. 1025â€“1035.

[13] Arman Hasanzadeh, Ehsan Hajiramezanali, Shahin Boluki, Mingyuan Zhou, Nick
Duffield, Krishna Narayanan, and Xiaoning Qian. 2020. Bayesian graph neural networks with adaptive connection sampling. In ICML. 4094â€“4104. [14] Junxian He, Jiatao Gu, Jiajun Shen, and Marcâ€™Aurelio Ranzato. 2020. Revisiting Self-Training for Neural Sequence Generation. In ICLR. [15] Jose Hernandez-Lobato, Yingzhen Li, Mark Rowland, Thang Bui, Daniel
HernÃ¡ndez-Lobato, and Richard Turner. 2016. Black-box alpha divergence minimization. In ICML. 1511â€“1520. [16] H. J. Scudder III. 1965. Probability of error of some adaptive pattern-recognition machines. IEEE Transactions on Information Theory 11, 3 (1965), 363â€“371. [17] Thomas N. Kipf and Max Welling. 2017. Semi-Supervised Classification with Graph Convolutional Networks. In ICLR. [18] Johannes Klicpera, Aleksandar Bojchevski, and Stephan GÃ¼nnemann. 2019. Pre-
dict then Propagate: Graph Neural Networks meet Personalized PageRank. In ICLR. [19] Dong-Hyun Lee et al. 2013. Pseudo-label: The simple and efficient semisupervised learning method for deep neural networks. In ICML Workshop. [20] Qimai Li, Zhichao Han, and Xiao-Ming Wu. 2018. Deeper Insights Into Graph Convolutional Networks for Semi-Supervised Learning. In AAAI. 3538â€“3545. [21] Zaiqiao Meng, Shangsong Liang, Hongyan Bao, and Xiangliang Zhang. 2019. Co-embedding attributed networks. In WSDM. 393â€“401. [22] Subhabrata Mukherjee and Ahmed Awadallah. 2020. Uncertainty-aware selftraining for few-shot text classification. In NIPS. [23] Giorgio Patrini, Alessandro Rozza, Aditya Krishna Menon, Richard Nock, and
Lizhen Qu. 2017. Making deep neural networks robust to label noise: A loss correction approach. In CVPR. 1944â€“1952. [24] Daniel Carlos GuimarÃ£es Pedronette and Longin Jan Latecki. 2021. Rank-based self-training for graph convolutional networks. Information Processing & Management 58, 2 (2021), 102443. [25] Yu Rong, Wenbing Huang, Tingyang Xu, and Junzhou Huang. 2019. Dropedge: Towards deep graph convolutional networks on node classification. arXiv preprint arXiv:1907.10903 (2019). [26] Prithviraj Sen, Galileo Namata, Mustafa Bilgic, Lise Getoor, Brian Galligher, and Tina Eliassi-Rad. 2008. Collective classification in network data. AI magazine 29, 3 (2008), 93â€“93.
[27] Sainbayar Sukhbaatar, Joan Bruna, Manohar Paluri, Lubomir Bourdev, and Rob Fergus. 2014. Training convolutional networks with noisy labels. arXiv preprint arXiv:1406.2080 (2014).
[28] Ke Sun, Zhouchen Lin, and Zhanxing Zhu. 2020. Multi-Stage Self-Supervised
Learning for Graph Convolutional Networks on Graphs with Few Labeled Nodes. In AAAI. 5892â€“5899. [29] Laurens Van der Maaten and Geoffrey Hinton. 2008. Visualizing data using t-SNE. Journal of machine learning research 9, 11 (2008). [30] Petar VeliÄkoviÄ‡, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. 2017. Graph attention networks. ICLR. [31] Xiao Wang, Hongrui Liu, Chuan Shi, and Cheng Yang. 2021. Be Confident! Towards Trustworthy Graph Neural Networks via Confidence Calibration. Advances in Neural Information Processing Systems 34 (2021). [32] Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, and Kilian Weinberger. 2019. Simplifying graph convolutional networks. In ICML. 6861â€“ 6871.
[33] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. 2020. A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems 32, 1 (2020), 4â€“24.
[34] Zonghan Wu, Shirui Pan, Fengwen Chen, Guodong Long, Chengqi Zhang, and S Yu Philip. 2020. A comprehensive survey on graph neural networks. IEEE transactions on neural networks and learning systems 32, 1 (2020), 4â€“24.
[35] Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. 2019. How Powerful are Graph Neural Networks. In ICLR.
[36] Ziwei Zhang, Peng Cui, and Wenwu Zhu. 2020. Deep learning on graphs: A survey. IEEE Transactions on Knowledge and Data Engineering (2020).
[37] Jie Zhou, Ganqu Cui, Shengding Hu, Zhengyan Zhang, Cheng Yang, Zhiyuan Liu,
Lifeng Wang, Changcheng Li, and Maosong Sun. 2020. Graph neural networks: A review of methods and applications. AI Open 1 (2020), 57â€“81. [38] Ziang Zhou, Jieming Shi, Shengzhong Zhang, Zengfeng Huang, and Qing Li.
2019. Effective Semi-Supervised Node Classification on Few-Labeled Graph Data. arXiv preprint arXiv:1910.02684 (2019).

WWW â€™22, April 25â€“29, 2022, Virtual Event, Lyon, France

Hongrui Liu, Binbin Hu, Xiao Wang, Chuan Shi, Zhiqiang Zhang, and Jun Zhou

A SUPPLEMENT
In the supplement, we first provide detailed poofs of import theorems in our paper i.e., Theorem 4.1, Proposition 4.2 and Theorem 4.3. Next, more experimental details are represented for reproduction.

A.1 Proof

In this section, we successively show the detailed proof for Theorem 4.1, Proposition 4.2 and Theorem 4.3.

A.1.1 Proof of Theorem 4.1.

Proof. With our assumption that ğ‘¦Â¯ğ‘¢ = ğ‘¦ğ‘¢ for each pseudolabeled node ğ‘£ğ‘¢ âˆˆ ğ’®ğ‘ˆ , we first rewrite â„’ğ‘ğ‘œğ‘ in Eq. 3 as:

â„’ğ‘ğ‘œğ‘

=

|ğ’®ğ‘ˆ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

|

E ( ğ‘£ğ‘¢ ,ğ‘¦ğ‘¢

) âˆ¼ğ‘ƒğ‘ğ‘œ ğ‘

( ğ’± ,ğ’´ )

ğ‘™

(ğ‘¦Â¯ğ‘¢

,

pğ‘¢

)

(17)

+

| |ğ’±ğ¿

ğ’±ğ¿ | âˆª ğ’®ğ‘ˆ

|

E

(

ğ‘£ğ‘–

,ğ‘¦ğ‘–

)

âˆ¼ğ‘ƒğ‘ğ‘œ

ğ‘

(ğ’±,ğ’´

)

ğ‘™

(ğ‘¦ğ‘–

,

pğ‘–

)

.

where yğ‘¢ is a one-hot vector expanded from ğ‘¦ğ‘¢ . The proof is con-

cluded for MSE loss.

CE

loss.

Under

CE

loss,

we

prove

the

equality

of

ğœƒÂ¯ and

âˆ—
ğœƒ

from

the perspective of gradient descent. Specifically, if for each node ğ‘£ğ‘¢ , the gradient of ğ‘“ğœƒÂ¯(xğ‘¢, A) w.r.t. ğœƒÂ¯ is equal to that of ğ‘“ğœƒâˆ— (xğ‘¢, A) w.r.t. ğœƒ âˆ—, then optimizing a model ğ‘“ğœƒÂ¯ using gradient descent will definitely leads to our desired model ğ‘“ğœƒâˆ— , that is to say, ğœƒÂ¯ = ğœƒ âˆ—.
Specifically, for each node ğ‘£ğ‘¢ , we first rewrite the CE loss as

follows:

ğ‘™ (yğ‘¢, pğ‘¢ ) = yğ‘¢T log ğ‘“ğœƒ (xğ‘¢, A).

(22)

Then the difference ğ‘‘ of gradient between ğœƒÂ¯ and ğœƒ âˆ— can be written

as: ğ‘‘ = ||âˆ‡ğœƒ yÂ¯ğ‘¢T log ğ‘“ğœƒÂ¯(xğ‘¢, A) âˆ’ âˆ‡ğœƒ yğ‘¢T log ğ‘“ğœƒâˆ— (xğ‘¢, A)|| (23)
Considering our assumption that ğ‘“ğœƒÂ¯(xğ‘¢, A) = Tğ‘“ğœƒâˆ— (xğ‘¢, A), Eq. 23 becomes:

ğ‘‘ = ||âˆ‡ğœƒ (Tyğ‘¢ )T log(Tğ‘“ğœƒâˆ— (xğ‘¢, A)) âˆ’ âˆ‡ğœƒ yğ‘¢T log ğ‘“ğœƒâˆ— (xğ‘¢, A)|| (24)

Note that ğ‘ƒğ‘ğ‘œğ‘ (ğ‘£ğ‘¢, ğ‘¦ğ‘¢ )
E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´)ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ ) = E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ ğ‘¡ (ğ’±,ğ’´) ğ‘ƒğ‘ ğ‘¡ (ğ‘£ğ‘¢, ğ‘¦ğ‘¢ ) ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ ), (18)

then we can rewrite Eq. 17 as

â„’ğ‘ğ‘œğ‘

=

|ğ’®ğ‘ˆ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

|

E ( ğ‘£ğ‘¢ ,ğ‘¦ğ‘¢

) âˆ¼ğ‘ƒğ‘ ğ‘¡

( ğ’± ,ğ’´ )

ğ‘ƒğ‘ğ‘œğ‘ (ğ‘£ğ‘¢, ğ‘¦ğ‘¢ ) ğ‘ƒğ‘ ğ‘¡ (ğ‘£ğ‘¢, ğ‘¦ğ‘¢ )

ğ‘™

(ğ‘¦Â¯ğ‘¢ ,

pğ‘¢

)

+

|ğ’±ğ¿ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

| E(ğ‘£ğ‘–,ğ‘¦ğ‘– )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´)ğ‘™ (ğ‘¦ğ‘– , pğ‘– )

(19)

=

|ğ’®ğ‘ˆ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

|

E ( ğ‘£ğ‘¢ ,ğ‘¦ğ‘¢

) âˆ¼ğ‘ƒğ‘ ğ‘¡

( ğ’± ,ğ’´ ) ğ›¾ğ‘¢ ğ‘™

(ğ‘¦Â¯ğ‘¢

,

pğ‘¢

)

+

|ğ’±ğ¿ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

| E(ğ‘£ğ‘–,ğ‘¦ğ‘– )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´)ğ‘™ (ğ‘¦ğ‘–, pğ‘– ),

where ğ›¾ğ‘¢ can be regarded as a weight of the loss function for each

pseudo-labeled node ğ‘£ğ‘¢ .

Finally, recalling the loss function under the distribution shift

According to the chain rule, we have:

ğ‘‘ = ||âˆ‡ğœƒ ğ‘“ğœƒâˆ— (xğ‘¢, A) Â· (TT (Tyğ‘¢ âŠ˜ Tğ‘“ğœƒâˆ— (xğ‘¢, A)) âˆ’ yğ‘¢ âŠ˜ ğ‘“ğœƒâˆ— (xğ‘¢, A))||, (25)
where âŠ˜ represents the element-wise division operation. Obviously, if T is a permutation matrix, the difference ğ‘‘ of gra-

dient is zero. The proof is concluded for CE loss.

â–¡

A.1.3 Proof of Theorem 4.3. To prove Theorem 4.3, we need to borrow a corollary from [38], which illustrates the impact of incorrect pseudo labels on self-training without distribution shift.

Corollary A.1. Assuming that the augmented dataset follows the population distribution ğ‘ƒğ‘ğ‘œğ‘ and ||âˆ‡ğœƒğ‘™ || â‰¤ Î¨ for any gradient âˆ‡ğœƒ â„’, the following bound between âˆ‡ğœƒ â„’ğ‘ğ‘œğ‘ and âˆ‡ğœƒ â„’ğ‘ ğ‘¡ holds:

|âˆ‡ğœƒ â„’ğ‘ğ‘œğ‘

âˆ’ âˆ‡ğœƒ â„’ğ‘ ğ‘¡ |

â©½

|ğ’®ğ‘ˆ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

|

2Î¨

|

|ğ‘ƒ

(ğ‘£ğ‘¢

,ğ‘¦ğ‘¢

)

âˆ¼ğ‘ƒğ‘ğ‘œ

ğ‘

(ğ’±,ğ’´

)

(ğ‘¦Â¯ğ‘¢

â‰  ğ‘¦ğ‘¢ )||.

(26)

case in Eq. 4, i.e.,

Now, we prove Theorem 4.3.

â„’ğ‘ ğ‘¡

=

|ğ’±ğ¿ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

|

E ( ğ‘£ğ‘– ,ğ‘¦ğ‘–

) âˆ¼ğ‘ƒğ‘ğ‘œ ğ‘

(ğ’±,ğ’´ ) ğ‘™

(ğ‘¦ğ‘–

,

pğ‘–

)

(20)

+

|ğ’®ğ‘ˆ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

|

E

(ğ‘£ğ‘¢

,ğ‘¦ğ‘¢

)

âˆ¼ğ‘ƒğ‘ ğ‘¡

(

ğ’±,ğ’´

)

ğ‘™

(ğ‘¦Â¯ğ‘¢

,

pğ‘¢

),

we can find that it is definitely equal to that in Eq. 3 with an ad-

ditional weight coefficient. In other words, we can recover the

population distribution as long as we weight each pseudo-labeled

node with a proper coefficient in â„’ğ‘ ğ‘¡ .

â–¡

A.1.2 Proof of Proposition 4.2.

Proof. Without loss of generality, we respectively prove the equality of ğœƒ âˆ— and ğœƒÂ¯ under MSE loss and CE loss.

MSE loss. Under the MSE loss, with our non-zero assumption for T, the following equation holds true:

âˆ—
ğœƒ

=

arg min
ğœƒâˆ— âˆˆÎ˜

âˆ‘ï¸

|| ğ‘“ğœƒ âˆ—

( xğ‘¢ ,

A)

âˆ’

yğ‘¢ ||2

ğ‘¢

=

arg

min
ğœƒâˆ— âˆˆÎ˜

âˆ‘ï¸

|

|Tğ‘“ğœƒ

âˆ—

(xğ‘¢

,

A)

âˆ’

Tyğ‘¢

||2

(21)

ğ‘¢

=

arg

min
ğœƒÂ¯âˆˆÎ˜

âˆ‘ï¸
ğ‘¢

| | ğ‘“ğœƒÂ¯(xğ‘¢ ,

A)

âˆ’

yÂ¯ğ‘¢

||2

=

ğœƒÂ¯,

Proof. We first calculate the difference between âˆ‡ğœƒ â„’ğ‘ğ‘œğ‘ and âˆ‡ğœƒ â„’ğ‘ ğ‘¡ as follows:

||âˆ‡ğœƒ â„’ğ‘ğ‘œğ‘

âˆ’ âˆ‡ğœƒ â„’ğ‘ ğ‘¡ ||

=

|ğ’®ğ‘ˆ |ğ’±ğ¿

| ğ’®ğ‘ˆ

|

|

|E

(ğ‘£ğ‘¢

,ğ‘¦ğ‘¢

)

âˆ¼ğ‘ƒğ‘ğ‘œğ‘

(ğ’±,ğ’´

)

âˆ‡ğœƒ

ğ‘™

(ğ‘¦ğ‘¢

,

pğ‘¢

)

âˆ’ E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ ğ‘¡ (ğ’±,ğ’´) âˆ‡ğœƒ ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ ) ||.

(27)

Adding and subtracting a same term E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ ğ‘¡ (ğ’±,ğ’´) âˆ‡ğœƒ ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ ),

and abbreviating

|ğ’®ğ‘ˆ | |ğ’±ğ¿ ğ’®ğ‘ˆ |

as ğœ‚, Eq. 27 can be written as:

||âˆ‡ğœƒ â„’ğ‘ğ‘œğ‘ âˆ’ âˆ‡ğœƒ â„’ğ‘ ğ‘¡ || =

ğœ‚ ||E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´) âˆ‡ğœƒ ğ‘™ (ğ‘¦ğ‘¢, pğ‘¢ ) âˆ’ E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´) âˆ‡ğœƒ ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ )

+ E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´) âˆ‡ğœƒ ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ ) âˆ’ E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ ğ‘¡ (ğ’±,ğ’´) âˆ‡ğœƒ ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ ) ||.

(28)

According to the triangle property of the norm, the following in-

equality is satisfied:

||âˆ‡ğœƒ â„’ğ‘ğ‘œğ‘ âˆ’ âˆ‡ğœƒ â„’ğ‘ ğ‘¡ || â‰¤ ğœ‚ (||E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´) âˆ‡ğœƒ ğ‘™ (ğ‘¦ğ‘¢, pğ‘¢ ) âˆ’ E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´) âˆ‡ğœƒ ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ ) || + ||E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´) âˆ‡ğœƒ ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ ) âˆ’ E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ ğ‘¡ (ğ’±,ğ’´) âˆ‡ğœƒ ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ ) ||).
(29)

Confidence May Cheat: Self-Training on Graph Neural Networks under Distribution Shift

WWW â€™22, April 25â€“29, 2022, Virtual Event, Lyon, France

Table 2: The statistics of datasets

Dataset Nodes Edges Classes Features Validation Test

Cora 2708 5429 7 Citeseer 3327 4732 6 Pubmed 19717 44338 3 CoraFull 19793 65311 70
Flickr 7575 239738 9

1433 3703 500 8710 12047

500 1000 500 1000 500 1000 500 1000 500 1000

Recalling Corollary A.1, we know that the first term on the right

hand side satisfies:
||E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´) âˆ‡ğœƒ ğ‘™ (ğ‘¦ğ‘¢, pğ‘¢ ) âˆ’ E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´) âˆ‡ğœƒ ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ ) || â‰¤ 2Î¨||ğ‘ƒ (ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´) (ğ‘¦Â¯ğ‘¢ â‰  ğ‘¦ğ‘¢ ) ||.
(30)

And for the second term, we have:

E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ğ‘œğ‘ (ğ’±,ğ’´) âˆ‡ğœƒ ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ ) âˆ’ E(ğ‘£ğ‘¢,ğ‘¦ğ‘¢ )âˆ¼ğ‘ƒğ‘ ğ‘¡ (ğ’±,ğ’´) âˆ‡ğœƒ ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ ) ||

âˆ« +âˆ âˆ« +âˆ

=

âˆ‡ğœƒ ğ‘™ (ğ‘¦Â¯ğ‘¢, pğ‘¢ )ğ‘‘ (ğ‘ƒğ‘ğ‘œğ‘ (ğ’±, ğ’´) âˆ’ ğ‘ƒğ‘ ğ‘¡ (ğ’±, ğ’´))

âˆ’âˆ âˆ’âˆ

â‰¤ Î¨ Â· ||ğ‘ƒğ‘ğ‘œğ‘ (ğ’±, ğ’´) âˆ’ ğ‘ƒğ‘ ğ‘¡ (ğ’±, ğ’´)||,

(31)

where the inequality is from our assumption that ||âˆ‡ğœƒğ‘™ || â‰¤ Î¨.

Combining Eq. 30 with Eq. 31, we have:

||âˆ‡ğœƒ â„’ğ‘ğ‘œğ‘

âˆ’ âˆ‡ğœƒ â„’ğ‘ ğ‘¡ ||

â©½

|ğ’®ğ‘ˆ | |ğ’±ğ¿ âˆª ğ’®ğ‘ˆ

|

Î¨

(

2

|

|ğ‘ƒ

(ğ‘£ğ‘¢

,ğ‘¦ğ‘¢

)

âˆ¼ğ‘ƒğ‘ğ‘œ

ğ‘

(ğ’±,ğ’´

)

(ğ‘¦Â¯ğ‘¢

â‰  ğ‘¦ğ‘¢ )

+ ||ğ‘ƒğ‘ ğ‘¡ (ğ’±, ğ’´) âˆ’ ğ‘ƒğ‘ğ‘œğ‘ (ğ’±, ğ’´)||).

(32)

The proof is concluded.

â–¡

A.2 Time Complexity Analysis
We first analyze the time complexity of a general self-training framework. Assuming training an epoch takes ğ‘‚ (ğ‘€) time, given epochs ğ¸, its time complexity in each stage is ğ‘‚ (ğ¸ğ‘€). DR-GST is innovated in information gain and loss correction, which respectively takes ğ‘‚ (ğ‘‡ ğ‘€) and ğ‘‚ (ğ¸ğ‘2) time in each stage, where ğ‘‡ and ğ‘ are the numbers of sampling for variational inference and class.
Moreover, considering that we train a student model twice in each stage, the total time complexity is ğ‘‚ ((2ğ¸ + ğ‘‡ )ğ‘€ + ğ¸ğ‘2). In fact, ğ‘‡ and ğ‘‚ (ğ¸ğ‘2) are always far less than ğ¸ and ğ‘‚ (ğ¸ğ‘€). Consequently, the time complexity of DR-GST is approximately twice that of the
general self-training framework.

A.3 More Experimental Details
A.3.1 Details of datasets. We adopt five widely used benchmark datasets from citation networks [3, 26] (i.e., Cora, Citeseer, Pubmed and CoraFull) and social network [21] (i.e., Flickr) for evaluation. For the citation networks, nodes represent papers, edges are the citation relationship between papers, node features are comprised of bag-ofwords vector of the papers and labels represent the fields of papers. And for the social network, nodes in Flickr represent users of the Flickr website, edges are their relationships induced by their photosharing records and labels represent usersâ€™ interest groups. For all the datasets, We choose 500 nodes for validation, 1000 nodes for test. The details of these datasets are summarized in Table 2. Our data

are public and do not contain personally identifiable information and offensive content. The address of our data is https://docs.dgl.ai/ en/latest/api/python/dgl.data.html#node-prediction-datasets and the license is Apache License 2.0. A.3.2 Implementation. We supplement the implementation details of DR-GST and all the baselines here.
For fair comparison, we utilize the standard GCN with 2 layers as the backbone for all graph self-training framework. We optimize models via Adam with learning rate of 0.01 and early stopping with a window size of 200. In paticular, we set L2 regularization with ğœ†ğ‘Ÿ = 5ğ‘’ âˆ’ 4 for Cora, Citeseer, Pubmed, CoraFull and ğœ†ğ‘Ÿ = 5ğ‘’ âˆ’ 5 for Flickr. We set ReLU as the activation function and apply a dropout rate of 0.5 to prevent over-fitting. As for the MC-dropout and MCdropedge, we set the number of sampling ğ‘‡ = 100. Moreover, we apply grid search for other important hyper-parameters. Specifically, the drop rate of MC-dropout and MC-dropedge is chosen from {0.1, 0.2, Â· Â· Â· , 0.5}, the balance coefficient ğ›½ for information gain in Eq. 13 is searched in {4/3, 1, 2/3, 1/2, 1/3, 1/4} and the threshold ğœ is tuned amongst {0.4, 0.45, Â· Â· Â· , 0.75} for Cora, Citeseer, {0.6, 0.65, Â· Â· Â· , 0.9} for Pubmed, CoraFull and {0.75, 0.78, Â· Â· Â· , 0.96} for Flickr.
We adopt the implementation of GCN, GAT and APPNP from DGL2, and the implementations of STs 3 and ABN 4 are publicly provided by their authors. Considering that the implementation of M3S is not available, we re-implement it referring to the original paper [28]. For all baselines, we perform grid search for important hyper-parameters (i.e., ğœ) to obtain optimal results. A.3.3 Experimental Environment. In this section we summarize the hardware and software environment in our experiments.
We utilize a linux machine powered by an Intel(R) Xeon(R) CPU E5-2682 v4 @ 2.50GHz CPU and 4 Tesla P100-PCIE-16GB as well as 4 GeForce RTX 3090 GPU cards.
The operating system is Linux version 3.10.0-693.el7.x86_64. We realize our code with Python 3.8.8 as well as some other python packages as follows: PyTorch 1.8.1, DGL 0.6.0 (cuda 10.1), NetworkX 2.5.
2 https://www.dgl.ai/ 3 https://github.com/Davidham3/deeper_insights_into_GCNs 4 https://anonymous.4open.science/r/e7aca211-0d8d-4564-8f3f-0ef24b01941e/

