
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2212.09662

Help | Advanced Search
Search
Computer Science > Computation and Language
(cs)
[Submitted on 19 Dec 2022 ( v1 ), last revised 23 May 2023 (this version, v2)]
Title: MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering
Authors: Fangyu Liu , Francesco Piccinno , Syrine Krichene , Chenxi Pang , Kenton Lee , Mandar Joshi , Yasemin Altun , Nigel Collier , Julian Martin Eisenschlos
Download a PDF of the paper titled MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering, by Fangyu Liu and 8 other authors
Download PDF

    Abstract: Visual language data such as plots, charts, and infographics are ubiquitous in the human world. However, state-of-the-art vision-language models do not perform well on these data. We propose MatCha (Math reasoning and Chart derendering pretraining) to enhance visual language models' capabilities in jointly modeling charts/plots and language data. Specifically, we propose several pretraining tasks that cover plot deconstruction and numerical reasoning which are the key capabilities in visual language modeling.
    We perform the MatCha pretraining starting from Pix2Struct, a recently proposed image-to-text visual language model. On standard benchmarks such as PlotQA and ChartQA, the MatCha model outperforms state-of-the-art methods by as much as nearly 20%. We also examine how well MatCha pretraining transfers to domains such as screenshots, textbook diagrams, and document figures and observe overall improvement, verifying the usefulness of MatCha pretraining on broader visual language tasks. 

Comments: 	ACL 2023
Subjects: 	Computation and Language (cs.CL) ; Artificial Intelligence (cs.AI); Computer Vision and Pattern Recognition (cs.CV)
Cite as: 	arXiv:2212.09662 [cs.CL]
  	(or arXiv:2212.09662v2 [cs.CL] for this version)
  	https://doi.org/10.48550/arXiv.2212.09662
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Fangyu Liu [ view email ]
[v1] Mon, 19 Dec 2022 17:44:54 UTC (7,043 KB)
[v2] Tue, 23 May 2023 18:21:27 UTC (8,072 KB)
Full-text links:
Download:

    Download a PDF of the paper titled MatCha: Enhancing Visual Language Pretraining with Math Reasoning and Chart Derendering, by Fangyu Liu and 8 other authors
    PDF
    Other formats 

Current browse context:
cs.CL
< prev   |   next >
new | recent | 2212
Change to browse by:
cs
cs.AI
cs.CV
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

