

这是作者多年以来学习总结的笔记，经整理之后开源于世。考虑到正式出版的时间周期较长，而且书本购买成本高不利于技术广泛传播，因此作者采取开源的形式。 笔记内容仅供个人学习使用，非本人同意不得应用于商业领域。

笔记内容较多，可能有些总结的不到位的地方，欢迎大家探讨。联系方式:huaxz1986@163.com qq: 525875545

另有个人在 github 上的一些内容：

    "《算法导论》的C++实现"代码：https://github.com/huaxz1986/cplusplus-_Implementation_Of_Introduction_to_Algorithms
    《Unix 环境高级编程第三版》笔记：https://github.com/huaxz1986/APUE_notes

20230801 修订:

新增 36 篇关于 Prompt Engineering 的热门论文:
《Chain of Thought Prompting Elicits Reasoning in Large Language Models》
《Least-to-Most Prompting Enables Complex Reasoning in Large Language Models》
《Automatic Chain of Thought Prompting in Large Language Models》
《Self-Consistency Improves Chain of Thought Reasoning in Language Models》
《Large Language Models are Zero-Shot Reasoners》
《Calibrate Before Use: Improving Few-Shot Performance of Language Models》
《What Makes Good In-Context Examples for GPT-3?》
《Making Pre-trained Language Models Better Few-shot Learners》
《It’s Not Just Size That Matters: Small Language Models Are Also Few-Shot Learners》
《Exploiting Cloze-Questions for Few-Shot Text Classification and Natural Language Inference》
《GPT Understands, Too》
《P-Tuning v2: Prompt Tuning Can Be Comparable to Fine-tuning Universally Across Scales and Tasks》
《Prefix-Tuning: Optimizing Continuous Prompts for Generation》
《The Power of Scale for Parameter-Efficient Prompt Tuning》
《How Can We Know What Language Models Know?》
《Eliciting Knowledge from Language Models Using Automatically Generated Prompts》
《Fantastically Ordered Prompts and Where to Find Them: Overcoming Few-Shot Prompt Order Sensitivity》
《Can language models learn from explanations in context?》
《Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?》
《Multitask Prompted Training Enables Zero-Shot Task Generalization》
《Language Models as Knowledge Bases?》
《Do Prompt-Based Models Really Understand the Meaning of Their Prompts?》
《Finetuned Language Models Are Zero-Shot Learners》
《Factual Probing Is [MASK]: Learning vs. Learning to Recall》
《How many data points is a prompt worth?》
《Learning How to Ask: Querying LMs with Mixtures of Soft Prompts》
《Learning To Retrieve Prompts for In-Context Learning》
《PPT: Pre-trained Prompt Tuning for Few-shot Learning》
《Prompt Programming for Large Language Models: Beyond the Few-Shot Paradigm》
《Show Your Work: Scratchpads for Intermediate Computation with Language Models》
《True Few-Shot Learning with Language Models》
《Few-Shot Parameter-Efficient Fine-Tuning is Better and Cheaper than In-Context Learning》
《Improving and Simplifying Pattern Exploiting Training》
《MetaICL: Learning to Learn In Context》
《SPoT: Better Frozen Model Adaptation through Soft Prompt Transfer》
《Noisy Channel Language Model Prompting for Few-Shot Text Classification》
20230524 修订:
新增 Transformer 7、8、9 三章，包括：《Scaling Laws for Neural Language Models》、 《Training Compute-Optimal Large Language Models》、LLaMA、GLM、GLM-130B、 GPT-NeoX-20B、Bloom、PaLM、PaLM2、Self-Instruct 等十篇论文。
20230516 修订:
新增 HuggingFace Transformer 应用、Gradio。 所有 HuggingFace Transformer 官方教程和 API ， 包括 Tokenizer、Dataset、Trainer、Evaluator、Pipeline、Model、Accelerate、AutoClass、应用，等九章内容

历史更新请参考 这里
数学基础

    1.线性代数基础
        一、基本知识
        二、向量操作
        三、矩阵运算
        四、特殊函数
    2.概率论基础
        一、概率与分布
        二、期望和方差
        三、大数定律及中心极限定理
        五、常见概率分布
        六、先验分布与后验分布
        七、信息论
        八、其它
    3.数值计算基础
        一、数值稳定性
        二、梯度下降法
        三、二阶导数与海森矩阵
        四、牛顿法
        五、拟牛顿法
        六、 约束优化
    4.蒙特卡洛方法与 MCMC 采样
        一、蒙特卡洛方法
        二、马尔可夫链
        三、MCMC 采样

统计学习

    0.机器学习简介
        一、基本概念
        二、监督学习
        三、机器学习三要素
    1.线性代数基础
        一、线性回归
        二、广义线性模型
        三、对数几率回归
        四、线性判别分析
        五、感知机
    2.支持向量机
        一、 线性可分支持向量机
        二、线性支持向量机
        三、非线性支持向量机
        四、支持向量回归
        五、SVDD
        六、序列最小最优化方法
        七、其它讨论
    3.朴素贝叶斯
        一、贝叶斯定理
        二、朴素贝叶斯法
        三、半朴素贝叶斯分类器
        四、其它讨论
    4.决策树
        一、 原理
        二、 特征选择
        三、生成算法
        四、剪枝算法
        五、CART 树
        六、连续值、缺失值处理
        七、多变量决策树
    5.knn
        一、k 近邻算法
        二、 kd树
    6.集成学习
        一、集成学习误差
        二、 Boosting
        三、Bagging
        四、集成策略
        五、多样性分析
    7.梯度提升树
        一、提升树
        二、xgboost
        三、LightGBM
    8.特征工程
        一、缺失值处理
        二、特征编码
        三、数据标准化、正则化
        四、特征选择
        五、稀疏表示和字典学习
        六、多类分类问题
        七、类别不平衡问题
    9.模型评估
        一、泛化能力
        二、过拟合、欠拟合
        三、偏差方差分解
        四、参数估计准则
        五、泛化能力评估
        六、训练集、验证集、测试集
        七、性能度量
        八、超参数调节
        九、传统机器学习的挑战
    10.降维
        一、维度灾难
        二、主成分分析 PCA
        三、核化线性降维 KPCA
        四、流形学习
        五、度量学习
        六、概率PCA
        七、独立成分分析
        八、t-SNE
        九、LargeVis
    11.聚类
        一、性能度量
        二、原型聚类
        三、密度聚类
        四、层次聚类
        五、谱聚类
    12.半监督学习
        半监督学习
        一、生成式半监督学习方法
        二、半监督 SVM
        三、图半监督学习
        四、基于分歧的方法
        五、半监督聚类
        六、 总结
    13.EM算法
        一、示例
        二、EM算法原理
        三、EM算法与高斯混合模型
        四、EM 算法与 kmeans 模型
        五、EM 算法的推广
    14.最大熵算法
        一、最大熵模型MEM
        二、分类任务最大熵模型
        三、最大熵的学习
    15.隐马尔可夫模型
        一、隐马尔可夫模型HMM
        二、 HMM 基本问题
        三、 最大熵马尔科夫模型MEMM
    16.概率图与条件随机场
        一、概率图模型
        二、贝叶斯网络
        三、马尔可夫随机场
        四、条件随机场 CRF
    17.边际概率推断
        一、精确推断
        二、近似推断
    18.主题模型
        一、Unigram Model
        二、pLSA Model
        三、LDA Model
        四、LDA优化
        五、sentence-LDA
        六、模型讨论

深度学习

    0.深度学习简介
        一、 介绍
        二、历史
    1.深度前馈神经网络
        一、基础
        二、损失函数
        三、输出单元
        四、隐单元
        五、结构设计
        六、历史小记
    2.反向传播算法
        一、链式法则
        二、反向传播
        三、算法实现
        四、自动微分
    3.正则化
        一、参数范数正则化
        二、显式约束正则化
        三、数据集增强
        四、噪声鲁棒性
        五、早停
        六、参数相对约束
        七、dropout
        八、对抗训练
        九、正切传播算法
        十、其它相关
    4.最优化基础
        一、代价函数
        二、神经网络最优化挑战
        三、 mini-batch
        四、基本优化算法
        五、自适应学习率算法
        六、二阶近似方法
        七、共轭梯度法
        八、优化策略和元算法
        九、参数初始化策略
        十、Normalization
        十一、Online Learning
    5.卷积神经网络
        一、卷积运算
        二、卷积层、池化层
        三、基本卷积的变体
        四、应用
        五、 历史和现状
    5.卷积神经网络(图片分类)
        一、LeNet
        二、AlexNet
        三、VGG-Net
        四、Inception
        五、ResNet
        六、ResNet 变种
        七、SENet
        八、 DenseNet
        九、小型网络
    6.循环神经网络
        一、RNN计算图
        二、训练算法
        三、长期依赖
        四、常见 RNN 变种
    7.Transformer(1)
        一、Transformer[2017]
        二、Universal Transformer[2018]
        三、Transformer-XL[2019]
        四、GPT1[2018]
        五、GPT2[2019]
        六、GPT3[2020]
        七、OPT[2022]
    7.Transformer(2)
        八、BERT[2018]
        九、XLNet[2019]
        十、RoBERTa[2019]
        十一、ERNIE1.0 [2019]
        十二、ERNIE2.0 [2019]
        十三、ERNIE3.0 [2021]
        十四、ERNIE-Huawei [2019]
        十五、MT-DNN [2019]
        十六、BART [2019]
        十七、mBART[2020]
    7.Transformer(3)
        十八、SpanBERT [2019]
        十九、ALBERT [2019]
        二十、UniLM [2019]
        二十一、MASS [2019]
        二十二、MacBERT [2019]
        二十三、Fine-Tuning Language Models from Human Preferences [2019]
        二十四 Learning to summarize from human feedback[2020]
        二十五、InstructGPT [2022]
    7.Transformer(4)
        二十六、T5 [2020]
        二十七、mT5[2020]
        二十八、ExT5[2021]
        二十九、Muppet[2021]
        三十、Self-Attention with Relative Position Representations[2018]
    7.Transformer(5)
        三十一、USE[2018]
        三十二、Sentence-BERT[2019]
        三十三、SimCSE[2021]
        三十四、BERT-Flow[2020]
        三十五、BERT-Whitening [2021]
        三十六、Comparing the Geometry of BERT, ELMo, and GPT-2 Embeddings[2019]
        三十七、CERT [2020]
    7.Transformer(6)
        三十八、DeCLUTR[2020]
        三十九、CLEAR[2020]
        四十、ConSERT [2021]
        四十一、Sentence-T5[2021]
        四十二、ULMFiT[2018]
    7.Transformer(7)
        四十三、Scaling Laws for Neural Language Models[2020]
        四十四、Chinchilla[2022]
        四十五、LLaMA[2023]
        四十六、GLM[2021]
    7.Transformer(8)
        四十七、GLM-130B[2022]
        四十八、GPT-NeoX-20B[2022]
        四十九、Bloom[2022]
    7.Transformer(9)
        五十、PaLM[2022] （粗读）
        五十一、PaLM2[2023]（粗读）
        五十二、Self-Instruct[2022]
    8.句子向量
        一、Paragraph Vector[2014]
        二、Skip-Thought Vectors[2015]
        三、FastSent[2016]
        四、InferSent[2017]
        五、Simple-But-Tough-To-Beat Baseline For Sentence Embedding [2017]
        六、QuickThoughts[2018]
    8.词向量
        一、向量空间模型 VSM
        二、LSA
        三、Word2Vec
        四、GloVe
        五、FastText
        六、ELMo
    9.CTR 预估模型(传统方法)
        一、LR 模型[2007]
        二、POLY2 模型[2010]
        三、FM模型[2011]
        四、FFM模型[2016]
        五、GBDT-LR 模型[2014]
        六、FTRL工程应用[2013]
        七、LS-PLM 模型[2017]
    9.CTR 预估模型(神经网络方法 1)
        一、DSSM[2013]
        二、FNN[2016]
        三、PNN[2016]
        四、DeepCrossing[2016]
        五、Wide&Deep[2016]
        六、DCN[2017]
        七、DeepFM[2017]
        八、NFM[2017]
        九、AFM[2017]
        十、xDeepFM[2018]
        十一、ESMM[2018]
        十二、DIN[2017]
        十三、DIEN[2019]
        十四、DSIN[2019]
        十五、DICM[2017]
    9.CTR 预估模型(神经网络方法 2)
        十六、DeepMCP[2019]
        十七、MIMN[2019]
        十八、DMR[2020]
        十九、MiNet[2020]
        二十、DSTN[2019]
        二十一、BST[2019]
        二十二、SIM[2020]
        二十三、ESM2[2019]
        二十四、MV-DNN[2015]
        二十五、CAN[2020]
    9.CTR 预估模型(神经网络方法 3)
        二十六、AutoInt[2018]
        二十七、Fi-GNN[2019]
        二十八、FwFM[2018]
        二十九、FM2[2021]
        三十、FiBiNET[2019]
        三十一、AutoFIS[2020]
        三十二、DCN V2[2020]
    9.CTR 预估模型(神经网络方法 4)
        三十三、AFN [2020]
        三十四、FGCNN[2019]
        三十五、AutoCross[2019]
        三十六、InterHAt[2020]
        三十七、xDeepInt[2023]
        三十八、BarsCTR[2021]
    9.CTR 预估模型(神经网络方法 5)
        三十九、AutoDis[2021]
        四十、MDE[2020]
        四十一、NIS[2020]
        四十二、AutoEmb[2020]
        四十三、AutoDim[2021]
        四十四、PEP[2021]
        四十五、DeepLight[2021]
    10.Graph Embedding(1)
        一、DeepWalk[2014]
        二、LINE[2015]
        三、GraRep[2015]
        四、TADW[2015]
        五、DNGR[2016]
        六、Node2Vec[2016]
        七、WALKLETS[2016]
        八、SDNE[2016]
        九、CANE[2017]
        十、EOE[2017]
        十一、metapath2vec[2017]
        十二、GraphGAN[2018]
        十三、struc2vec[2017]
        十四、GraphWave[2018]
        十五、NetMF[2017]
        十六、NetSMF[2019]
    10.Graph Embedding(2)
        十七、PTE[2015]
        十八、HNE[2015]
        十九、AANE[2017]
        二十、LANE[2017]
        二十一、MVE[2017]
        二十二、PMNE[2017]
        二十三、ANRL[2018]
        二十四、DANE[2018]
        二十五、HERec[2018]
        二十六、GATNE[2019]
        二十七、MNE[2018]
        二十八、MVN2VEC[2018]
        二十九、SNE[2018]
        三十、ProNE[2019]
    10.Graph Embedding(综述)
        一、A Comprehensive Survey of Graph Embedding[2017]
        二、Graph Embedding Techniques, Applications, and Performance[2017]
        三、Representation Learning on Graphs[2017]
    11.图神经网络(1)
        一、GNN[2009]
        二、Spectral Networks & Deep Locally Connected Networks [2013]
        三、Fast Localized Spectral Filtering On Graph[2016]
        四、GCN[2016]
        六、GGS-NN[2016]
        七、PATCHY-SAN[2016]
        八、GraphSAGE[2017]
        九、GAT[2017]
        十、R-GCN[2017]
        十一、 AGCN[2018]
        十二、FastGCN[2018]
        十三、PinSage[2018]
    11.图神经网络(2)
        十四、GCMC[2017]
        十五、JK-Net[2018]
        十六、PPNP[2018]
        十七、VRGCN[2017]
        十八、ClusterGCN[2019]
        十九、LDS-GNN[2019]
        二十、DIAL-GNN[2019]
        二十一、HAN[2019]
        二十二、HetGNN[2019]
        二十三、HGT[2020]
        二十四、GPT-GNN[2020]
        二十五、Geom-GCN[2020]
    11.图神经网络(3)
        二十六、Graph Network[2018]
        二十七、GIN[2019]
        二十八、MPNN[2017]
        二十九、UniMP[2020]
        三十、Correct and Smooth [2020]
        三十一、LGCN[2018]
        三十二、DGCNN[2018]
        三十三、AS-GCN
        三十四、DGI[2018]
        三十五、DIFFPOLL[2018]
        三十六、DCNN[2016]
        三十七、IN[2016]
    11.图神经网络(4)
        一、Deeper Insights into GCN[2018]
        二、GNNEXPLAINER[2019]
        三、GCN 自监督学习[2020]
        四、GNN 公平比较[2019]
        五、GNN 评估陷阱[2018]
        六、AGL [2020]
        七、AliGraph [2019]
    11.图神经网络(综述)
        一、Deep Learning On Graph[2018]
        二、GNN : A Review of Methods and Applications[2018]
        三、A Comprehensive Survey On GNN[2019]
    12.推荐算法(传统方法)
        一、Tapestry[1992]
        二、GroupLens[1994]
        三、ItemBased CF[2001]
        四、Amazon I-2-I CF[2003]
        五、Slope One Rating-Based CF[2005]
        六、Bipartite Network Projection[2007]
        七、Implicit Feedback CF[2008]
        八、PMF[2008]
        九、SVD++[2008]
        十、MMMF 扩展[2008]
        十一、OCCF[2008]
        十二、BPR[2009]
        十三、MF for RS[2009]
        十四、 Netflix BellKor Solution[2009]
    13.推荐算法（神经网络方法 1)
        一、MIND[2019]（用于召回）
        二、DNN For YouTube[2016]
        三、Recommending What Video to Watch Next[2019]
        四、ESAM[2020]
        五、Facebook Embedding Based Retrieval[2020]（用于检索）
        六、Airbnb Search Ranking[2018]
        七、MOBIUS[2019]（用于召回）
        八、TDM[2018]（用于检索）
        九、DR[2020]（用于检索）
        十、JTM[2019]（用于检索）
    13.推荐算法（神经网络方法 2)
        十一、Pinterest Recommender System[2017]
        十二、DLRM[2019]
        十三、Applying Deep Learning To Airbnb Search[2018]
        十四、Improving Deep Learning For Airbnb Search[2020]
        十五、HOP-Rec[2018]
        十六、NCF[2017]
        十七、NGCF[2019]
        十八、LightGCN[2020]
        十九、Sampling-Bias-Corrected Neural Modeling[2019]（检索）
        二十、EGES[2018]（Matching 阶段）
        二十一、SDM[2019]（Matching 阶段）
    13.推荐算法（神经网络方法 3)
        二十二、COLD[2020 ] (Pre-Ranking 模型)
        二十三、ComiRec[2020] (matching阶段)
        二十四、EdgeRec[2020]
        二十五、DPSR[2020]（检索）
        二十六、PDN[2021]（mathcing）
        二十七、时空周期兴趣学习网络ST-PIL[2021]
    14.推荐算法之序列推荐(1)
        一、FPMC[2010]
        二、GRU4Rec[2015]
        三、HRM[2015]
        四、DREAM[2016]
        五、Improved GRU4Rec[2016]
        六、NARM[2017]
        七、HRNN[2017]
    14.推荐算法之序列推荐(2)
        八、RRN[2017]
        九、Caser[2018]
        十、p-RNN[2016]
        十一、GRU4Rec Top-k Gains [2018]
        十二、SASRec[2018]
        十三、RUM[2018]
        十四、SHAN[2018]
    14.推荐算法之序列推荐(3)
        十五、Phased LSTM[2016]
        十六、Time-LSTM[2017]
        十七、STAMP[2018]
        十八、Latent Cross[2018]
        十九、CSRM[2019]
        二十、SR-GNN[2019]
        二十一、GC-SAN[2019]
        二十二、BERT4Rec[2019]
    14.推荐算法之序列推荐(4)
        二十三、MCPRN[2019]
        二十四、RepeatNet[2019]
        二十五、LINet(2019)
        二十六、NextItNet[2019]
        二十七、GCE-GNN[2020]
        二十八、LESSR[2020]
        二十九、HyperRec[2020]
        三十、DHCN[2021]
        三十一、TiSASRec[2020]
    15.推荐算法(综述)
        一、A Survey on Accuracy-oriented Neural Recommendation: From Collaborative Filtering to Information-rich Recommendation[2022]
    16.多任务学习
        一、MMOE[2018]
    17.系统架构
        一、Hidden Technical Debt[2015]
    18.工程实践指导原则
        一、性能度量
        二、默认的基准模型
        三、决定是否收集更多数据
        四、选择超参数
        五、调试策略
        六、示例：数字识别系统
        七、数据预处理
        八、变量初始化
        九、结构设计
    19.深度强化学习(1)
        一、PPO [2017]
    20.自动代码生成
        一、CodeGen[2022]
    21. Prompt 工程 (1)
        一、LAMA[2019]
        二、LPAQA [2019]
        三、AutoPrompt[2020]
        四、PET[2020]
        五、PET-2[2021]
        六、Do Prompt-Based Models Really Understand the Meaning of Their Prompts?[2021]
        七、How Many Data Points is a Prompt Worth[2021]
        八、Rethinking the Role of Demonstrations[2022]
        九、Overcoming Few-Shot Prompt Order Sensitivity [2021]
    21. Prompt 工程 (2)
        十、Calibrate Before Use[2021]
        十一、KATE [2021]
        十二、LM-BFF[2021]
        十三、EPR[2021]
        十四、ADAPET[2021]
        十五、Noisy Channel Prompt Tuning [2021]
        十六、True Few-Shot Learning with Language Models【2021】
    21. Prompt 工程 (3)
        十七、FLAN[2021]
        十八、T0[2021]
        十九、MetaPrompt[2021]
        二十、Scratchpad[2021]
        二十一、Can language models learn from explanations in context? [2022]
        二十二、COT[2022]
        二十三、Self-Consistency COT[2022]
        二十四、Zero-Shot CoT[2022]
        二十五、Auto COT[2022]
        二十六、Least-To-Most Prompting [2022]
    21. Prompt 工程 (4)
        二十七、Prefix-Tuning[2021]
        二十八、P-Tuning[2021]
        二十九、P-Tuning V2[2021]
        三十、The Power of Scale for Parameter-Efficient Prompt Tuning[2021]
        三十一、Querying LMs with Mixtures of Soft Prompts[2021]
        三十二、PPT[2021]
        三十三、SPOT[2021]
        三十四、OptiPrompt[2021]
    21. Prompt 工程 (5)
        三十五、T-Few[2022]
        三十六、MetaICL [ 2021]

工具
CRF

    CRF++
        一、安装
        二、使用
        三、Python接口
        四、常见错误

lightgbm

    lightgbm使用指南
        一、安装
        二、调参
        三、进阶
        四、API
        五、Docker

xgboost

    xgboost使用指南
        一、安装
        二、调参
        三、外存计算
        四、 GPU计算
        五、单调约束
        六、 DART booster
        七、Python API

scikit-learn

    1.预处理
        一、特征处理
        二、特征选择
        三、字典学习
        四、PipeLine
    2.降维
        一、PCA
        二、MDS
        三、Isomap
        四、LocallyLinearEmbedding
        五、FA
        六、FastICA
        七、t-SNE
    3.监督学习模型
        一、线性模型
        二、支持向量机
        三、贝叶斯模型
        四、决策树
        五、KNN
        六 、AdaBoost
        七、梯度提升树
        八、Random Forest
    4.模型评估
        一、数据集切分
        二、性能度量
        三、验证曲线 && 学习曲线
        四、超参数优化
    5.聚类模型
        一、KMeans
        二、DBSCAN
        三、MeanShift
        四、AgglomerativeClustering
        五、BIRCH
        六、GaussianMixture
        七、SpectralClustering
    6.半监督学习模型
        一、标签传播算法
    7.隐马尔可夫模型
        一、Hmmlearn
        二、seqlearn

spark

    1.基础概念
        一、核心概念
        二、安装和使用
        三、 pyspark shell
        四、独立应用
    2.rdd使用
        一、概述
        二、创建 RDD
        三、转换操作
        四、行动操作
        五、其他方法和属性
        六、持久化
        七、分区
        八、混洗
    3.dataframe使用
        一、概述
        二、SparkSession
        三、DataFrame 创建
        四、 DataFrame 保存
        五、DataFrame
        六、Row
        七、Column
        八、GroupedData
        九、functions
    4.累加器和广播变量
        一、累加器
        二、广播变量

numpy

    numpy 使用指南
        一、 ndarray
        二、 ufunc 函数
        三、 函数库
        四、数组的存储和加载

scipy

    scipy 使用指南
        一、 常数和特殊函数
        二、 拟合与优化
        三、线性代数
        四、 统计
        五、数值积分
        六、 稀疏矩阵

matplotlib

    matplotlib 使用指南
        一、matplotlib配置
        二、 matplotlib Artist
        三、基本概念
        四、布局
        五、 Path
        六、 path effect
        七、坐标变换
        八、 3D 绘图
        九、技巧

pandas

    pandas 使用指南
        一、基本数据结构
        二、 内部数据结构
        三、 下标存取
        四、 运算
        五、变换
        六、数据清洗
        七、 字符串操作
        八、 聚合与分组
        九、时间序列
        十、 DataFrame 绘图
        十一、 移动窗口函数
        十二、 数据加载和保存

huggingface_transformer

    一、Tokenizer
        一、Subword Tokenization 算法
        二、算法原理
        三、Hugging Face Tokenizer 库
        四、Tokenizer 库的应用
        五、Tokenizer in Transformers
    二、Datasets
        一、基本概念
        二、load_dataset() 原理
        三、API
    三、Model
        一、Configuration
        二、Data Collator
        三、Models
        四、Model outputs
    四、Trainer
        一、Trainer
        二、Callbacks
        三、Keras callbacks
        四、Logger
        五、Optimization
        六、Processors
        七、分享预训练的模型
        八、示例
    五、Evaluator
        一、基本概念
        二、API
    六、Pipeline
        一、基本概念
        二、pipeline abstraction
        三、实现一个新的 pipeline
        四、API
    七、Accelerate
        一、基础概念
        二、API
    八、Autoclass
        一、基本概念
        二、API
    九、应用
        一、Token classification
        二、微调 Masked Language Model
        三、从头开始训练因果语言模型
        四、文本摘要
        五、翻译
        六、问答
    十、Gradio
        一、基础概念
        二、高级功能
        三、示例

Scala

    环境搭建
        一、安装 scala
        二、安装 Jupyter 支持
        三、Scala 解释器
        四、IntelliJ 使用
        五、Maven 使用
    基础知识
        一、Scala 特点
        二、入门
        三、For 表达式
    函数
        一、函数定义
        二、函数分类
        三、闭包
        四、递归函数
        五、自定义控制结构
    类
        一、类的定义
        二、单例对象
        三、访问级别
        四、继承
        五、Trait
        五、包和导入
        五、隐式类型转换
        六、编译和执行
        七、可变对象
        八、类型参数化
        九、抽象成员
        十、模块化编程
        十一、对象相等性
    样式类和模式匹配
        一、样例类
        二、模式匹配
        三、Option 类型
        四、一切皆模式
        五、提取器
    测试和注解
        一、断言
        二、测试
        三、注解
    集合collection
        一、Traversable
        二、Iterable
        三、Seq
        四、LinearSeq/IndexedSeq
        五、Buffer
        六、Array
        七、List
        八、ListBuffer/ArrayBuffer
        九、Set
        十、Map
        十一、String&StringOps
        十二、元组
        十三、其它不可变集合
        十四、其它可变集合
        十五、性能
    集合collection(二)
        一、视图
        二、迭代器
        三、集合相等性
        四、创建集合对象
        五、List 原理
        六、Java 和 Scala 集合
        七、Scala 集合框架
    集成Java
        一、通用规则
        二、特殊规则
        三、注解
        四、通配类型
        五、同时编译 Scala 和 Java
        六、Scala2.12 和 Java 8 的集成
    并发
        一、基本概念
        二、使用 Future
        三、测试

