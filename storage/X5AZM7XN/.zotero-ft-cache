Under review

arXiv:2111.10657v2 [cs.LG] 23 Nov 2021

GENERALIZING GRAPH NEURAL NETWORKS ON OUTOF-DISTRIBUTION GRAPHS

Shaohua Fan, Xiao Wang, Chuan Shi Department of Computer Science Beijing University of Posts and Telecommunications Beijing, China
{fanshaohua,xiaowang,shichuan}@bupt.edu.cn

Peng Cui Department of Computer Science and Technology Tsinghua University Beijing, China
cuip@tsinghua.edu.cn

Bai Wang Department of Computer Science Beijing University of Posts and Telecommunications Beijing, China
wangbai@bupt.edu.cn

ABSTRACT
Graph Neural Networks (GNNs) are proposed without considering the agnostic distribution shifts between training graphs and testing graphs, inducing the degeneration of the generalization ability of GNNs on Out-Of-Distribution (OOD) settings. The fundamental reason for such degeneration is that most GNNs are developed based on the I.I.D hypothesis. In such a setting, GNNs tend to exploit subtle statistical correlations existing in the training set for predictions, even though it is a spurious correlation. This learning mechanism inherits from the common characteristics of machine learning approaches. However, such spurious correlations may change in the wild testing environments, leading to the failure of GNNs. Therefore, eliminating the impact of spurious correlations is crucial for stable GNN models. To this end, in this paper, we argue that the spurious correlation exists among subgraph-level units and analyze the degeneration of GNN in causal view. Based on the causal view analysis, we propose a general causal representation framework for stable GNN, called StableGNN. The main idea of this framework is to extract high-level representations from raw graph data ﬁrst and resort to the distinguishing ability of causal inference to help the model get rid of spurious correlations. Particularly, to extract meaningful high-level representations, we exploit a differentiable graph pooling layer to extract subgraph-based representations by an end-to-end manner. Furthermore, inspired by the confounder balancing techniques from causal inference, based on the learned high-level representations, we propose a causal variable distinguishing regularizer to correct the biased training distribution by learning a set of sample weights. Hence, GNNs would concentrate more on the true connection between discriminative substructures and labels. Extensive experiments are conducted on both synthetic datasets with various distribution shift degrees and eight real-world OOD graph datasets. The results well verify that the proposed model StableGNN not only outperforms the state-of-the-arts but also provides a ﬂexible framework to enhance existing GNNs. In addition, the interpretability experiments validate that StableGNN could leverage causal structures for predictions.
1 INTRODUCTION
Graph Neural Networks (GNNs) are powerful deep learning algorithms on graphs with various applications (Scarselli et al., 2008; Kipf & Welling, 2016; Velicˇkovic´ et al., 2017; Hamilton et al., 2017). One major category of applications is the predictive task over entire graphs, i.e., graph-level task, such as molecular graph property prediction (Hu et al., 2020; Lee et al., 2018; Ying et al., 2018), scene graph classiﬁcation (Pope et al., 2019), and social network category classiﬁcation (Zhang et al.,
1

Under review

Testing Graphs

Baseline (GCN)

Correlation (Star) Motif

StableGNN (Ours)

Causal (House) Motif

Figure 1: Visualization of subgraph importance for “house” motif classiﬁcation task, produced by the vanilla GCN model and StableGNN when most of training graphs containing “house” motifs with “star” motifs. The red subgraph indicates the most important subgraph used by the model for prediction (generated by GNNExplainer (Ying et al., 2019)). Due to the spurious correlation, the GCN model tends to focus more on “star” motifs while our model focuses mostly on “house” motifs. For more cases of testing graph, please refer to Figure 5.
2018; Ying et al., 2018), etc. The success could be attributed to the non-linear modeling capability of GNNs, which extracts the useful information from raw graph data and encodes them into the graph representation in a data-driven fashion.
The basic learning diagram of existing GNNs is to learn the parameters of GNNs from the training graphs, and then make predictions on unseen testing graphs. The most fundamental assumption to guarantee the success of such learning diagram is the I.I.D. hypothesis, i.e., training and testing graphs are independently sampled from the identical distribution (Liao et al., 2020). However, in reality, such a hypothesis is hardly satisﬁed due to the uncontrollable generation mechanism of real data, such as data selection biases, confounder factors or other peculiarities (Bengio et al., 2019; Engstrom et al., 2019; Su et al., 2019; Hendrycks & Dietterich, 2019). The testing distribution may incur uncontrolled and unknown shifts from the training distribution, called Out-Of-Distribution (OOD) shifts (Sun et al., 2019; Krueger et al., 2021), which makes most GNN models fail to make stable predictions. As reported by OGB benchmark (Hu et al., 2020), GNN methods will occur a degeneration of 5.66% to 20% points when splitting the datasets according to the OOD settings, i.e., splitting structurally different graphs into training and testing sets.
Essentially, for general machine learning models, when there incurs a distribution shift, the main reason for the degeneration of accuracy is the spurious correlation between the irrelevant features and the category labels. This kind of spurious correlations is intrinsically caused by the unexpected correlations between irrelevant features and relevant features for a given category (Zhang et al., 2021; Lake et al., 2017; Lopez-Paz et al., 2017). For graph-level tasks that we focus on in this paper, as the predicted properties of graphs are usually determined by the subgraph units (e.g., groups of atoms and chemical bonds representing functional units in a molecule) (Ying et al., 2018; 2019; Jin et al., 2020), we deﬁne one subgraph unit could be one relevant feature or irrelevent feature with graph label. Taking the classiﬁcation task of “house” motif as an example, as depicted in Figure 1, where the label of graph is labeled by whether the graph has a "house" motif and the ﬁrst column represents the testing graphs. The GCN model is trained on the dataset where “house” motifs coexist with “star” motifs in most training graphs. With this dataset, the structural features of “house” motifs and “star” motifs would be strongly correlated. This unexpected correlation leads to spurious correlation
2

Under review
between structural features of “star” motifs with the label “house”. And the second column of Figure 1 shows the visualization of the most importance subgraph used by the GCN for prediction (shown with red color and generated by GNNExplainer (Ying et al., 2019)). As a result, the GCN model tends to use such spurious correlation, i.e., "star" motif, for prediction. When encountering graphs without “star” motif, or other motifs (e.g., “diamond” motifs) with “star” motifs, the model is prone to make false predictions (See Section 5.1).
To improve the OOD generalization ability of GNNs, one important way is to make GNNs get rid of such subgraph-level spurious correlation. However, it is not a trivial task, which will face the two following challenges: (1) How to explicitly encode the subgraph-level information into graph representation? As the spurious correlation usually exists between subgraphs, it is necessary to encode such subgraph information into the graph representation, so that we could develop decorrelation method based on the subgraph-level representation. (2) How to remove the spurious correlation among the subgraph-level representations? The nodes in same type of subgraph units may exist correlation, for example, the information of ‘N’ atom and ‘O’ atom in ‘NO2’ groups of molecular graphs may be encoded into different dimensions of learned embedding, but they act as an integrated whole and such correlations are stable across unseen testing distributions. Hence, we should not remove the correlation between the interior variables of one kind of subgraphs and only need to remove the spurious correlation between subgraph-level variables.
To address these two challenges, we propose a novel causal representation framework for graph, called StableGNN, which takes the advantages of both the ﬂexible representation ability of GNNs and the distinguishing ability for spurious correlations of causal inference methods. In terms of the ﬁrst challenge, we propose a graph high-level variable learning module that employs a graph pooling layer to map nearby nodes to a set of clusters, where each cluster will be one densely-connected subgraph unit of original graph. Moreover, we theoretically prove that the semantic meanings of clusters would be aligned across graphs by a ordered concatenation operation. Given the aligned high-level variables, to overcome the second challenge, we analyze the degeneration of GNNs in causal view and propose a novel causal variable distinguishing regularizer to decorrelate each high-level variable pair by learning a set of sample weights. These two modules are jointly optimized in our framework. Furthermore, as shown in Figure 1, StableGNN can effectively partial out the irrelevant subgraphs (i.e., “star” motif) and leverage truly relevant subgraphs (i.e., “house” motif) for predictions.
In summary, the major contributions of the paper are as follows:
• To our best knowledge, we ﬁrstly study the OOD generalization problem on GNNs for graphlevel task, which is a key direction to apply GNNs to wild non-stationary environments.
• We propose a general causal representation learning framework for GNNs, jointly learning the high-level representation with the causal variable distinguisher, which could learn an invariant relationship between the graph causal variables with the labels. And our framework is general to be adopted to various base GNN models to help them get rid of spurious correlations.
• Comprehensive experiments are conducted on both synthetic datasets and real-world OOD graph datasets. The effectiveness, ﬂexibility and interpretability of the proposed framework have been well validated with the convincing results.
2 RELATED WORK
In this section, we discuss three main categories closely related with our work: graph neural networks, causal representation learning and stable learning.
2.1 GRAPH NEURAL NETWORKS
Graph neural networks are powerful deep neural networks that could perform on graph data directly (Scarselli et al., 2008; Kipf & Welling, 2016; Velicˇkovic´ et al., 2017; Hamilton et al., 2017; Zhang et al., 2018; Lee et al., 2018). Most of these approaches ﬁt within the framework of “neural message passing” (Gilmer et al., 2017). In the message passing framework, a GNN is regarded as a message passing algorithm where node representations are iteratively calculated from the features of their neighborhood nodes using a differentiable aggregation function. GNNs have been applied
3

Under review
to a wide variety of tasks, including node classiﬁcation (Kipf & Welling, 2016; Velicˇkovic´ et al., 2017; Hamilton et al., 2017; Bo et al., 2021), link prediction (Schlichtkrull et al., 2018; Zhang & Chen, 2018), and graph classiﬁcation (Zhang et al., 2018; Lee et al., 2018). For graph classiﬁcation, the task we majorly focus on here, the major challenge in applying GNNs is how to generate the representation of the entire graph. Common approaches to this problem is simply summing up or averaging all the node embedding in ﬁnal layer. Several literatures argue that such simply operation will greatly ignore high-level structure that might be presented in the graph, and then propose to learn the hierarchical structure of graph in an end-to-end manner (Zhang et al., 2018; Ying et al., 2018; Lee et al., 2019; Gao & Ji, 2019). Although these methods have achieved remarkable results in I.I.D setting, they largely ignore the generalization ability in OOD setting, which is crucial for real applications.
2.2 CAUSAL REPRESENTATION LEARNING
Recently, Schölkopf et al. (Schölkopf et al., 2021) publish a survey paper, towards causal representation learning, and point out that causality, with its focus on representing structural knowledge about the data generating process that allows interventions and changes, can contribute towards understanding and resolving some limitations of current machine learning methods. Traditional causal discovery and reasoning assume that the units are random variables connected by a causal graph. However, real-world observations are not structured into these units, for example, graph data we focus on is a kind of unstructured data. Thus for this kind of data, causal representation learning generally consists of two steps: (1) inferring the abstract/high-level causal variables from available low-level input features, and (2) leveraging the causal knowledge as inductive bias to learn the causal structure of high-level variables. After learning the causal system, the causal relationship is robust to irrelevant interventions and changes on data distributions. Based on this idea, Invariant Risk Minimization (IRM) framework (Arjovsky et al., 2019; Rosenfeld et al., 2020; Kamath et al., 2021) proposes a regularization that enforce model learn an invariant representation across environments. The representation learning part plays the role of extracting high-level representation from low-level raw features, and the regularization encodes the causal knowledge that causal representation should be invariant across environments into the representation learning. Despite the IRM framework could learn the representations that have better OOD generalization ability, the requirement that domains should be labeled hinders the IRM methods from real applications. To overcome such dilemma, some methods are proposed to implicitly learn domains from data (Qiao et al., 2020; Matsuura & Harada, 2020; Wang et al., 2019), but they implicitly assume the training data is formed by balanced sampling from latent domains. However, in reality, due to the uncontrollable data generation process, the assumption could be easily violated, leading to the degeneration of these methods. More importantly, all these methods are mainly designed for tabular or image data, thus they cannot capture the intrinsic properties of graphs.
2.3 STABLE LEARNING
To improve the feasibility of IRM based methods, a series of researches on stable learning are proposed (Kuang et al., 2018; 2020). These methods mainly bring the ideas from the causal effect estimation (Angrist & Imbens, 1995) into machine learning models. Particularly, Shen et al. (Shen et al., 2018) propose a global confounding balancing regularizer that helps the logistic regression model to identify causal features, whose causal effect on outcome are stable across domains. To make the confounder balancing much easier in high-dimensional scenario, Kuang et al. (Kuang et al., 2018) utilize the autoencoder to encode the high-dimensional features into low-dimensional representation. Furthermore, (Kuang et al., 2020) and (Shen et al., 2020) demonstrate that decorrelating relevant and irrelevant features can make a linear model produce stable prediction under distribution shifts. The decorrelation operation actually has the same effect with confounder balancing, as the global confounder balancing regularizer tends to make every pair of treatment and confounder independent. But they are all developed based on the linear framework. Recently, Zhang et al. (Zhang et al., 2021) extend decorrelation into deep CNN model to tackle more complicated data types like images. This method pays much attention to eliminating the non-linear dependence among features, but the feature learning part is largely ignored. We argue that it is important to develop an effective high-level representation learning method to extract variables with appropriate granularity for the targeted task, so that the causal variable distinguishing part could develop on meaningful causal variables.
4

Under review

Z

M

Y

G

Figure 2: Causal graph for data generation process. Gray nodes and white nodes mean the unobserved latent variables and the observed variables, respectively.
3 PROBLEM FORMULATION
Notations. In our paper, for a vector v, vi represents the i-th element of v. For any matrix X, let Xi, and X,j represent the i-th row and the j-th column in X, respectively. Xi,j represents the j-th element of i-th row vector of X. X,j∶k means the submatrix of X from j-th column to (k − 1)-th column. And for any italic uppercase letter, such as X, it will represent a random variable.
Problem 1. OOD Generalization Problem on Graphs. Given the training graphs Gtrain = {(G1, Y1), ⋯, (Gn, Yn)}, where Gi means the i-th graph data in training set and Yi is the corresponding label, the task is to learn a GNN model hθ(⋅) with parameter θ to precisely predict the label of testing graphs Gtest, where the distribution Ψ(Gtrain) ≠ Ψ(Gtest). And in the OOD setting, we do not know the distribution shifts from training graphs to unseen testing graphs.
We utilize a causal graph of the data generation process, as shown in Figure 2, to illustrate the fundamental reason to cause the distribution shifts on graphs. As illustrated in the ﬁgure, the observed graph data G is generated by the unobserved latent cause Z and M . Z is a set of relevant variables and the label Y is mainly determined by Z. M is a set of irrelevant variables which does not decisive for label Y . During the unseen testing process in the real world, the variable M could change, but the causal relationship P(Y |Z) is invariant across environments. Taking the classifying mutagenic property of a molecular graph (Luo et al., 2020) as an example, G is a molecular graph where the nodes are atoms and the edges are the chemical bonds between atoms, and Y is the class label, e.g., whether the molecule is mutagenic or not. The whole molecular graph G is an effect of relevant latent causes Z such as the factors to generate nitrogen dioxide (NO2) group, which has an determinative effect on the mutagenicity of molecule, and the effect of irrelevant variable M , such as the carbon ring which exist more frequently in mutagenic molecule but not determinative (Luo et al., 2020). If we aim to learn a GNN model that is robust to unseen change on M , such as carbon exists in the non-mutagenic molecule, one possible way is to develop a representation function f (⋅) to recover Z and M from G, and learn a classiﬁer g(⋅) based on Z, so that the invariant causal relationship P (Y ∣Z) could be learned.
4 THE PROPOSED METHOD
4.1 OVERVIEW
The basic idea of our framework is to design a causal representation learning method that could extract meaningful graph high-level variables and estimate their true causal effects for graph-level tasks. As depicted in Figure 3, the proposed framework mainly consists of two components: the graph highlevel variable learning component and causal variable distinguishing component. The graph high-level variable learning component ﬁrst employs a graph pooling layer that learns the node embedding and maps nearby nodes into a set of clusters. Then we get the cluster-level embeddings through aggregating the node embeddings in the same cluster, and align the cluster semantic space across
5

Under review

Input graphs

DiffPool layer 1 DiffPool layer 2 Semantic alignment

Sample weights learning

Weighted GNN

Kernel Kernel

HSIC

Sample Weights

...

Classifier

Prediction Prediction Elementwise Loss Multiplication
Label

Weighted Loss

Graph high-level variable learning

Causal variable distinguishing

Figure 3: The overall architecture of the proposed StableGNN.

graphs through an ordered concatenation operation. The cluster-level embeddings act as the high-level variables for graphs. After obtaining the high-level variables, we develop a sample reweighting component based on Hilbert-Schmidt Independence Criterion (HSIC) measure to learn a set of sample weights that could remove the non-linear dependences among multiple multi-dimensional embeddings. As the learned sample weights could generate a pseudo-distribution with less spurious correlation among cluster-level variables, we utilize the weights to reweight the GNN loss. Thus the GNN model trained on this less biased pseudo-data could estimate causal effect of each high-level variable with the label more precisely, resulting in better generalization ability in wild environments.

4.2 GRAPH HIGH-LEVEL VARIABLE LEARNING
As the goal of this component is to learn a representation that could represent original subgraph unit explicitly, we adopt a differentiable graph pooling layer that could map densely-connected subgraphs into clusters by an end-to-end manner. And then we theoretically prove that the semantic meaning of the learned high-level representations could be aligned by a simple ordered concatenation operation.

High-level Variable Pooling. To learn node embedding as well as map densely connected subgraphs
into clusters, we exploit the DiffPool layer (Ying et al., 2018) to achieve this goal by learning a cluster
assignment matrix based on the learned embedding in each pooling layer. Particularly, as GNNs
could smooth the node representations and make the representation more discriminative, given the input adjacency matrix A, also denoted as A(0) in this context, and the node features F of a graph, we ﬁrst use an embedding GNN module to get the smoothed embeddings F(0):

F(0) = GNN(e0m)bed(A(0), F),

(1)

where GNN(e0m)bed(⋅, ⋅) is a three-layer GNN module, and the GNN layer could be GCN (Kipf & Welling, 2016), GraphSAGE (Hamilton et al., 2017), or others. Then we develop a pooling layer

based on the smoothed representation F(0). In particular, we ﬁrst generate node representation at

layer 1 as follows:

Z(1) = GNN(e1m)bed(A(0), F(0)).

(2)

As nodes in the same subgraph would have similar node features and neighbor structure and GNN
could map the nodes with similar features and structural information into similar representation, we also take the node embeddings F(0) and adjacency matrix A(0) into a pooling GNN to generate a cluster assignment matrix at layer 1, i.e., the clusters of original graph:

S(1) = softmax(GNN(p1oo)l(A(0), F(0))),

(3)

6

Under review

where S(1) ∈ Rn0×n1 , and S(i,1) represents the cluster assignment vector of i-th node, and S(,j1) corresponds to the all nodes’ assignment probabilities on j-th cluster at the layer 1. GNN(p1oo)l(⋅, ⋅) is also a three-layer GNN module, and the output dimension of GNN(p1oo)l(⋅, ⋅) is a pre-deﬁned maximum number of clusters at layer 1 and is a hyperparameter. And the appropriate number of clusters could
be learned in an end-to-end manner. The maximum number of clusters in the last pooling layer
should be the number of high-level variables we aim to extract. The softmax function is applied in a
row-wise fashion to generate the cluster assignment probabilities for each node at layer 1.

After obtaining the assignment matrix S(1), we could know the assignment probability of each node on the predeﬁned clusters. Hence, based on the assignment matrix S(1) and learned the node embedding matrix Z(1), we could the a new coarsened graph, where the nodes are the clusters learned
by this layer and edges are the connectivity strength between each pair of clusters. Particularly, the
new matrix of embeddings is calculated by the following equation:

F(1) = S(1)TZ(1) ∈ Rn1×d.

(4)

This equation aggregates the node embedding Z(1) according to the cluster assignment S(1), generat-

ing embeddings for each of the n1 clusters. Similarly, we generate a coarsened adjacency matrix as

follows.

A(1) = S(1)TA(1)S(1) ∈ Rn1×n1 .

(5)

For all the operations with superscript (1), it is one DiffPool unit and it is denoted as
(A(1), F(1) = DiffPool(A(0), F(0)). For any DiffPool layer l, it could be denoted as (A(l), F(l)) = DiffPool(A(l−1), F(l−1)). In particular, we could stack multiple DiffPool layers to extract the deep
hierarchical structure of the graph.

High-level Representation Alignment. After stacking L graph pooling layers, we could get the most high-level cluster embedding F(L) ∈ RnL×d, where F(i,L) represents the i-th high-level representation of the corresponding subgraph in the original graph. As our target is to encode subgraph information into graph representation and F(L) has explicitly encoded each densely-conntected subgraph information into each row of F(L), we propose to utilize the embedding matrix F(L) to
represent the high-level variables. However, due to the Non-Euclidean property of graph data, for the i-th learned high-level representations F̂ (i,L) and F̃ (i,L) from two graphs Ĝ and G̃, respectively, their semantic meaning may not matched, e.g., F̂ (i,L) and F̃ (i,L) may represent ring carbon and NO2 group in two molecular graphs, respectively. To match the semantic meaning of learned high-level
representation across graphs, we propose to concatenate the high-level variables by the order of row
index of high-level embedding matrix for each graph:

h = concat(F(1L, ), F(2L, ), ⋯, F(nLL),),

(6)

where h ∈ RnLd and concat(⋅) means concatenation operation by the row axis. Moreover, we

stack m high-level representations for a mini-batch with m graphs to obtain the embedding matrix

H ∈ Rm×nLd:

H = stack(h1, h2, ⋯, hm),

(7)

where stack(⋅) means the stacking operation by the row axis, and Hi, means the high-level represen-

tation for the i-th graph in the mini-batch. Hi,(k−1)d∶kd means k-th high-level representation of i-th graph. Hence, to prove the semantic alignment of any two high-level representations Hi, and Hj,,

we need to demonstrate that the semantic meanings of Hi,(k−1)d∶kd and Hj,(k−1)d∶kd are aligned for all k ∈ [1, nL]. To this end, we ﬁrst prove the permutation invariant property of DiffPool layer.

Lemma 1. Permutation Invariance (Ying et al., 2018). Given any permutation matrix P ∈
{0, 1}n×n, if P ⋅ GNN(A, F) = GNN(PAPT, PF) (i.e., the GNN method used is permutation equivariant), then DiffPool(A, F) = DiffPool(PAPT, PF).

Proof.

Following (Keriven & Peyré, 2019), a function f

∶

n×d
R

→ Rn×l:

is invariant if f (F, X) =

f (PFPT, PF), i.e, the permutation will not change node representation and the node order in the

7

Under review

learned

matrix.

A

function

f

∶

n×d
R

→

Rn×l:

is

equivariant

if

f (A, F)

=

P

⋅

f (PAPT, PF),

i.e,

the

permutation will not change the node representation but the order of nodes in matrix will be permuted.

The permutation invariant aggregator functions such as mean pooling and max pooling ensures that

the basic model can be trained and applied to arbitrarily ordered node neighborhood feature sets,

i.e, permutation equivariant. Therefore, the Eq. (2) and (3) are the permutation equivariant by the

assumption that the GNN module is permutation equivariant. And since any permutation matrix is

orthogonal, i.e., PTP = I, applying this into Eq. (4) and (5), we have:

F(1) = S(1)TPTPZ(1),

(8)

A(1) = S(1)TPTPA(1)PPTS(1).

(9)

Hence, DiffPool layer is permutation invariant.

After proving the permutation invariant property of single graph, we then illustrate the theoretical results for the semantic alignment of learned high-level representation across graphs.
Theorem 1. Semantic Alignment of High-level Variables. Given any two graphs Gi = (Ai, Fi) and Gj = (Aj, Fj), the semantic space of high-level representations Hi, and Hj, learned by a series of shared DiffPool layers is aligned.

Proof. WL-test (Leman & Weisfeiler, 1968) is widely used in graph isomorphism checking: if two graphs are isomorphic, they will have the same multiset of WL colors at any iteration. GNNs could be viewed a continuous approximation to the WL test, where they both aggregate signal from neighbors and the trainable neural network aggregators is analogy to hash function in WL-test (Zhang et al., 2018). Therefore, the outputs of GNN module are exactly the continuous WL colors. Then the embeddings value between any two graphs in the same layer will be in the same WL color space. The color space would represent a semantic space. Hence, the semantic meaning of each column of the learned assignment matrices S(il) and S(jl) of graphs Gi and Gi would be aligned, e.g., the k-th column would represent carbon ring structure in all molecule graphs. Due to the permutation invariant property of DiffPool layer, according to Eq. (8), the input graph with any node order will map its carbon ring structure signal into the k-th high-level representation, i.e., the k-th high-level representation of Hi,(k−1)d∶kd and Hj,(k−1)d∶kd. Hence, the semantic meaning of Hi,. and Hj,. is aligned.
4.3 CAUSAL VARIABLE DISTINGUISHING REGULARIZER
So far the variable learning part extracts all the high-level representations for all the densely-connected subgraphs regardless of whether it is relevant with the graph label due to causal relation or spurious correlation. In this section, we ﬁrst analyze the reason leading to the degeneration of GNNs on OOD scenarios in causal view and then propose the Causal Variable Distinguishing (CVD) regularizer with sample reweighting technique.

X

...

T

Y

T

Y

(a) Confounder balancing frame-(b) Multiple multi-dimensional

work.

confounder balancing framework.

Figure 4: Causal view on GNNs.

8

Under review

Revisiting on GNNs in Causal View. As described in Section 3, our target is to learn a classiﬁer g(⋅) based on the relevant variable Z. To this end, we need to distinguish which variable of learned high-

level representation H belongs to Z or M . The major difference of Z and M is whether they have

casual effect on Y . For a graph-level classiﬁcation task, after learning the graph representation, it will

be fed into a classiﬁer to predict its label. The prediction process could be represented by the causal

graph with three variables and their relationships, as shown in Figure 4(a), where T is a treatment

variable, Y is label/outcome variable, and X is the confounder variable, which has effect both on

treatment variable and outcome variable. The path T → Y represents the target of GNNs that aims to

estimate the causal effect of the one learned variable T (e.g., i-th high-level representation H,(i−1)d∶id ) on Y . Meanwhile, other learned variables (e.g., j-th high-level representation H,(j−1)d∶jd) will act as counfounder X. Due to the existence of spurious correlation of subgraphs, there has spurious
correlation between their learned embeddings. Hence, there incurs a path between X and T . 1 And

because GNNs also employ the confounder (e.g., the representation of carbon ring) for prediction,

there exists a path X → Y . Hence, these two paths form a backdoor path between X and Y (i.e.,

T ← X → Y ) and induce the spurious correlation between T and Y . And the spurious correlation

will amplify the true correlation between treatment variable and label, and may change in testing

environments. Under this scenario, existing GNNs cannot estimate the causal effect of subgraphs

accurately, so the performance of GNNs will be degenerate when the spurious correlation change

in the testing phase. Confounding balancing techniques (Hainmueller, 2012; Zubizarreta, 2015)

correct the non-random assignment of treatment variable by balancing the distributions of confounder

across different treatment levels. Because moments can uniquely determine a distribution, confounder

balancing methods directly balance the confounder moments by adjusting weights of samples (Athey

et al., 2016; Hainmueller, 2012). The sample weights w for binary treatment scenario are learnt by:

w = arg min ∣∣

wi ⋅ Xi, −

wj ⋅ Xj,∣∣22,

(10)

w

i∶Ti =1

j∶Tj =0

where X is the confounder matrix and Xi, is the confounder vector for i-th graph. Given a binary treatment feature T , ∑i∶Ti=1 wi ⋅ Xi, and ∑j∶Tj=0 wj ⋅ Xj, refer to the mean value of confounders
on samples with and without treatment, respectively. After confounder balancing, the dependence

between X and T (i.e., T ← X) would be eliminated, thus the correlation between the treatment

variable and the output variable will represent the causal effect (i.e., X → Y ).

Moreover, for a GNN model, we have little prior knowledge on causal relationships between the
learned high-level variables {H,0∶d, ⋯, H,(nL−1)d∶nLd}, thus have to set each learned high-level variable as treatment variable one by one, and the remaining high-level variables are viewed as con-
founding variables, e.g, H,0∶d is set as treatment variable and {H,d∶2d, ⋯, H,(nL−1)d∶nLd} are set as confounders. Note that for a particular treatment variable, previous confounder balancing techniques

are mainly designed for a single-dimensional treatment feature as well as the confounder usually

consists of multiple variables where each variable is a single-dimensional feature. In our scenario,

however, as depicted in Figure 4(b), we should deal with the confounders which are composed of mul-
tiple multi-dimensional confounder variables {X(1), ⋯, X(p)}, where each multi-dimensional confounder variable corresponds to one of learned high-level representations {H,0∶d, ⋯, H,(nL−1)d∶nLd}. The multi-dimensional variable unit usually has integrated meaning such as representing one sub-

graph, so it is unnecessary to remove the correlation between the treatment variable with each of

feature H,i in one multi-dimensional feature unit, e.g., H,0∶d. And we should only remove the subgraph-level correlation between treatment variable T with multiple multi-dimensional variable

units {X(1), ⋯, X(p)}. One possible way to achieve this goal is to learn a set of sample weights that

balance the distributions of all confounding variables for the targeted treatment variable, as illustrated

in Figure 4(b), i.e., randomizing the assignment of treatment T 2 with confounders {X(1), ⋯, X(p)}.

The sample weights w could be learnt by the following multiple multi-dimensional confounder

balancing objective:

p

w = arg min ∣∣

wi ⋅ X(i,k) −

wj ⋅ X(jk, )∣∣22,

w k=1 i∶Ti=1

j∶Tj =0

(11)

1Note that the direction of arrow means that the assignment of treatment value will dependent on confounder. However, if the arrow is reversed, it will not affect the theoretical results in our paper.
2Here, we still assume the treatment is a binary variable. In the following part, we will consider the treatment as a multi-dimensional variable.

9

Under review

where X(k) is the embedding matrix for k-th confounding variable X(k).

Weighted Hilbert-Schmidt Independence Criterion. Since above confounder balancing method
is mainly designed for binary treatment variable, which needs the treatment value to divide the
samples into treated or control group, it is hard to apply to the continuous multi-dimensional variables
learned by GNNs. Inspired by the intuition of confounder balancing is to remove the dependence
between the treatment with the corresponding confounding variables, thus we propose to remove
dependence between continuous multi-dimensional random variable T with each of confounder in {X(1), ⋯, X(p)}. Thus we ﬁrst need to measure the degree of dependence between them. And it is feasible to resort to HSIC measure (Song et al., 2007). For two random variables U and V and kernel k and l, HSIC is deﬁned as HSICk,l(U, V ) ∶= ∣∣CUk,Vl ∣∣2HS, where Ck,l is cross-covariance operator in the Reproducing Kernel Hilbert Spaces (RKHS) of k and l (Gretton et al., 2005), an RKHS analogue of covariance matrices. ∣∣ ⋅ ∣∣HS is the Hilbert-Schmidt norm, a Hilbert-space analogue of the Frobenius norm. For two random variables U and V and radial basis function (RBF) kernels k and l, HSICk,l(U, V ) = 0 if and only if U ⊥ V . To estimate HSICk,l(U, V ) with ﬁnite sample, we employ a widely used estimator HSICk0,l(U, V ) (Gretton et al., 2005) with m samples, deﬁned as:

HSICk0,l(U, V ) = (m − 1)−2tr(KPLP),

(12)

where

K, L

∈

m×m
R

are

RBF kernel matrices containing

entries Kij

=

k(Ui, Uj) and Lij

=

l(Vi, Vj),

and

P

=

I − m−111

∈

m×m
R

is

a

centering

matrix

which

projects

onto

the

space

orthogonal to the vector 1.

To eliminate the dependence between the high-level treatment representation with the corresponding confounders, sample reweighting techniques could generate a pseudo-distribution which has less dependence between variables (Zhang et al., 2021; Zou et al., 2020). We propose a sample reweighting method to eliminate the dependence between high-level variables, where the non-linear dependence is measured by HSIC.

We

use

w

∈

m
R+

to

denote

a

set

of

sample

weights

and

∑m i=1

wi

=

m.

For

any

two

random

variables

U and V , we ﬁrst utilize the random initialized weights to reweight these two variables:

Uˆ = (w ⋅ 1T) ⊙ U,

(13)

Vˆ = (w ⋅ 1T) ⊙ V.

(14)

Substituting Uˆ and Vˆ into Eq. (12), we obtain the weighted HSIC value:

HSˆICk0,l(U, V, w) = (m − 1)−2tr(Kˆ PLˆP),

(15)

where

Kˆ , Lˆ

∈

m×m
R

are

weighted

RBF

kernel

matrices

containing

entries

Kˆ ij

=

k(Uˆi, Uˆj)

and

Lˆij = l(Vˆi, Vˆj). Specially, for treatment variable H,0∶d and its corresponding multiple confounder

variables {H,d∶2d, ⋯, H,(nL−1)d∶nLd}, we share the sample weights w across multiple confounders

and propose to optimize w by:

w∗ = arg min

HSˆICk0,l(H,0∶d, H,(p−1)d∶pd, w),

w∈∆m 1<p<nL

(16)

where ∆m = {w ∈ Rn+∣ ∑m i=1 wi = m} and we utilize w = softmax(w) to satisfy this constraint. Hence, reweighting training samples with the optimal w∗ can mitigate the dependence between high-level treatment variable with confounders to the greatest extent.

Global Multi-dimensional Variable Decorrelation. Note that the above method is to remove the correlation between a single treatment variable H,0∶d with the confounders {H,d∶2d, ⋯, H,(nL−1)d∶nLd}. However, we need to estimate the casual effect of all the learned high-level representations {H,0∶d, H,d∶2d, ⋯, H,(nL−1)d∶nLd}. As mentioned above, we need to set each high-level representation as treatment variable and the remaining high-level representations as
confounders, and remove the dependence between each treatment variable with the corresponding
confounders. One effective way to achieve this goal is to remove the all the dependence between

10

Under review

variables. Particularly, we learn a set of sample weights that globally remove the dependence between each pair of high-level representations, deﬁned as follows

w∗ = arg min

HSˆICk0,l(H,(i−1)d∶id, H,(j−1)d∶jd, w).

w∈∆m 1≤i<j≤nL

(17)

As we can see from Eq. (17), the global sample weights w simultaneously reduce the dependence among all high-level representations.

4.4 WEIGHTED GRAPH NEURAL NETWORKS

In the traditional GNN model, the parameters of the model are learned on the original graph dataset G = {G1, ⋯, Gm}. Because the sample weights w learned by the causal variable distinguishing regularizer are capable of globally decorrelating the high-level variables, we propose to use the sample weights to reweight the GNN loss, and iteratively optimize sample weights w and the parameters of
weighted GNN model as follows:

m

f (t+1), g(t+1) = arg min wi(t)L(g(f (Ai, Fi)), yi),

(18)

f,g i=1

w(t+1) = arg min

HSˆICk0,l(H(,(ti+−11))d∶id, H(,(tj+−11))d∶jd, w(t)),

w(t+1)∈∆m 1≤i<j≤nL

(19)

where f (⋅) is representation part of our model and its output is the high-level representation H, H(t+1) = f (t+1)(A, F), t represents the iteration number, g(⋅) is a linear prediction layer, and L(⋅, ⋅)

represents the loss function depends on which task we target. For classiﬁcation task, cross entropy loss is used, and for regression task, least squared loss is used. Initially, w(0) = (1, 1, ⋯, 1)T in each

mini-batch. In the training phase, we iteratively optimize sample weights and model parameters with

Eq. (18) and (19). During the inference phase, the predictive model directly conducts prediction

based on GNN model without any calculation of sample weights. The detailed procedure of our

model is shown in Algorithm 1.

Although StableGNN still performs on dataset G, the weight wi of each graph is no longer same. This weight adjusts the contribution of each graph in the mini-batch loss, so that the GNN parameters are learned on the dataset that each high-level features are decorrelated3 which can better learn the
true correlation between relevant features and labels.

Algorithm 1: Training process of StableGNN

Input: Training graphs Gtrain = {(G1, y1), ⋯, (GN , yN )}; Training Epoch:Epoch;

Decorrelation Epoch: DecorEpoch;

Output: Learned GNN model;

1 while t < Epoch do

2 for 1 to BatchNumber do

3

Forward propagation to generate H;

4

for 1 to DecorEpoch do

5

Optimize sample weights w via Eq. (19);

6

end

7

Back propagate with weighted GNN loss to update f and g via Eq. (18);

8 end

9 end

Discussion. Our proposed framework, StableGNN, aims to relive the distribution shifts problem by causal representation learning diagram in a general way. Specially, a new causal representation
3In this paper, we sightly abuse the term "decorrelate/decorrelation", which means removing both the linear and non-linear dependence among features unless speciﬁed.
11

Under review
learning for graph that seamless integrates the power of representation learning and causal inference is proposed. For the representation learning part, we could utilize various state-of-the-art graph pooling layer (Zhang et al., 2018; Ying et al., 2018; Lee et al., 2019; Gao & Ji, 2019) to extract high-level representations, nevertheless the main intuition of our work is that we should learn high-level meaningful representation rather than meaningless mixed representation in our proposed learning diagram. This point is key for meaningful and effective causal learning, which is validated in Section 5.2. Moreover, we believe that this general framework has the potential to spur the causal representation in other areas, such as for images, we could extract high-level object representation ﬁrst and utilize causal inference techniques to incorporate knowledge into the learning framework.
Time Complexity Analysis. As the proposed framework consists of two parts, we analyze them separately. For graph high-level part, to cluster nodes, although it requires additional computation of an assignment matrix, we observed that the Diffpool layer did not incur substantial additional running time in practice. The reason is that each DiffPool layer reduces the size of graphs by extracting a coarser high-level representation of the graph, which speeds up the graph convolution operation in the next layer. For CVD regularizer, given nL learned high-level representation, the complexity of compute HSIC value of each pair of high-level variable is O(m2) (Song et al., 2012), where m is the batch size. Hence, for each batch, the computation complexity of CVD regularizer is O(tnL(nL − 1)m2), where t is the number of epochs to optimize w and nL is a very small number.
5 EXPERIMENTS
In this section, we evaluate our algorithm on both synthetic and real-world datasets, comparing with state-of-the-arts.
Model Conﬁgurations. In our experiments, the GNN layer used for DiffPool layer is built on top of the GraphSAGE (Hamilton et al., 2017) or GCN (Kipf & Welling, 2016) layer, to demonstrate that our framework can be applied on top of different GNN models. We use the “max pooling” variant of GraphSAGE. One DiffPool layer is used for all the datasets and more sophisticated hierarchical layers could be learned by stacking multiple DiffPool layers. For our model, StableGNN-SAGE/GCN refers to using GraphSAGE/GCN as base model, respectively. All the models are trained with same learning rate mode and the model for prediction is selected based on the epoch with best validation performance.
5.1 EXPERIMENTS ON SYNTHETIC DATA
To better verify the advantages of StableGNN on datasets with different degree of distribution shifts between training set and testing set, we generate the synthetic datasets with clear generation process so that the biased degree of dataset is controllable.
Dataset. We aim to generate a graph classiﬁcation dataset that has a variety of distribution shifts from training dataset to testing dataset. Inspired by recently studies on GNN explanation (Ying et al., 2019; Lin et al., 2021), we utilize motif as subgraph of graphs. We ﬁrst generate a base subgraph for each graph, that is, each positive graph has a “house”-structured network motif and each negative graph has a motif that is randomly drawn from 4 candidate motifs (i.e., star, clique, diamond and grid motifs). Hence, the “house” motif is the causal structure that causally determine the label. To inject spurious correlation, µ ∗ 100% of positive graphs will be added “star” motif and remaining positive and negative graph will randomly add a non-causal motif from 4 candidate motifs. The node features are drawn from same uniform distribution for all nodes. We set µ as {0.6, 0.7, 0.8, 0.9} to get four spurious correlation degrees for training set. And we set µ = 0.5 to generate OOD validation set and µ = 0.25 to generate unbiased testing dataset. The larger µ for training set means there incurs a larger distribution shift between training and testing set. The resulting graphs are further perturbed by adding edges from the vertices of the ﬁrst motif to one of the vertices of the second motif in each graph with probability 0.25. The number of training samples is 2000, and for validation and testing set is 1000.
12

Under review

Experimental Settings and Metrics. As the synthetic data has known generating mechanism and our model is based on the GraphSAGE/GCN, to clearly validate and explain the effectiveness of our framework helping base GNN get rid of spurious correlation, in this subsection, we only compare with the base models. The number of layers of GraphSAGE and GCN is set as 5. The dropout rate for all the methods is set as 0.0. For all the GNN models, an initial learning rate is set as 1 × 10−3, the reduce factor is 0.5, and the patience value is 5. And the learning rate of CVD regularizer is selected from {0.1, 0.3, ⋯, 1.3}. To baselines, the training epoch is set as 50. For StableGNNSAGE/GCN, we set 20 epochs to warm up the parameters, i.e., training without the CVD regularizer, and 30 epochs to train the whole model. The decorrelation epoch to learn sample weights is set as 50. For all the methods, we take the model of the epoch with the best validation performance for prediction. The batch size is set as 250. The number of high-level representation is set as 7 for StableGNN-SAGE and 8 for StableGNN-GCN. For all the baseline models, if not mentioned specially, we aggregate node embeddings by mean pooling readout function to get the graph-level representation. Following (Hendrycks & Dietterich, 2019), we augment each GNN layer with batch normalization (BN) (Ioffe & Normalization) and residual connection (He et al., 2016). We evaluate the methods with three widely used metrics for binary classiﬁcation, i.e., Accuracy, F1 score and ROC-AUC (Huang & Ling, 2005). For all the experiments, we run 4 times with different random seeds and report its mean and standard error of prediction value with the corresponding metric on the test set in percent.

Table 1: Results on synthetic dataset in different settings. The ‘improvements’ means the improvement percent of StableGNN-SAGE/StableGNN-GCN against GraphSAGE/GCN.

Correlation Degree (µ) 0.6 0.7 0.8 0.9 0.6 0.7 0.8 0.9

Method GraphSAGE StableGNN-SAGE Improvements GraphSAGE StableGNN-SAGE Improvements GraphSAGE StableGNN-SAGE Improvements GraphSAGE StableGNN-SAGE Improvements
GCN StableGNN-GCN
Improvements GCN
StableGNN-GCN Improvements GCN
StableGNN-GCN Improvements GCN
StableGNN-GCN Improvements

Accuracy 69.68±0.91 73.93±0.66
6.10% 67.85±0.76 73.9±1.78
8.92% 65.67±1.22 72.15±1.26
9.86% 65.2±0.94 70.35±1.66
7.90%
70.98±0.93 74.92±1.91
5.56% 70.9±1.45 73.15±2.62
3.17% 70.35±0.50 74.5±1.03
5.90% 69.68±0.56 76.35±1.37
9.57%

F1 score 67.83±1.41 73.05±1.21
7.70% 63.76±1.32 71.23±1.88
11.71% 60.23±0.81 68.56±0.87
13.83% 54.24±1.98 64.84±2.54
19.54%
67.06±2.95 73.91±2.49
10.21% 65.57±3.69 70.29±2.76
7.198% 65.41±0.85 70.94±1.69
8.45% 62.28±1.38 72.64±2.62
16.63%

ROC-AUC 77.49±0.71 79.22±1.07
2.23% 75.55±1.01 81.48±4.13
7.85% 72.70±1.45 81.35±2.12
9.98% 72.89±0.67 80.31±1.78
10.18%
77.55±0.55 81.79±2.42
5.47% 78.27±1.53 79.77±3.42
1.92% 75.76±1.09 81.53±0.86
7.62% 76.61±0.66 83.24±0.58
8.65%

Results on Synthetic Data. The results are given in Table 1, and we have the following observations. First, both the GraphSAGE and GCN suffer from serious performance decrease with the increase of spurious correlation degree, e.g., for F1 score, GraphSAGE drops from 67.83 to 54.24, and GCN drops from 67.06 to 62.28, indicating that spuirous correlation greatly affects the GNNs’ generalization performance and the heavier distribution shifts will cause larger performance decrease. Second, comparing with base model, our proposed models achieve up to 19.64% performance improvements, and gain larger improvements under heavier distribution shifts. As we know the "house" motif is decisive for the label, the only way to improve the performance is to utilize this causal subgraph, demonstrating that our models could signiﬁcantly reduce the inﬂuence of spurious correlation among

13

Under review

Case 1

Case 2

Case 3

(a) Testing Graphs

(b) GCN

(c) StableGNN-GCN

Figure 5: Explanation cases of GCN and StableGNN-GCN. Red nodes are the important subgraph calculated by the GNNExplainer.

subgraphs and reveal the true relationship between causal subgraphs with labels. Third, when building our framework both on GraphSAGE and GCN, our framework could achieve consistent improvements, and it indicates that StableGNN is a general framework and has the potential to adopt to various GNN architectures.
Explanation Analysis. An intuitive type of explanation for GNN models is to identify subgraphs that have a strong inﬂuence on ﬁnal decisions (Ying et al., 2019). To demonstrate whether the model focuses on the relevant or irrelevant subgraphs while conducting prediction, we utilize GNNExplainer (Ying et al., 2019) to calculate the most important subgraph with respect to GNN’s prediction and visualize it with red color. As GNNExplainer needs to compute an edge mask for explanation and GraphSAGE cannot aware the edge weights, we explain the GCN-based model, i.e., GCN and StableGNN-GCN. As shown in Figure 5, we ﬁnd the following interesting cases contributing to the success of our model, where each case represents a kind of failures easily made by existing methods.
• Case 1. As we can see, GCN assigns the higher weights to “star” motif, however, StableGNN-GCN concentrates more on “house” motif. Although GCN could make correct predictions based on the “star” motif, which is highly correlated with “house” motif, this prediction is unstable and it means that if there incurs spurious correlation in the training set, the model could learn the spurious correlation and rely on this clue for predictions. This unstable prediction is undesirable, as the unstable structure may change during the wild testing environments.
• Case 2. In this case, there is a “grid” motif connecting with “house” motif. As we can see, GCN pays more attention on “grid” motif and StableGNN-GCN still concentrates on “house” motif. Due to the existing of spurious correlated subgraphs, it will reduce the conﬁdence of true causal subgraph for prediction. When there appears another irrelevant subgraph, GCN may also pay attention on this irrelevant subgraph, leading to incorrect prediction results. However, our model could focus on the true causal subgraphs regardless of which kind of subgraphs are associated with them.
• Case 3. This is a case for negative samples. The spurious correlation leads to the GCN model focusing on the “star” motif. As the “star” motif is correlated with the positive label, GCN model will predict this graph as a positive graph. In contrast, due to the decorrelation of subgraphs in our model, we ﬁnd that the “star” motif may not discriminative to the label decision and “diamond” motif may attribute more to the negative labels.

14

Under review
5.2 EXPERIMENTS ON REAL-WORLD DATASETS
In this section, we apply our StableGNN algorithm on eight real-world datasets for out-of-distribution graph property prediction.
Datasets. We adopt seven molecular property prediction datasets from OGB Datasets (Hu et al., 2020). All the molecules are pre-processed using RDKit (Landrum et al., 2006). Each graph represents a molecule, where nodes are atoms, and edges are chemical bonds. We use the 9-dimensional node features and 3-dimensional edges features provided by (Hu et al., 2020), which has better generalization performance. The task of these datasets is to predict the target molecular properties, e.g., whether a molecule inhibits HIV virus replication or not. Input edge features are 3-dimensional, containing bond type, bond stereochemistry as well as an additional bond feature indicating whether the bond is conjugated. Depending on the properties of molecular, these datasets can be categorized into three kinds of tasks: binary classiﬁcation, multi-label classiﬁcation and regression. Different from commonly used random splitting, these datasets adopt scaffold splitting (Wu et al., 2018) procedure that splits the molecules based on their two-dimensional structural frameworks. The scaffold splitting attempts to separate structurally different molecules into different subsets, which provides a more realistic estimate of model performance in prospective experimental settings. Due to the selection bias of training set, it will inevitably introduce the spurious correlation between the subgraphs of molecules. Moreover, we also conduct the experiments on a commonly used graph classiﬁcation dataset, MUTAG (Debnath et al., 1991), as we could explain the results based on the knowledge used in (Luo et al., 2020). It consists of 4,337 molecule graphs. Each graph is assigned to one of 2 classes based on its mutagenic effect. Note that this dataset cannot adopt the scaffold splitting, as the +4 valence N atom, which commonly exists in this dataset, is illegal in the RDKit (Landrum, 2013) tool used for scaffold splitting. We just use the random splitting for this dataset, however, we still believe there are some OOD cases in the testing set. The splitting ratio for all the datasets is 80/10/10. The detailed statistics are shown in Table 2.
Baselines. As the superiority of GNNs against traditional method on graph-level task, like kernelbased methods (Shervashidze et al., 2011; 2009), has been demonstrated by previous literature (Ying et al., 2018), here, we mainly consider baselines based upon several related and state-of-the-art GNNs.
• Base models: GraphSAGE (Hamilton et al., 2017) and GCN (Kipf & Welling, 2016) are classical GNN methods. We utilize them as base models in our framework, so they are the most related baselines to validate the effectiveness the proposed framework.
• DIFFPOOL (Ying et al., 2018): It is a hierarchical graph pooling method in an end-to-end fashion. It adopts the same model architecture and hyperparamter setting with high-level variable learning component in our framework, except that DIFFPOOL model aggregates the clusters’ representation by summation operation rather than an ordered concatenation operation to generate the ﬁnal high-level representations.
• GAT (Velicˇkovic´ et al., 2017): It is an attention-based GNN method, which learns the edge weights by an attention mechanism.
• GIN (Xu et al., 2019): It is a graph isomorphism network that is as powerful as the WL graph isomorphism test. We compare with two variants of GIN, i.e., whether the is a learnable parameter or a ﬁxed 0 scalar, denoted as GIN and GIN0, respectively.
• MoNet (Monti et al., 2017): It is a general architecure to learn on graphs and manifolds using the bayesian gaussian mixture model.
• SGC (Wu et al., 2019): It is a simpliﬁed GCN-based method, which reduces the excess complexity through successively removing nonlinearities and collapsing weight matrices between consecutive layers.
• JKNet (Xu et al., 2018): It is a GNN framework that selectively combines different aggregations at the last layer.
Experimental Settings and Metrics. Here, we only describe the experimental settings that is different from Section 5.1. For all the GNN baselines, the number of layers is set as 5. The dropout
15

Under review

Table 2: Summary of real-world datasets.

Dataset
Molbace Molbbbp Molhiv MUTAG Molclintox Moltox21 Molesol Mollipo

Task Type
Binary classiﬁcation Binary classiﬁcation Binary classiﬁcation Binary classiﬁcation Multi-label classiﬁcation Multi-label classiﬁcation
Regression Regression

#Graphs
1,513 2,039 41,127 4,337 1,477 7,831 1,128 4,200

Average #Nodes
34.1 24.1 25.5 30.32 26.2 18.6 13.3 27.0

Average #Edges
36.9 26.0 27.5 30.77 27.9 19.3 13.7 29.5

#Task
1 1 1 1 2 12 1 1

Splitting Type
Scaffold splitting Scaffold splitting Scaffold splitting Random splitting Scaffold splitting Scaffold splitting Scaffold splitting Scaffold splitting

Metric
ROC-AUC ROC-AUC ROC-AUC Accuracy ROC-AUC ROC-AUC
RMSE RMSE

rate after each layer for all the methods on the datasets for binary classiﬁcation and multi-label classiﬁcation is set as 0.5, and for regression datasets, the dropout rate is set as 0.0. The number of batch size for binary classiﬁcation and multi-label classiﬁcation is set as 128, and for regression datasets, the batch size is set as 64. The training epoch for all the baselines is set as 200. And for our model, we utilize 100 epoch to warm up and 100 epoch to train the whole model. The number of clusters is set as 7 for our models and DIFFPOOL. As these datasets usually treat chemical bond type as their edge type, to include edge features, we follow (Hu et al., 2020) and add transformed edge features into the incoming node features. For the datasets from OGB, we use the metrics recommended by original paper for each task (Hu et al., 2020). And following (Ying et al., 2019), we adopt Accuracy for MUTAG dataset.
Results on Real-world Datasets. The experimental results on eight datasets are presented in Table 3, and we have the following observations. First, comparing with these competitive GNN models, StableGNN-SAGE/GCN achieves 6 ﬁrst places and 2 second places on all eight datasets. And the average rank of StableGNN-SAGE and StableGNN-GCN are 1.75 and 2.87, respectively, which is much higher than the third place, i.e., 4.38 for MoNet. It means that most existing GNN models cannot perform well on OOD datasets and our model signiﬁcantly outperforms existing methods, which well demonstrates the effectiveness of the proposed causal representation learning framework. Second, comparing with the base models, i.e., GraphSAGE and GCN, our models achieve consistent improvements on all datasets, validating that our framework could boost the existing GNN architectures. Third, StableGNN-SAGE/GCN also outperforms DIFFPOOL method with a large margin. Although we utilize the DiffPool layer to extract high-level representations in our framework, the seamless integration of representation learning and causal learning is the key to the improvements of our model. Fourth, StableGNN-SAGE/GCN achieves superior performance on datasets with three different tasks and a wide range of dataset scales, indicating that our proposed framework is general enough to adopt datasets with a variety of properties.
Ablation Study. Note that our framework naturally fuses the high-level representation learning and causal effect estimation in a uniﬁed framework. Here we conduct ablation studies to investigate the effect of each component. For our framework without the CVD regularizer, we term it as StableGNNNoCVD. 4 The results are presented in Figure 6. We ﬁrst ﬁnd that StableGNN-NoCVD outperforms GraphSAGE on most datasets, indicating that learning hierarchical structure by our model for graphlevel task is necessary and effective. Second, StableGNN-NoCVD achieves competitive results or better results with DIFFPOOL method. The only difference between them is that DIFFPOOL model averages the learned clusters’ representations and StableGNN-NoCVD concatenates them by a consistent order, and then the aggregated embeddings are fed into a classiﬁer. As the traditional MLP classiﬁer needs the features of all samples should in a consistent order, the superior performance of StableGNN-NoCVD well validates that the learned representations H are in a consistent order across graphs. Moreover, we ﬁnd that StableGNN consistently outperforms StableGNN-NoCVD. As the only difference between the two models is the CVD term, we can safely attribute the improvements to the distinguishing of causal variables by our proposed regularizer. Note that on some datasets, we could ﬁnd that StableGNN-NoDVD cannot achieve satisfying results, however, when combining with
4Note that, for simplicity, in the following studies we mainly conduct analysis on StableGNN-SAGE, and StableGNN-GCN will get similar results. StableGNN will refer to StableGNN-SAGE unless mentioned speciﬁcally.
16

Under review

Table 3: Performance of real-world graph datasets. The number in the (⋅) along with each performance number means the rank of the method among all the methods on this dataset. “↑” means that for this metric, the larger value means better performance. “↓” means that for this metric, the smaller value means better performance. Best results of all methods are indicated in bold.

Methods
GIN GIN0 GAT MoNet SGC JKNet DIFFPOOL GCN StableGNN-GCN GraphSAGE StableGNN-SAGE
Methods
GIN GIN0 GAT MoNet SGC JKNet DIFFPOOL GCN StableGNN-GCN GraphSAGE StableGNN-SAGE

Binary Classiﬁcation

Molhiv

Molbace

Molbbbp

MUTAG

ROC-AUC (↑) ROC-AUC (↑)

ROC-AUC (↑)

Accuracy (↑)

76.21±0.53 (6) 75.49±0.91 (9) 76.52±0.69 (5) 77.13±0.79 (3) 69.46±1.44 (11) 74.99±1.60 (10) 75.75±1.38 (8) 76.63±1.13 (4) 77.79 ±1.19 (1) 75.78±2.19 (6) 77.63±0.79 (2)

74.50±2.75 (9) 74.36±3.48 (10)
81.17±0.8 (1) 76.92±0.91 (6) 71.28±1.79 (11) 78.99±13.4 (3) 74.69±11.13 (8) 75.88±1.85 (7) 76.95±3.27 (5) 78.51±1.72 (4) 80.73±3.98 (2)

67.72±1.89 (4) 66.65±1.32 (6) 67.17±0.49 (5) 69.52±0.46 (1) 61.17±2.91 (11) 65.62±0.77 (9) 63.35±2.21 (10) 66.47±0.90 (7) 68.82±3.87 (2) 66.16±0.97 (8) 68.47±2.47 (3)

78.86±1.15 (10) 79.03±0.56 (9) 79.26±1.13 (8) 79.95±0.86 (4) 69.53±0.77 (11) 79.49±1.16 (7) 80.13±1.32 (3) 79.89±1.32 (5) 81.45±2.00 (2) 79.78±0.78 (6) 82.13±0.32 (1)

Multilabel Classiﬁcation

Regression

Molclintox

Moltox21

Molesol

Molipo

ROC-AUC (↑) ROC-AUC (↑)

RMSE (↓)

RMSE (↓)

86.86±3.78 (6) 89.31±2.11 (3) 83.47±1.37 (8) 86.75±1.22 (7) 77.76±1.87 (10) 81.63±2.79 (9) 90.48±2.42 (2) 86.23±2.81 (7) 87.98±2.37 (5) 88.60±2.44 (4) 90.96±1.93 (1)

64.20±0.23 (11) 64.62±0.87 (10) 68.81±0.48 (5) 67.02±0.26 (7) 66.49±1.10 (8) 65.98±0.46 (9) 69.05±0.94 (3) 67.75±0.66 (6) 70.80±0.31 (1) 68.88±0.59 (4) 69.14±0.24 (2)

1.1002±0.0450 (4) 1.1358±0.0587 (5) 1.2758±0.0269 (10) 1.0753±0.0357 (3) 1.6548±0.0462 (11) 1.1688±0.0434 (7) 1.176±0.01388 (8) 1.153±0.0392 (6) 0.9638±0.0292 (1) 1.1852±0.0353 (9) 1.0092±0.0706 (2)

0.8051±0.0323 (10) 0.8050±0.0123 (9) 0.8101±0.0183 (9) 0.7379±0.0117 (4) 1.0681±0.0148 (10) 0.7493±0.0048 (5) 0.7325±0.0221 (2) 0.7927±0.0086 (8) 0.7839±0.0165 (6) 0.7911±0.0147 (7) 0.6971±0.0297 (1)

Average-Rank (↓)
7.50 (9) 7.63 (10) 6.38 (7) 4.38 (3) 10.38 (11) 7.38 (8) 5.50 (4) 6.25 (6) 2.87 (2) 6.00 (5) 1.75 (1)

the regularizer, it makes clear improvements. This phenomenon further validates the necessity of each component that we should conduct representation learning and causal inference jointly.

ROC-AUC (%) ROC-AUC (%) ROC-AUC (%)

90

GraphSAGE

85 DIFFPOOL

StableGNN-NoCVD StableGNN

80

75

70

65

60 Molhiv MolbaDcaetasetsMolbbbp MUTAG

(a) Binary Classiﬁcation (↑)

95

GraphSAGE

90 DIFFPOOL

StableGNN-NoCVD StableGNN

85

80

75

70

65

Moltox21 Datasets

Molclintox

(b) Multilabel Classiﬁcation (↑)

1.2

GraphSAGE

StableGNN-NoCVD

1.1

DIFFPOOL

StableGNN

1.0

0.9

0.8

0.7

Molesol Datasets

Mollipo

(c) Regression (↓)

Figure 6: Ablation study on three real-world tasks.

Comparison with Different Decorrelation Methods. As there may be other ways to decorrelate the variables in GNNs by sample reweighting methods, one question arises naturally: is our proposed decorrelation framework a more suitable strategy for graphs? To answer this question, we compare the following alternatives:
• GraphSAGE-Decorr: This method directly decorrelates each dimension of graph-level representations learned by GraphSAGE.
• StableGNN-NoCVD-Decorr: This method decorrelates each dimension of concatenated high-level representation H learned by StableGNN-NoCVD.
• StableGNN-NoCVD-Distent: This method forces the high-level representation learned by StableGNN-NoCVD to be disentangled via adding a HSIC regularizer to the overall loss.
The results are shown in Table 4. Comparing with these potential decorrelation methods, StableGNN achieves better results consistently, demonstrating that decorrelating the representations by the cluster-level granularity is a more suitable strategy for graph data. Moreover, we ﬁnd that GraphSAGE-Decorr/StableGNN-NoCVD-Decorr shows worse performance than
17

Under review

Table 4: Performance of different decorrelation methods.

Method GraphSAGE GraphSAGE-Decorr StableGNN-NoCVD StableGNN-NoCVD-Decorr StableGNN-NoCVD-Distent StableGNN

Molhiv 75.78±2.19 76.52±0.69 76.47±1.01 75.32±0.52 75.76±0.64 77.63±0.79

Molbace 78.51±1.72 77.34±5.63 79.65±0.86 78.71±2.34 79.04±1.24 80.73±3.98

Molbbbp 66.16±0.97 66.28±0.89 66.73±1.87 67.02±1.55 64.21±1.34 68.47±2.47

MUTAG 79.78±0.7 80.76±1.32 80.13±1.80 79.17±1.07 80.92+0.50 82.13±0.32

Molclintox 88.60±2.44 86.51±0.82 87.56±1.91 88.89±2.58 90.44±0.79 90.96±1.93

Moltox21 68.88±0.59 68.77±0.66 68.63±0.63 69.05±0.66 68.87±1.28 69.14±0.24

Molesol 1.8098±0.1220 1.7889±0.1234 1.0819±0.0219 1.0377±0.0389 1.0729±0.0256 1.022±0.0039

Mollipo 0.7911±0.0147 0.8024±0.0165 0.6971±0.017 0.7171±0.0378 0.7171±0.0378 0.6971±0.0297

GraphSAGE/StableGNN-NoCVD, and the reason is that if we aggressively decorrelate single dimension of embeddings, it will inevitably break the intrinsic semantic meaning of original data. Furthermore, StableGNN-NoCVD-Distent forces the high-level representations to be disentangled, which changes the semantic implication of features, while StableGNN learns sample weights to adjust the data structure while the semantic of features is not effected. Overall, StableGNN is a general and effective framework comparing with all the potential ways.
Convergence Rate and Parameter Sensitivity Analysis. We ﬁrst analyze the convergence rate of our proposed causal variable distinguishing regularizer. We report the summation of HSIC value of all high-level representation pairs and the difference of learned weights between two consecutive epochs during the weights learning procedure in one batch on three relatively smaller datasets in Figure 7. As we can see, the weights learned by CVD regularizer could achieve convergence very fast while reducing the HSIC value signiﬁcantly. In addition, we study the sensitivity of the number of high-level representations and report the performance of StableGNN-NoCVD and StableGNN based on the same pre-deﬁned number of clusters in Figure 8. StableGNN outperforms StableGNN-NoCVD on almost all cases, which well demonstrates the robustness of our methods with the number of pre-deﬁned clusters and the effectiveness of the proposed CVD regularizer. Note that our framework could learn the appropriate number of clusters in an end-to-end way, i.e., some clusters might not be used by the assignment matrix.

(a) Molbace

(b) Molbbbp

(c) Molclintox

Figure 7: Convergence rate analysis of CVD regularizer.

(a) Molbace(↑)

(b) Molbbbp(↑)

(c) Molclintox(↑)

Figure 8: Sensitivity of the pre-deﬁned maximum number of clusters.

Interpretability Analysis. In Figure 9, we investigate explanations for graph classiﬁcation task on MUTAG dataset. In the MUTAG example, colors indicate node features, which represent atoms. StableGNN correctly identiﬁes chemical N O2 and N H2, which are known to be mutagenic (Luo et al., 2020) while baselines fail in. These cases demonstrate that our model could utilize more interpretable structures for prediction. Moreover, the difference of StableGNN-GCN-NoCVD between StableGNNGCN indicates the necessity of integrating two components in our framework.

18

Under review

(a) Input graph

(b) GCN

(c) StableGNN-GCNNoCVD

(d) StableGNN-GCN

Figure 9: Explanation instance for MUTAG dataset. The blue, green, red and yellow color represent N, H, O, C atom, respectively. The top important subgraphs selected by GNNExplainer are viewed in black color (keep top 6 important edges). The picture is best viewed in color.

6 CONCLUSION AND FURTHER WORK
In this paper, we study a practical but seldom studied problem: generalizing GNNs on out-ofdistribution graph data. We analyze the problem in a causal view that the generalization of GNNs will be hindered by the spurious correlation among subgraphs. To improve the stability of existing methods, we propose a general causal representation learning framework, called StableGNN, which integrates graph high-level variable representation learning and causal effect estimation in a uniﬁed framework. Extensive experiments well demonstrate the effectiveness, ﬂexibility, and interpretability of the StableGNN.
In addition, we believe that this paper just opens a direction for causal representation learning on graphs. As the most important contribution, we propose a general framework for causal graph representation learning: graph high-level variable representation learning and causal variable distinguishing, which can be ﬂexibly adjusted for speciﬁc tasks. For example, a multi-channel ﬁlter may be adopted to learn different signals on graphs into subspaces. And for some datasets there may exist more complicated causal relationships among high-level variables, hence discovering causal structure for these high-level variables may be useful for reconstructing original data generation process. To be border impact, we believe the idea could also spur the causal representation learning in other areas, like object recognition and automatic driving in wild environments.

19

Under review
REFERENCES
Joshua Angrist and Guido Imbens. Identiﬁcation and estimation of local average treatment effects, 1995.
Martin Arjovsky, Léon Bottou, Ishaan Gulrajani, and David Lopez-Paz. Invariant risk minimization. arXiv preprint arXiv:1907.02893, 2019.
Susan Athey, Guido W Imbens, and Stefan Wager. Approximate residual balancing: De-biased inference of average treatment effects in high dimensions. arXiv preprint arXiv:1604.07125, 2016.
Yoshua Bengio, Tristan Deleu, Nasim Rahaman, Rosemary Ke, Sébastien Lachapelle, Olexa Bilaniuk, Anirudh Goyal, and Christopher Pal. A meta-transfer objective for learning to disentangle causal mechanisms. arXiv preprint arXiv:1901.10912, 2019.
Deyu Bo, Xiao Wang, Chuan Shi, and Huawei Shen. Beyond low-frequency information in graph convolutional networks. 2021.
Asim Kumar Debnath, Rosa L Lopez de Compadre, Gargi Debnath, Alan J Shusterman, and Corwin Hansch. Structure-activity relationship of mutagenic aromatic and heteroaromatic nitro compounds. correlation with molecular orbital energies and hydrophobicity. Journal of medicinal chemistry, 34 (2):786–797, 1991.
Logan Engstrom, Brandon Tran, Dimitris Tsipras, Ludwig Schmidt, and Aleksander Madry. Exploring the landscape of spatial robustness. In ICML, pp. 1802–1811. PMLR, 2019.
Hongyang Gao and Shuiwang Ji. Graph u-nets. In international conference on machine learning, pp. 2083–2092. PMLR, 2019.
Justin Gilmer, Samuel S Schoenholz, Patrick F Riley, Oriol Vinyals, and George E Dahl. Neural message passing for quantum chemistry. In ICML, pp. 1263–1272. PMLR, 2017.
Arthur Gretton, Olivier Bousquet, Alex Smola, and Bernhard Schölkopf. Measuring statistical dependence with hilbert-schmidt norms. In International conference on algorithmic learning theory, pp. 63–77. Springer, 2005.
Jens Hainmueller. Entropy balancing for causal effects: A multivariate reweighting method to produce balanced samples in observational studies. Political Analysis, 20(1):25–46, 2012.
Will Hamilton, Zhitao Ying, and Jure Leskovec. Inductive representation learning on large graphs. In NeurIPS, pp. 1024–1034, 2017.
Kaiming He, Xiangyu Zhang, Shaoqing Ren, and Jian Sun. Deep residual learning for image recognition. In Proceedings of the IEEE conference on computer vision and pattern recognition, pp. 770–778, 2016.
Dan Hendrycks and Thomas Dietterich. Benchmarking neural network robustness to common corruptions and perturbations. arXiv preprint arXiv:1903.12261, 2019.
Weihua Hu, Matthias Fey, Marinka Zitnik, Yuxiao Dong, Hongyu Ren, Bowen Liu, Michele Catasta, and Jure Leskovec. Open graph benchmark: Datasets for machine learning on graphs. 2020.
Jin Huang and Charles X Ling. Using auc and accuracy in evaluating learning algorithms. TKDE, 17 (3):299–310, 2005.
Sergey Ioffe and Christian Szegedy Batch Normalization. Accelerating deep network training by reducing internal covariate shift. arXiv preprint arXiv:1502.03167.
Wengong Jin, Regina Barzilay, and Tommi Jaakkola. Hierarchical generation of molecular graphs using structural motifs. In ICML, pp. 4839–4848. PMLR, 2020.
Pritish Kamath, Akilesh Tangella, Danica Sutherland, and Nathan Srebro. Does invariant risk minimization capture invariance? In International Conference on Artiﬁcial Intelligence and Statistics, pp. 4069–4077. PMLR, 2021.
20

Under review
Nicolas Keriven and Gabriel Peyré. Universal invariant and equivariant graph neural networks. NeurIPS, 32:7092–7101, 2019.
Thomas N Kipf and Max Welling. Semi-supervised classiﬁcation with graph convolutional networks. In ICLR, 2016.
David Krueger, Ethan Caballero, Joern-Henrik Jacobsen, Amy Zhang, Jonathan Binas, Dinghuai Zhang, Remi Le Priol, and Aaron Courville. Out-of-distribution generalization via risk extrapolation (rex). In ICML, pp. 5815–5826, 2021.
Kun Kuang, Peng Cui, Susan Athey, Ruoxuan Xiong, and Bo Li. Stable prediction across unknown environments. In KDD, pp. 1617–1626, 2018.
Kun Kuang, Ruoxuan Xiong, Peng Cui, Susan Athey, and Bo Li. Stable prediction with model misspeciﬁcation and agnostic distribution shift. In AAAI, 2020.
Brenden M Lake, Tomer D Ullman, Joshua B Tenenbaum, and Samuel J Gershman. Building machines that learn and think like people. Behavioral and brain sciences, 40, 2017.
Greg Landrum. Rdkit: A software suite for cheminformatics, computational chemistry, and predictive modeling, 2013.
Greg Landrum et al. Rdkit: Open-source cheminformatics. 2006.
John Boaz Lee, Ryan Rossi, and Xiangnan Kong. Graph classiﬁcation using structural attention. In SIGKDD, pp. 1666–1674, 2018.
Junhyun Lee, Inyeop Lee, and Jaewoo Kang. Self-attention graph pooling. In ICML, pp. 3734–3743. PMLR, 2019.
AA Leman and B Weisfeiler. A reduction of a graph to a canonical form and an algebra arising during this reduction. Nauchno-Technicheskaya Informatsiya, 2(9):12–16, 1968.
Renjie Liao, Raquel Urtasun, and Richard Zemel. A pac-bayesian approach to generalization bounds for graph neural networks. 2020.
Wanyu Lin, Hao Lan, and Baochun Li. Generative causal explanations for graph neural networks. In ICML, 2021.
David Lopez-Paz, Robert Nishihara, Soumith Chintala, Bernhard Scholkopf, and Léon Bottou. Discovering causal signals in images. In CVPR, pp. 6979–6987, 2017.
Dongsheng Luo, Wei Cheng, Dongkuan Xu, Wenchao Yu, Bo Zong, Haifeng Chen, and Xiang Zhang. Parameterized explainer for graph neural network. In NeurIPS, 2020.
Toshihiko Matsuura and Tatsuya Harada. Domain generalization using a mixture of multiple latent domains. In AAAI, volume 34, pp. 11749–11756, 2020.
Federico Monti, Davide Boscaini, Jonathan Masci, Emanuele Rodola, Jan Svoboda, and Michael M Bronstein. Geometric deep learning on graphs and manifolds using mixture model cnns. In CVPR, pp. 5115–5124, 2017.
Phillip E Pope, Soheil Kolouri, Mohammad Rostami, Charles E Martin, and Heiko Hoffmann. Explainability methods for graph convolutional neural networks. In CVPR, pp. 10772–10781, 2019.
Fengchun Qiao, Long Zhao, and Xi Peng. Learning to learn single domain generalization. In CVPR, pp. 12556–12565, 2020.
Elan Rosenfeld, Pradeep Ravikumar, and Andrej Risteski. The risks of invariant risk minimization. 2020.
Franco Scarselli, Marco Gori, Ah Chung Tsoi, Markus Hagenbuchner, and Gabriele Monfardini. The graph neural network model. IEEE Transactions on Neural Networks, 20(1):61–80, 2008.
21

Under review
Michael Schlichtkrull, Thomas N Kipf, Peter Bloem, Rianne Van Den Berg, Ivan Titov, and Max Welling. Modeling relational data with graph convolutional networks. In European semantic web conference, pp. 593–607. Springer, 2018.
Bernhard Schölkopf, Francesco Locatello, Stefan Bauer, Nan Rosemary Ke, Nal Kalchbrenner, Anirudh Goyal, and Yoshua Bengio. Toward causal representation learning. Proceedings of the IEEE, 109(5):612–634, 2021.
Zheyan Shen, Peng Cui, Kun Kuang, Bo Li, and Peixuan Chen. Causally regularized learning with agnostic data selection bias. In MM, pp. 411–419, 2018.
Zheyan Shen, Peng Cui, Tong Zhang, and Kun Kuang. Stable learning via sample reweighting. In AAAI, pp. 5692–5699, 2020.
Nino Shervashidze, SVN Vishwanathan, Tobias Petri, Kurt Mehlhorn, and Karsten Borgwardt. Efﬁcient graphlet kernels for large graph comparison. In Artiﬁcial intelligence and statistics, pp. 488–495. PMLR, 2009.
Nino Shervashidze, Pascal Schweitzer, Erik Jan Van Leeuwen, Kurt Mehlhorn, and Karsten M Borgwardt. Weisfeiler-lehman graph kernels. Journal of Machine Learning Research, 12(9), 2011.
Le Song, Alex Smola, Arthur Gretton, Karsten M Borgwardt, and Justin Bedo. Supervised feature selection via dependence estimation. In ICML, pp. 823–830, 2007.
Le Song, Alex Smola, Arthur Gretton, Justin Bedo, and Karsten Borgwardt. Feature selection via dependence maximization. Journal of Machine Learning Research, 13(5), 2012.
Jiawei Su, Danilo Vasconcellos Vargas, and Kouichi Sakurai. One pixel attack for fooling deep neural networks. TEC, 23(5):828–841, 2019.
Yu Sun, Xiaolong Wang, Zhuang Liu, John Miller, Alexei A Efros, and Moritz Hardt. Test-time training for out-of-distribution generalization. 2019.
Petar Velicˇkovic´, Guillem Cucurull, Arantxa Casanova, Adriana Romero, Pietro Lio, and Yoshua Bengio. Graph attention networks. In ICLR, 2017.
Haohan Wang, Zexue He, Zachary C Lipton, and Eric P Xing. Learning robust representations by projecting superﬁcial statistics out. arXiv preprint arXiv:1903.06256, 2019.
Felix Wu, Amauri Souza, Tianyi Zhang, Christopher Fifty, Tao Yu, and Kilian Weinberger. Simplifying graph convolutional networks. In ICML, pp. 6861–6871. PMLR, 2019.
Zhenqin Wu, Bharath Ramsundar, Evan N Feinberg, Joseph Gomes, Caleb Geniesse, Aneesh S Pappu, Karl Leswing, and Vijay Pande. Moleculenet: a benchmark for molecular machine learning. Chemical science, 9(2):513–530, 2018.
Keyulu Xu, Chengtao Li, Yonglong Tian, Tomohiro Sonobe, Ken-ichi Kawarabayashi, and Stefanie Jegelka. Representation learning on graphs with jumping knowledge networks. In ICML, pp. 5453–5462. PMLR, 2018.
Keyulu Xu, Weihua Hu, Jure Leskovec, and Stefanie Jegelka. How powerful are graph neural networks? In ICLR, 2019. URL https://openreview.net/forum?id=ryGs6iA5Km.
Rex Ying, Jiaxuan You, Christopher Morris, Xiang Ren, William L Hamilton, and Jure Leskovec. Hierarchical graph representation learning with differentiable pooling. In NeurIPS, 2018.
Rex Ying, Dylan Bourgeois, Jiaxuan You, Marinka Zitnik, and Jure Leskovec. Gnnexplainer: Generating explanations for graph neural networks. In NeurIPS, 2019.
Muhan Zhang and Yixin Chen. Link prediction based on graph neural networks. volume 31, pp. 5165–5175, 2018.
Muhan Zhang, Zhicheng Cui, Marion Neumann, and Yixin Chen. An end-to-end deep learning architecture for graph classiﬁcation. In AAAI, 2018.
22

Under review Xingxuan Zhang, Peng Cui, Renzhe Xu, Linjun Zhou, Yue He, and Zheyan Shen. Deep stable
learning for out-of-distribution generalization. In CVPR, pp. 5372–5382, 2021. Hao Zou, Peng Cui, Bo Li, Zheyan Shen, Jianxin Ma, Hongxia Yang, and Yue He. Counterfactual
prediction for bundle treatment. NeurIPS, 33, 2020. José R Zubizarreta. Stable weights that balance covariates for estimation with incomplete outcome
data. Journal of the American Statistical Association, 110(511):910–922, 2015.
23

