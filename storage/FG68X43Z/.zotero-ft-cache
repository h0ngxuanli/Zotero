
Skip to main content
Cornell University
We gratefully acknowledge support from the Simons Foundation, member institutions , and all contributors. Donate
arxiv logo > cs > arXiv:2210.03347

Help | Advanced Search
Search
Computer Science > Computation and Language
(cs)
[Submitted on 7 Oct 2022 ( v1 ), last revised 15 Jun 2023 (this version, v2)]
Title: Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding
Authors: Kenton Lee , Mandar Joshi , Iulia Turc , Hexiang Hu , Fangyu Liu , Julian Eisenschlos , Urvashi Khandelwal , Peter Shaw , Ming-Wei Chang , Kristina Toutanova
Download a PDF of the paper titled Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding, by Kenton Lee and 9 other authors
Download PDF

    Abstract: Visually-situated language is ubiquitous -- sources range from textbooks with diagrams to web pages with images and tables, to mobile apps with buttons and forms. Perhaps due to this diversity, previous work has typically relied on domain-specific recipes with limited sharing of the underlying data, model architectures, and objectives. We present Pix2Struct, a pretrained image-to-text model for purely visual language understanding, which can be finetuned on tasks containing visually-situated language. Pix2Struct is pretrained by learning to parse masked screenshots of web pages into simplified HTML. The web, with its richness of visual elements cleanly reflected in the HTML structure, provides a large source of pretraining data well suited to the diversity of downstream tasks. Intuitively, this objective subsumes common pretraining signals such as OCR, language modeling, image captioning. In addition to the novel pretraining strategy, we introduce a variable-resolution input representation and a more flexible integration of language and vision inputs, where language prompts such as questions are rendered directly on top of the input image. For the first time, we show that a single pretrained model can achieve state-of-the-art results in six out of nine tasks across four domains: documents, illustrations, user interfaces, and natural images. 

Comments: 	Accepted at ICML
Subjects: 	Computation and Language (cs.CL) ; Computer Vision and Pattern Recognition (cs.CV)
Cite as: 	arXiv:2210.03347 [cs.CL]
  	(or arXiv:2210.03347v2 [cs.CL] for this version)
  	https://doi.org/10.48550/arXiv.2210.03347
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Mandar Joshi [ view email ]
[v1] Fri, 7 Oct 2022 06:42:06 UTC (5,979 KB)
[v2] Thu, 15 Jun 2023 21:34:23 UTC (5,245 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Pix2Struct: Screenshot Parsing as Pretraining for Visual Language Understanding, by Kenton Lee and 9 other authors
    PDF
    Other formats 

Current browse context:
cs.CL
< prev   |   next >
new | recent | 2210
Change to browse by:
cs
cs.CV
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

1 blog link
( what is this? )
a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

