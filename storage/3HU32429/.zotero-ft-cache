
Skip to main content
Cornell University
We gratefully acknowledge support from
the Simons Foundation and member institutions.
arxiv logo > cs > arXiv:2201.12987

Help | Advanced Search
Search
Computer Science > Machine Learning
(cs)
[Submitted on 31 Jan 2022 ( v1 ), last revised 17 Jun 2022 (this version, v3)]
Title: Interpretable and Generalizable Graph Learning via Stochastic Attention Mechanism
Authors: Siqi Miao , Miaoyuan Liu , Pan Li
Download a PDF of the paper titled Interpretable and Generalizable Graph Learning via Stochastic Attention Mechanism, by Siqi Miao and 2 other authors
Download PDF

    Abstract: Interpretable graph learning is in need as many scientific applications depend on learning models to collect insights from graph-structured data. Previous works mostly focused on using post-hoc approaches to interpret pre-trained models (graph neural networks in particular). They argue against inherently interpretable models because the good interpretability of these models is often at the cost of their prediction accuracy. However, those post-hoc methods often fail to provide stable interpretation and may extract features that are spuriously correlated with the task. In this work, we address these issues by proposing Graph Stochastic Attention (GSAT). Derived from the information bottleneck principle, GSAT injects stochasticity to the attention weights to block the information from task-irrelevant graph components while learning stochasticity-reduced attention to select task-relevant subgraphs for interpretation. The selected subgraphs provably do not contain patterns that are spuriously correlated with the task under some assumptions. Extensive experiments on eight datasets show that GSAT outperforms the state-of-the-art methods by up to 20% ↑ in interpretation AUC and 5% ↑ in prediction accuracy. Our code is available at this https URL . 

Comments: 	Accepted to ICML 2022
Subjects: 	Machine Learning (cs.LG)
Cite as: 	arXiv:2201.12987 [cs.LG]
  	(or arXiv:2201.12987v3 [cs.LG] for this version)
  	https://doi.org/10.48550/arXiv.2201.12987
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Siqi Miao [ view email ]
[v1] Mon, 31 Jan 2022 03:59:48 UTC (1,778 KB)
[v2] Thu, 16 Jun 2022 01:29:19 UTC (1,798 KB)
[v3] Fri, 17 Jun 2022 01:43:45 UTC (1,793 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Interpretable and Generalizable Graph Learning via Stochastic Attention Mechanism, by Siqi Miao and 2 other authors
    PDF
    Other formats 

( license )
Current browse context:
cs.LG
< prev   |   next >
new | recent | 2201
Change to browse by:
cs
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

DBLP - CS Bibliography
listing | bibtex
Pan Li
a export BibTeX citation Loading...
Bookmark
BibSonomy logo Mendeley logo Reddit logo ScienceWISE logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

