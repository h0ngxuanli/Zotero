
Skip to main content
Cornell University
We are hiring

We gratefully acknowledge support from
the Simons Foundation and member institutions.
arxiv logo > cs > arXiv:2303.05077

Help | Advanced Search
Search
Computer Science > Computation and Language
(cs)
[Submitted on 9 Mar 2023 ( v1 ), last revised 10 Mar 2023 (this version, v2)]
Title: Learning the Legibility of Visual Text Perturbations
Authors: Dev Seth , Rickard Stureborg , Danish Pruthi , Bhuwan Dhingra
Download a PDF of the paper titled Learning the Legibility of Visual Text Perturbations, by Dev Seth and 2 other authors
Download PDF

    Abstract: Many adversarial attacks in NLP perturb inputs to produce visually similar strings ('ergo' → ' ϵ rgo') which are legible to humans but degrade model performance. Although preserving legibility is a necessary condition for text perturbation, little work has been done to systematically characterize it; instead, legibility is typically loosely enforced via intuitions around the nature and extent of perturbations. Particularly, it is unclear to what extent can inputs be perturbed while preserving legibility, or how to quantify the legibility of a perturbed string. In this work, we address this gap by learning models that predict the legibility of a perturbed string, and rank candidate perturbations based on their legibility. To do so, we collect and release LEGIT, a human-annotated dataset comprising the legibility of visually perturbed text. Using this dataset, we build both text- and vision-based models which achieve up to 0.91 F1 score in predicting whether an input is legible, and an accuracy of 0.86 in predicting which of two given perturbations is more legible. Additionally, we discover that legible perturbations from the LEGIT dataset are more effective at lowering the performance of NLP models than best-known attack strategies, suggesting that current models may be vulnerable to a broad range of perturbations beyond what is captured by existing visual attacks. Data, code, and models are available at this https URL . 

Comments: 	14 pages, 7 figures. Accepted at EACL 2023 (main, long)
Subjects: 	Computation and Language (cs.CL) ; Computer Vision and Pattern Recognition (cs.CV)
Cite as: 	arXiv:2303.05077 [cs.CL]
  	(or arXiv:2303.05077v2 [cs.CL] for this version)
  	https://doi.org/10.48550/arXiv.2303.05077
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Dev Seth [ view email ]
[v1] Thu, 9 Mar 2023 07:22:07 UTC (1,541 KB)
[v2] Fri, 10 Mar 2023 19:54:39 UTC (1,541 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Learning the Legibility of Visual Text Perturbations, by Dev Seth and 2 other authors
    PDF
    Other formats 

( license )
Current browse context:
cs.CL
< prev   |   next >
new | recent | 2303
Change to browse by:
cs
cs.CV
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Reddit logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

