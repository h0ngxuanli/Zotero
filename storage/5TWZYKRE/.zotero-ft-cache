
Skip to main content
Cornell University
We gratefully acknowledge support from
the Simons Foundation and member institutions.
arxiv logo > cs > arXiv:2211.14952

Help | Advanced Search
Search
Computer Science > Cryptography and Security
(cs)
[Submitted on 27 Nov 2022]
Title: Federated Learning Attacks and Defenses: A Survey
Authors: Yao Chen , Yijie Gui , Hong Lin , Wensheng Gan , Yongdong Wu
Download a PDF of the paper titled Federated Learning Attacks and Defenses: A Survey, by Yao Chen and 4 other authors
Download PDF

    Abstract: In terms of artificial intelligence, there are several security and privacy deficiencies in the traditional centralized training methods of machine learning models by a server. To address this limitation, federated learning (FL) has been proposed and is known for breaking down ``data silos" and protecting the privacy of users. However, FL has not yet gained popularity in the industry, mainly due to its security, privacy, and high cost of communication. For the purpose of advancing the research in this field, building a robust FL system, and realizing the wide application of FL, this paper sorts out the possible attacks and corresponding defenses of the current FL system systematically. Firstly, this paper briefly introduces the basic workflow of FL and related knowledge of attacks and defenses. It reviews a great deal of research about privacy theft and malicious attacks that have been studied in recent years. Most importantly, in view of the current three classification criteria, namely the three stages of machine learning, the three different roles in federated learning, and the CIA (Confidentiality, Integrity, and Availability) guidelines on privacy protection, we divide attack approaches into two categories according to the training stage and the prediction stage in machine learning. Furthermore, we also identify the CIA property violated for each attack method and potential attack role. Various defense mechanisms are then analyzed separately from the level of privacy and security. Finally, we summarize the possible challenges in the application of FL from the aspect of attacks and defenses and discuss the future development direction of FL systems. In this way, the designed FL system has the ability to resist different attacks and is more secure and stable. 

Comments: 	IEEE BigData. 10 pages, 2 figures, 2 tables
Subjects: 	Cryptography and Security (cs.CR) ; Artificial Intelligence (cs.AI)
Cite as: 	arXiv:2211.14952 [cs.CR]
  	(or arXiv:2211.14952v1 [cs.CR] for this version)
  	https://doi.org/10.48550/arXiv.2211.14952
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Wensheng Gan [ view email ]
[v1] Sun, 27 Nov 2022 22:07:07 UTC (2,924 KB)
Full-text links:
Download:

    Download a PDF of the paper titled Federated Learning Attacks and Defenses: A Survey, by Yao Chen and 4 other authors
    PDF
    Other formats 

( license )
Current browse context:
cs.CR
< prev   |   next >
new | recent | 2211
Change to browse by:
cs
cs.AI
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Mendeley logo Reddit logo ScienceWISE logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

