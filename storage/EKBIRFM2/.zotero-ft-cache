
Skip to main content
Cornell University
We gratefully acknowledge support from
the Simons Foundation and member institutions.
arxiv logo > cs > arXiv:2203.08669

Help | Advanced Search
Search
Computer Science > Cryptography and Security
(cs)
[Submitted on 16 Mar 2022 ( v1 ), last revised 6 May 2022 (this version, v2)]
Title: MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients
Authors: Xiaoyu Cao , Neil Zhenqiang Gong
Download a PDF of the paper titled MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients, by Xiaoyu Cao and Neil Zhenqiang Gong
Download PDF

    Abstract: Existing model poisoning attacks to federated learning assume that an attacker has access to a large fraction of compromised genuine clients. However, such assumption is not realistic in production federated learning systems that involve millions of clients. In this work, we propose the first Model Poisoning Attack based on Fake clients called MPAF. Specifically, we assume the attacker injects fake clients to a federated learning system and sends carefully crafted fake local model updates to the cloud server during training, such that the learnt global model has low accuracy for many indiscriminate test inputs. Towards this goal, our attack drags the global model towards an attacker-chosen base model that has low accuracy. Specifically, in each round of federated learning, the fake clients craft fake local model updates that point to the base model and scale them up to amplify their impact before sending them to the cloud server. Our experiments show that MPAF can significantly decrease the test accuracy of the global model, even if classical defenses and norm clipping are adopted, highlighting the need for more advanced defenses. 

Comments: 	In CVPR Workshops, 2022
Subjects: 	Cryptography and Security (cs.CR) ; Machine Learning (cs.LG)
Cite as: 	arXiv:2203.08669 [cs.CR]
  	(or arXiv:2203.08669v2 [cs.CR] for this version)
  	https://doi.org/10.48550/arXiv.2203.08669
Focus to learn more
arXiv-issued DOI via DataCite
Submission history
From: Xiaoyu Cao [ view email ]
[v1] Wed, 16 Mar 2022 14:59:40 UTC (8,114 KB)
[v2] Fri, 6 May 2022 02:54:02 UTC (8,125 KB)
Full-text links:
Download:

    Download a PDF of the paper titled MPAF: Model Poisoning Attacks to Federated Learning based on Fake Clients, by Xiaoyu Cao and Neil Zhenqiang Gong
    PDF
    Other formats 

( license )
Current browse context:
cs.CR
< prev   |   next >
new | recent | 2203
Change to browse by:
cs
cs.LG
References & Citations

    NASA ADS
    Google Scholar
    Semantic Scholar

a export BibTeX citation Loading...
Bookmark
BibSonomy logo Mendeley logo Reddit logo ScienceWISE logo
Bibliographic Tools
Bibliographic and Citation Tools
Bibliographic Explorer Toggle
Bibliographic Explorer ( What is the Explorer? )
Litmaps Toggle
Litmaps ( What is Litmaps? )
scite.ai Toggle
scite Smart Citations ( What are Smart Citations? )
Code, Data, Media
Demos
Related Papers
About arXivLabs
Which authors of this paper are endorsers? | Disable MathJax ( What is MathJax? )

    About
    Help

    contact arXiv Click here to contact arXiv Contact
    subscribe to arXiv mailings Click here to subscribe Subscribe

    Copyright
    Privacy Policy

    Web Accessibility Assistance

    arXiv Operational Status
    Get status notifications via email or slack

